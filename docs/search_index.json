[["index.html", "ENC2055: Introduction to Programming Languages for Linguistic Analysis Preface Course Objective Textbook Course Website Assignments Contributing to the Lecture Notes Course Demo Data Questions? Necessary Packages Interative Live Environment", " ENC2055: Introduction to Programming Languages for Linguistic Analysis Alvin Chen (陳正賢） 2023-03-01 Preface Welcome to ENC2055 Introduction to Programming Languages for Linguistic Analysis. This is a graduate-level course tailored to those who are interested in computational text analytics and data science in general. Have you decided to embark upon a digital journey to your future career, there are a series of courses provided in the Department of English, NTNU, Taiwan, offering necessary skills and knowledge in important disciplines. This introductory course in basic computational coding would be a prerequisite course for many other advance-level courses. In particular, our faculty in the Linguistics track is dedicated to research on both theoretical and applied linguistics. Along with courses offered by other faculty members, this course provides a necessary foundation for the burgeoning discipline of computational text analytics. Please note that while this course has no prerequisite from the students, it will turn out to be a prerequisite for a lot of advanced courses, such as Corpus Linguistics and Computational Linguistics. If you plan to step into this computational way of language processing, you need to take this course (or at least you need to learn how to code.) Course Objective The objective of this course is to provide a comprehensive introduction to programming languages with a special focus on its application in linguistic analyses. This course is especially tailored to those who do not have any background or experiences in coding. We will start from the very basic concepts, such as data types, variable assignments, control structures, to more complex procedures such as routines, functions, and other exploratory project-based tasks. The course consists of a series of theme-based hands-on tutorials, which demonstrate how the flexibility of the programming language can help you become a more efficient and productive data scientist. Specifically, this course will use the language R as our featuring programming language and introduce you to , Rstudio, and a collection of R packages designed to work together to make linguistic analyses fast, fluent, and fun. In addition, we will briefly touch upon a few important constructs with another popular language in data science, Python . By the end of the course, students should have a working knowledge of coding and an initial ability to advance a project independently as a data scientist. In this course, we will not be dealing with complex maths like: \\[ f(x)=\\frac{1}{\\sqrt{2 \\pi}} e^{-\\frac{1}{2} x^{2}} \\] \\[ P(A) = \\sum P(\\{ (e_1,\\dotsc,e_N) \\}) = \\binom{N}{k} \\cdot p^kq^{N-k} \\] We will not be dealing with linguistic theories as well. No transformations. No movements. No bindings. This course is all about (text) data processing and computational coding. library(tidyverse) data(&quot;USArrests&quot;) # ?USArrests ## check description of the dataset head(USArrests) USArrests %&gt;% pivot_longer(cols = c(&quot;Murder&quot;, &quot;Assault&quot;, &quot;UrbanPop&quot;, &quot;Rape&quot;), names_to = &quot;ArrestTypes&quot;, values_to = &quot;Rates&quot;) %&gt;% ggplot(aes(ArrestTypes, Rates, fill = ArrestTypes)) + geom_boxplot() ## data() ## check more built-in datasets In the lecture notes, the text boxes in light blue refer to codes that you need to run in either terminal or your R/Python console. The text boxes in black background show the outputs of the code processing. We will follow this presentation convention throughout the entire lecture notes. print(&quot;Hello! R!&quot;) [1] &quot;Hello! R!&quot; Textbook Throughout the semester, we will follow the materials provided on our course website (see below). We will not use a particular textbook for the course. However, I do like to recommend Wickham &amp; Grolemund (2017) for its simplicity. Also, another great book for R lovers, by Davies (2016): And two more comprehensive books for Python basics: Gerrard (2016) and Sweigart (2020): Course Website We have a course website. You may need a password to get access to the course materials. If you are an officially enrolled student, please ask the instructor for the access code. Assignments Students are expected to complete the exercises included in each chapter/topic. The assignment due is always one week after the chapter/topic is completed. No late submission will be accepted. Students need to follow the Ch3 Code Format Convention for their submitted scripts. Contributing to the Lecture Notes Although I have tried every possible way to make sure that the contents are correct, I may still accidentally make mistakes in the materials. If you spot any errors and would like make suggestions for better solutions, I would be more than happy to hear from you. To contribute your ideas, let’s use Hypothes.is, which is an amazing tool for website annotations. Go to Hypothes.is, and click the “get-started” on the top-right corner of the homepage. Install the the add-on for chrome, or other browser. To add an annotation, select some text and then click the on the pop-up menu. To see the annotations of others, click the in the upper right-hand corner of the page. Please turn on the Hypothes.is add-on when you are reading the course lecture notes, and you will see all public/shared annotations made by other course participants. See Quick Start Guide for Students and Annotation Tips for Students. At the beginning of the semester, I will share with the class a link to invite all the enrolled students to join a private group for annotation. But one can always provide feedbacks via the public annotations of the website. Course Demo Data Dropbox Demo Data Directory Questions? For more information related to this course, please see the FAQ on our course website or write me at any time at: alvinchen@ntnu.edu.tw Necessary Packages In this course, we will need the following R packages for tutorials and exercises. library(chatgpt) library(dplyr) library(foreign) library(gganimate) library(ggplot2) library(ggrepel) library(gptchatteR) library(Hmisc) library(lubridate) library(maps) library(purrr) library(quanteda.textplots) library(quanteda.textstats) library(quanteda) library(readr) library(readtext) library(reticulate) library(scales) library(showtext) library(stringr) library(tibble) library(tidyr) library(tidytext) library(tidyverse) Interative Live Environment Binder is an open-source tool that allows us to create an interactive environment to run our codes and scripts on the cloud. Through the link, we can launch an interactive RStudio environment in the web browser and run the R codes and scripts from the lecture notes. The cloud-based environment is pre-configured with essential tools required for the course, such as the R kernel, RStudio, and R libraries. The Binder platform offers a solution to compatibility issues arising from the use of different operating systems, such as Windows, Mac OS, and Linux. The use of Binder in the classroom enables us to work with a consistent and reliable platform for the R programming needs. Please note that any changes in the interactive Binder environment will not be retained upon closing the session. References Davies, T. M. (2016). The book of R: A first course in programming and statistics (1st ed.). No Starch Press, Inc. Gerrard, P. (2016). Lean python: Learn just enough python to build useful tools. Apress. Sweigart, A. (2020). Automate the boring stuff with python: Practical programming for total beginners. 2nd edition. No Starch Press. Wickham, H., &amp; Grolemund, G. (2017). R for data science: Import, tidy, transform, visualize, and model data (1st ed.). O’Reilly Media, Inc. "],["intro-ds.html", "Chapter 1 Data Science and R 1.1 What is Data Science? 1.2 Working Pipeline for Data Science 1.3 Why R? 1.4 tidyverse 1.5 More Skills", " Chapter 1 Data Science and R 1.1 What is Data Science? Data Science is an interdisciplinary subject, which integrates knowledge of statistics, computer science and other domina-specific areas. A graph by Drew Conway may summarize the essense of Data Science: 1.2 Working Pipeline for Data Science Hadley Wickham’s R for Data Science describes six important steps for data analysis: 1.3 Why R? According to a report by KDnuggets, among all the languages used by data scientists, python and R are the most popular two languages: It is true that Python now seems much more popular among IT developers. That being said, you may consult this article, &lt;&lt; Why R is the Best Data Science Language to Learn Today? &gt;&gt;, for a more comprehensive review of the strengths of R. The general tendency is that: if you want to go into the industry and take developers or programmers as your future career, you can choose Python; if you are planning to settle yourself in the academia, I would definitely recommend R. Here are a list of strengths for R language: powerful statistical analysis data visualization exploratory analysis re-usable reports tidyverse consistent grammar/syntax high readability of the codes, similar to human languages ( %&gt;% is a unique R feature!) In this course, our main objective is to introduce you to the world of coding. A high-level programming language like R would be a very friendly start, especially for those who have no background of computing. So, let us enjoy the journey of a simple yet powerful language learning! In fact, now it seems that data scientists are expected to be multilingual and well-versed in the proper coding language to deal with the target tasks efficiently. Also, R and RStudio have developed toward this aim by expanding its capacity of integrating the Python language. Now RStudio can be a Single Home for R &amp; Python. Similarly, Jupyter Lab/Notebook (a Python IDE) can run R codes seamlessly as well. 1.4 tidyverse In this course, we will be working on a collection of packages included in tidyverse. This is a unique package in R, which can help you deal with data in a massively convenient way. It is hoped that the user can easily call particular functions and make use of the pipe operator %&gt;% to concatenate all procedures serially, just like the natural human languages. In particular, we will work on the following major libraries from tidyverse: ggplot2: Data visualization dplyr: Data wrangling tidyr: Data wrangling stringr: String manipulation readr: Data importing purrr: Functional programming to avoid loops tibble: Powerful data structure Here is a quick example to show the efficiency of the tidyverse-style R. We first prepare a simple collection of texts, which include 720 sentences. library(tidyverse) head(sentences) ## `sentences` dataset is included in `stringr` [1] &quot;The birch canoe slid on the smooth planks.&quot; [2] &quot;Glue the sheet to the dark blue background.&quot; [3] &quot;It&#39;s easy to tell the depth of a well.&quot; [4] &quot;These days a chicken leg is a rare dish.&quot; [5] &quot;Rice is often served in round bowls.&quot; [6] &quot;The juice of lemons makes fine punch.&quot; ## Prepare a data frame for analysis corp &lt;- data.frame(id = seq(1:length(sentences)), texts = str_to_lower(sentences)) corp With a few R commands concatenated by the pipe %&gt;%, we can see the distributions of the vowel and consonant percentages of all the sentences in the text collection. corp %&gt;% mutate(NumOfChars = nchar(texts), VowelPer = str_count(texts,&#39;[aeiou]&#39;)/NumOfChars, ConPer = str_count(texts,&#39;[^aeiou]&#39;)/NumOfChars) %&gt;% pivot_longer(c(&quot;VowelPer&quot;, &quot;ConPer&quot;), names_to = &quot;Segment&quot;,values_to = &quot;Percent&quot;) %&gt;% ggplot(aes(Segment, Percent, fill=Segment)) + geom_boxplot(notch=TRUE) 1.5 More Skills Data scientists are now becoming more and more popular. To know more about this job, one thing you may want to know is what kinds of skills are needed? The following two graphs were taken from &lt;The Most in Demand Skills for Data Scientists&gt;: While people still have various definitions regarding what data science encompasses, there are indeed several practical fields that have been commonly regarded as part of the definitions of Data Science. According to Mason and Wiggins (2010) A Taxonomy of Data Science, data science can be defined according to five crucial steps: Obtain: pointing and clicking does not scale. (Data collection via copy-pasting is limited.) Scrub: the world is a messy place. (Clean data are hard to come by.) Explore: You can see a lot by looking. (A picture is worth a thousand words.) Models: always bad, sometimes ugly. (Chance-level observations are everywhere.) iNterpret: “The purpose of computing is insight, not numbers.” This OSEMN (awesome!!) model should give you a much clearer picture of what you need to become a proficient data scientist. What we do here in this course is just a start….Take a deep breath:) "],["r-fundamentals.html", "Chapter 2 R Fundamentals 2.1 Installing R 2.2 Installing RStudio 2.3 My Current Version 2.4 The Interface of Rstudio 2.5 Assignment 2.6 Data Structure 2.7 Function 2.8 Vectorization 2.9 Script 2.10 Library 2.11 Setting 2.12 Seeking Help 2.13 Language Learning Ain’t Easy! 2.14 Keyboard Shortcuts", " Chapter 2 R Fundamentals Download R: R-Project IDE: RStudio 2.1 Installing R Download the installation file: http://cran.r-project.org 2.2 Installing RStudio After you install R, you may install RStudio. RStudio is an editor which can help you write R codes. A good analogy is that R is the engine and Rstudio is the dashboard of the car. Please download the right version that is compatible with your PC operating system. https://www.rstudio.com/download Choose RStudio Desktop Important notes: Do not have Chinese characters in your directory names or on the path to the files Do not have spaces and weird symbols in your file path: D:/R D:/Rstudio /User/Alvinchen/ 2.3 My Current Version sessionInfo() R version 4.2.2 (2022-10-31) Platform: x86_64-apple-darwin17.0 (64-bit) Running under: macOS Catalina 10.15.7 Matrix products: default BLAS: /Library/Frameworks/R.framework/Versions/4.2/Resources/lib/libRblas.0.dylib LAPACK: /Library/Frameworks/R.framework/Versions/4.2/Resources/lib/libRlapack.dylib locale: [1] en_US.UTF-8/en_US.UTF-8/en_US.UTF-8/C/en_US.UTF-8/en_US.UTF-8 attached base packages: [1] stats graphics grDevices utils datasets methods base other attached packages: [1] forcats_0.5.2 stringr_1.5.0 dplyr_1.0.10 purrr_1.0.0 [5] readr_2.1.3 tidyr_1.2.1 tibble_3.1.8 ggplot2_3.4.0 [9] tidyverse_1.3.2 reticulate_1.26 loaded via a namespace (and not attached): [1] Rcpp_1.0.10 lubridate_1.9.0 lattice_0.20-45 [4] icons_0.2.0 png_0.1-8 assertthat_0.2.1 [7] digest_0.6.31 utf8_1.2.2 R6_2.5.1 [10] cellranger_1.1.0 backports_1.4.1 reprex_2.0.2 [13] evaluate_0.19 highr_0.10 httr_1.4.5 [16] pillar_1.8.1 rlang_1.0.6 readxl_1.4.1 [19] googlesheets4_1.0.1 rstudioapi_0.14 jquerylib_0.1.4 [22] Matrix_1.5-1 rmarkdown_2.19 labeling_0.4.2 [25] googledrive_2.0.0 munsell_0.5.0 broom_1.0.2 [28] compiler_4.2.2 modelr_0.1.10 xfun_0.36 [31] pkgconfig_2.0.3 htmltools_0.5.4 tidyselect_1.2.0 [34] bookdown_0.31 fansi_1.0.3 crayon_1.5.2 [37] withr_2.5.0 tzdb_0.3.0 dbplyr_2.2.1 [40] rappdirs_0.3.3 grid_4.2.2 jsonlite_1.8.4 [43] gtable_0.3.1 lifecycle_1.0.3 DBI_1.1.3 [46] magrittr_2.0.3 formatR_1.13 scales_1.2.1 [49] cli_3.6.0 stringi_1.7.8 cachem_1.0.6 [52] farver_2.1.1 fs_1.6.1 xml2_1.3.3 [55] bslib_0.4.2 ellipsis_0.3.2 generics_0.1.3 [58] vctrs_0.5.1 tools_4.2.2 glue_1.6.2 [61] hms_1.1.2 fastmap_1.1.0 yaml_2.3.6 [64] timechange_0.1.1 colorspace_2.0-3 gargle_1.2.1 [67] rvest_1.0.3 knitr_1.41 haven_2.5.1 [70] sass_0.4.5 2.4 The Interface of Rstudio When you start Rstudio, you will see an interface as follows: Figure 2.1: Rstudio Interface Rstudio Interface: Editor: You create and edit R-related files here (e.g., *.r, *.Rmd etc.) Console: This is the R engine, which runs the codes we send out either from the R-script file or directly from the console input Output: You can view graphic outputs here The R console is like a calculator. You can type any R code in the console after the prompt &gt; and run the code line by line by pressing enter. 1 + 1 [1] 2 log(10) [1] 2.302585 1:5 [1] 1 2 3 4 5 Or alternatively, we can create an R script in Rstudio and write down lines of R codes to be passed to the R console. This way, we can run the whole script all at once. This is the idea of writing a program. In the above example (Figure 2.1), I wrote a few lines of codes in a R script file (cf. the Editor frame) and asked R to run these lines of codes in the R Console. And the graphic output of the R script was printed in the Output frame. Exercise 2.1 Please create a new R script in Rstudio. You may name the script as “ch2.R”. Please write the following codes in the script and pass the whole script to the R Console. scores &lt;- rnorm(1000, mean = 75, sd = 5.8) plot(density(scores)) hist(scores) boxplot(scores) Exercise 2.2 Find the answer to the following mathematical calculation with R. \\(2^{2+1}-4+64^{(-2)^{2.25-\\frac{1}{4}}}\\) = 16777220 2.5 Assignment R works with objects of many different classes, some of which are defined in the base R while others are defined by specific libraries/environments/users. You can assign any object created in R to a variable name using &lt;-: x &lt;- 5 y &lt;- &quot;wonderful&quot; Now the objects are stored in the variables. You can print out the variables by either making use of the auto-printing (i.e., the variable name itself auto-prints its content) or print(): x [1] 5 print(x) [1] 5 y [1] &quot;wonderful&quot; print(y) [1] &quot;wonderful&quot; 2.6 Data Structure In R, the most primitive object is a vector. There are three types of primitive vectors: (a) numeric, (b) character, and (c) Boolean vectors. In our previous examples, x is a numeric vector of one element; y is a character vector of one element. The following code shows an example of a Boolean vector z. z &lt;- TRUE z [1] TRUE All elements in the vector have to be of the same data type. The vectors we’ve created so far are vectors of only ONE ELEMENT. You use c() to create a vector of multiple elements. Within the parenthesis, you concatenate each element of the vector by ,: x2 &lt;- c(1, 2, 3, 4, 5, 6) x2 [1] 1 2 3 4 5 6 y2 &lt;- c(&quot;wonderful&quot;, &quot;excellent&quot;, &quot;brilliant&quot;) y2 [1] &quot;wonderful&quot; &quot;excellent&quot; &quot;brilliant&quot; z2 &lt;- c(TRUE, FALSE, TRUE) z2 [1] TRUE FALSE TRUE Other data structures that we often work with include: List: a vector-like structure, but can consist of elements of different data types Matrix: a two-dimensional vector, where all elements have to be of the same data type Data Frame: a spreadsheet-like table, where columns can be of different data types ex_list &lt;- list(&quot;First element&quot;, 5:10, TRUE) print(ex_list) [[1]] [1] &quot;First element&quot; [[2]] [1] 5 6 7 8 9 10 [[3]] [1] TRUE ex_array &lt;- matrix(c(1,5,6,3,8,19),byrow = T, nrow = 2) ex_array [,1] [,2] [,3] [1,] 1 5 6 [2,] 3 8 19 ex_df &lt;- data.frame( WORD = c(&quot;the&quot;, &quot;boy&quot;, &quot;you&quot;,&quot;him&quot;), POS = c(&quot;ART&quot;,&quot;N&quot;,&quot;PRO&quot;,&quot;PRO&quot;), FREQ = c(1104,35, 104, 34) ) ex_df The following graph shows you an intuitive understanding of the data structures in R. We will discuss more on data structures in Chapter 4. 2.7 Function Function is also an object class. There are many functions pre-defined in the R-base libraries. class(c) [1] &quot;function&quot; class(vector) [1] &quot;function&quot; class(print) [1] &quot;function&quot; To instruct R to do things more precisely, a function call usually has many parameters to specify. Take the earlier function matrix() for example. It is a pre-defined function in the R base library. ex_array &lt;- matrix(c(1,5,6,3,8,19),byrow = T, nrow = 2) ex_array [,1] [,2] [,3] [1,] 1 5 6 [2,] 3 8 19 When creating a matrix, we specify the values for the parameters, byrow = and nrow =. These specifications provide clues for R to create a matrix with N rows and arrange the numbers by rows. The actual values of the parameters that we use, i.e., T and 2, are referred to as arguments. Parameter is a variable in the declaration of function. Argument is the actual value of this variable that gets passed to function. Most importantly, we can define our own function, which is tailored to perform specific tasks. All self-created functions need to be defined first in the R environment before you can call them. Define own functions: print_out_user_name &lt;- function(name = &quot;&quot;){ cat(&quot;The current username is: &quot;, name, &quot;\\n&quot;) } Call own functions: print_out_user_name(name = &quot;Alvin Cheng-Hsien Chen&quot;) The current username is: Alvin Cheng-Hsien Chen print_out_user_name(name = &quot;Ada Lovelace&quot;) The current username is: Ada Lovelace Exercise 2.3 Please define a function called make_students_happy(), which takes a multi-element numeric vector, and returns also a numeric vector, with the value of each element to be the square root of the original value multiplied by 10. student_current_scores &lt;- c(20, 34, 60, 87, 100) make_students_happy(old_scores = student_current_scores) [1] 44.72136 58.30952 77.45967 93.27379 100.00000 2.8 Vectorization Many operations in R are vectorized, meaning that operations occur in parallel in certain R objects. This allows you to write code that is efficient, concise, and easier to read than in non-vectorized languages. The simplest example of vectorized functions is when adding two vectors together. x &lt;- 1:4 y &lt;- 6:9 z &lt;- x + y z [1] 7 9 11 13 Without vectorization, you may need to do the element-wise vector adding as follows: z &lt;- numeric(length = length(x)) for(i in 1:length(x)){ z[i] &lt;- x[i]+y[i] } # endfor z [1] 7 9 11 13 Other common vectorized functions include: x &gt;= 5 [1] FALSE FALSE FALSE FALSE x &lt; 2 [1] TRUE FALSE FALSE FALSE y == 8 [1] FALSE FALSE TRUE FALSE For more information on vectorization, please watch the following YouTube clip from Roger Peng. 2.9 Script In our earlier demonstrations, we ran R codes by entering each procedure line by line. We can create one script file with the Editor of Rstudio and include all our R codes in the file, which usually has the file extension of .R. And then we can run all commands included in the whole script all at once in the Rstudio (i.e., sending everything in the script file to the R console). First you open the *.R script file in Rstudio, which should appear in the Editor frame of the Rstudio. To run the whole script from start to the end, select all lines in the script file and press ctrl/cmd + shift + enter. To run a particular line of the script, put your mouse in the line and press ctrl/cmd + enter. 2.10 Library R, like other programming languages, comes with a huge database of packages and extensions, allowing us to do many different tasks without worrying about writing the codes all from the scratch. In CRAN Task Views, you can find specific packages that you need for particular topics/tasks. To install a package (i.e., library): install.packages(&quot;tidyverse&quot;) install.packages(c(&quot;ggplot2&quot;, &quot;devtools&quot;, &quot;dplyr&quot;)) In this course, I would like to recommend all of you to install the package tidyverse, which is a bundle including several useful packages for data analysis. During the installation, if you are asked about whether to install the package from source, please enter yes (See below for more detail). During the R package installation, if you see messages like installation of package XXX had non-zero exit status, this indicates that the package has NOT been properly installed in your R environment. That is, something is WRONG (See below as well). You need to figure out a way to solve the issues indicated in the error messages so that you can successfully install the package in your R system. Before you install R packages from source, you need to install a few R tools for your operating system. These tools are necessary for you to build the R packages from the source. For MacOS Catalina users, please install the following applications on your own. They are necessary for building R packages from source. Command Line Tools for Xcode 11.X You may need to log in with your Apple ID and find the download page. clang7/8 from https://cran.r-project.org/bin/macosx/tools/ gfortran6.1 from https://cran.r-project.org/bin/macosx/tools/ For Windows users, please install Rtools from CRAN (Please install the version according to your R version). After you install all the above source-building tools, you can now install the package tidyverse from source. Please install the package from the source. This step is very important because some of the dependent packages require you to do so. However, for the other packages, I would still recommend you to install the packages in a normal way, i.e., installing NOT from source, but from the compiled version on CRAN. 2.11 Setting Always set your default encoding of the files to UTF-8: 2.12 Seeking Help In the process of (learning) programming, one thing you will never be able to dodge is feeling desperate for help. Here are some useful sources from which you may get additional assistance. Within Rstudio, in the R console, you can always use ? to check the documentation of a particular function (cf. Figure 2.2). When you run the command, you will see the documentation popping up in the output frame of the Rstudio. ?log ?read.table Figure 2.2: Help 1 If you need help from others, the first step is to create a reproducible example. The goal of a reproducible example is to package your problematic code in such a way that other people can run it and feel your pain. Then, hopefully, they can provide a solution and put you out of your misery. Figure 2.3: Help 2 So before you seek help from others (or before you yell at others for help, cf. Figure 2.3) : First, you need to make your code reproducible. This means that you need to capture everything, i.e., include any library() calls and create all necessary objects (e.g., files). The easiest way is to check the objects listed in the Environment tab of the Rstudio and identify objects that are relevant to your problematic code chunk. Second, you need to make it minimal. Strip away everything that is not directly related to your problem. This usually involves creating a much smaller and simpler R object than the one you’re facing in real life or even using built-in data. That sounds like a lot of work! And it can be, but it has a great payoff: 80% of the time creating an excellent reproducible example reveals the source of your problem. It’s amazing how often the process of writing up a self-contained and minimal example allows you to answer your own question. The other 20% of time you will have captured the essence of your problem in a way that is easy for others to play with. This substantially improves your chances of getting help! The following is a list of resources where people usually get external assistance quickly: http://www.r-project.org/mail.html http://stackoverflow.com/ Quick R: http://www.statmethods.net/ R CRAN Task Views: https://cran.r-project.org/web/views/ R for Data Science Text Mining with R R communities: R-Bloggers: https://www.r-bloggers.com/ kaggle: https://www.kaggle.com/ stackoverflow: https://stackoverflow.com/questions/tagged/r rstudio: https://community.rstudio.com/ 2.13 Language Learning Ain’t Easy! Learning R is like learning another foreign language. It is a long journey. You can’t expect yourself to learn all the vocabulary of the new language in one day. Also, you will forget things you learn all the time. Everyone’s been there. When your script does not work as expected, don’t be frustrated. Take a break and resume later. What I can say is that: it is always NORMAL to debug a script for hours or even days via endless searches on Google. That being said, here I would like to share with you some of the most common problems we may run into: You created an R script file (*.r) and opened it in the Rstudio, but the script didn’t work simply because you didn’t execute the script in R console (i.e., you didn’t send the script to R console.) If you get an error message, saying \"object not found\", check the object name again and see if you have mistyped the name of the object. If not, check your current environment and see if you have forgot to execute some assignment commands in the previous parts of the script (i.e., the object has NOT even been created yet). If you get an error message, saying \"function not found\", check the function and see if you have the correct name. Or more often, check if you have properly loaded the necessary libraries where the function is defined. To understand the meaning of the error messages is crucial to your development of R proficiency. To achieve this, you have to know very well every object name you have created in your script (as well as in your environment). For example: What type of object is it? (i.e., the class of the object, e.g., vector, list, data.frame?) For primitive vectors, what data type does the vector belong to? (e.g., numeric, character, boolean,factor?) What is the dimensionality of the object? (nrows, ncols?) Sometimes the script fails simply because of the obvious syntactic errors. Pay attention to all the punctuations in every R command. They are far more important (or lethal) than you think. They include: ,: commas between arguments inside a function \": quotes for strings/characters (): parentheses for functions {}: curly brackets for control structures From my experiences, about 80 percent of the errors may in the end boil down to a simple typo. No kidding. Copy-and-paste helps. DO NOT assume that your R script always works as intended! Always keep two questions in mind: Did R produce the intended result? What is included in the R object name? 2.14 Keyboard Shortcuts The best way to talk to a computer is via the keyboard. Scripting requires a lot of typing. Keyboard shortcuts may save you a lot of time. Here are some of the handy shortcuts: Crtl/Command + Enter: run the current line (send from the script to the console) Crtl/Command + A: select all Crtl/Command + C: copy Ctrl/Command + X: cut Ctrl/Command + V: paste Ctrl/Command + Z: undo (Mac) Alt/Option + Left/Right: move cursor by a word (Windows) Ctrl + Left/Right: move cursor by a word (Mac) Command + Left/Right: move cursor to the beginning/end of line (Windows) Home/End: move cursor to the beginning/end of line (Mac) Command + Tab: switch in-between different working windows/apps Ctrl/Command + S: save file Command + Shift + C: comment/uncomment selected lines Exercise 2.4 Make yourself familiar with the iris data set, which is included in R. Exercise 2.5 Use ? to make youself familiar with the following commands: str,summary, dim, colnames, names, nrow, ncol, head, and tail. What information can you get with all these commands? Exercise 2.6 Write a function to compute the factorial of a non-negative integer, x, expressed as x!. The factorial of x refers to x multiplied by the product of all integers less than x, down to 1. For example, 3! = 3 x 2 x 1 = 6. The special case, zero factorial is always defined as 1. Confirm that your function produce the same results as below: 5! = 120 120! = 6.689503e+198 0! = 1 # A Sample Format for your Function myfac &lt;- function(x){ } ##(i) myfac(5) [1] 120 ##(ii) myfac(12) [1] 479001600 ##(iii) myfac(0) [1] 1 "],["code-format-convetion.html", "Chapter 3 Code Format Convention 3.1 Assignment &lt;- 3.2 Comment # 3.3 Script Naming 3.4 Object Naming 3.5 Whitespace 3.6 Indention and Linebreaks 3.7 More References 3.8 Template for Script Assignments", " Chapter 3 Code Format Convention Like the first time we learn English writing, we need to know the conventional writing styles and formats in coding as well. This is very important because scripts of good formats would increase their readability. This would save us a lot of time in case of future debugging and maintenance. This chapter will discuss common practices among most R users. 3.1 Assignment &lt;- In R, people normally use &lt;- to assign values to object names. In other languages such as Python, people often use =. Although R still understands the value-assignment when you use =, I would still suggest to use &lt;- just to avoid the chance of confusing your R. x1 &lt;- &quot;This is a sentence.&quot; x2 = &quot;This is a sentence.&quot; x1 [1] &quot;This is a sentence.&quot; x2 [1] &quot;This is a sentence.&quot; 3.2 Comment # When you write codes, you would need to commit your code extensively. This is very important because we often forget why and how we write it this way. In your R script, any strings after the # will be treated as comments, which will NOT be processed by R. We can often add additional - and = after the # to separate different code chunks. # ==================== # Variable Assignment # ==================== x &lt;- &quot;This is a sentence&quot; # ==================== # Variable Printing # ==================== x [1] &quot;This is a sentence&quot; 3.3 Script Naming When you name your R script files, don’t be TOO creative. Use meaningful strings. Most importantly, use alphanumeric characters ONLY. Never use Chinese characters. For multiword names, it is suggested to connect words with -. # Recommended my-first-script.R my-first-assignment.R # NOT Recommended my first script.R 語料庫assingment1.R 3.4 Object Naming In your script, you will create lots of objects. Spend some time thinking about how to name all these objects. Choose names that are intuitive and meaningful. It is often the case that you want to keep the names simple (as typing is really annoying) but easy to understand as well. There are some principles: Use nouns for the object names (e.g., PTT_corpus) Use verbs for the function names (e.g., generate_ngrams()) Connect multiword names with _ (e.g., PTT_corpus_segmented) Avoid using characters/strings that have been used by R (e.g., vector, c, mean, sum, T etc.) 3.5 Whitespace For operators (i.e., =, +, -, &lt;-), they are usually embraced by white spaces, which would make your script easier to read: # Recommended grade_average &lt;- mean(midterm * 0.5 + final * 0.5) # NOT Recommended grade_average&lt;-mean(midterm*0.5+final*0.5) For : and ::, usually we do not put white spaces around them: # Recommended x &lt;- c(1:10) tidyr::separate() # NOT Recommended x &lt;- c(1 : 10) tidyr :: separate() : is an expression in R to create a sequence of numbers. For example, c(1:10) is the same as c(1,2,3,4,5,6,7,8,9,10). :: is an expression to access a particular object/function from a library without having the entire library loaded in your current R environment. For example, tidyr::separate() calls the function separate() from the library tidyr but the other objects in tidyr are still NOT included. You cannot use the other objects defined in tidyr. For parentheses (, if it is in the control structure, we usually put a white space before the initial (: # for-loop for (i in 1:10){ print(i) } [1] 1 [1] 2 [1] 3 [1] 4 [1] 5 [1] 6 [1] 7 [1] 8 [1] 9 [1] 10 # if-conditional x &lt;- 2 if (x == 1){ print(&quot;The answer is 1!&quot;) } else { print(&quot;The answer is greater than 1!&quot;) } [1] &quot;The answer is greater than 1!&quot; But if the parenthesis is in the function call (i.e., where we specify the arguments of the parameters), we don’t put a white space before the initial (: mean(x) ggplot(aes(x = money, y = achievement)) For curly brackets, we usually put a line break after the initial { and the ending } should be one single line. Also, as sometimes you would embed many different control structures at the same time, leading to many ending } lines, it is always good to commit properly which ending } goes with which control structure. for (i in 1:10) { if (i &lt; 5){ print(i) } else { print(i+10) } #endif } #endfor [1] 1 [1] 2 [1] 3 [1] 4 [1] 15 [1] 16 [1] 17 [1] 18 [1] 19 [1] 20 3.6 Indention and Linebreaks R does not care about line breaks, white spaces, or tabs in your R script. But these formatting characters are important because you need all these characters to help you quickly keep track of the script’s structure. Make good use of the indention to increase the readability of your script. long_function_name &lt;- function(a = &quot;a long argument&quot;, b = &quot;another argument&quot;, c = &quot;another long argument&quot;) { # As usual code is indented by two spaces. } y &lt;- matrix(data = c(2,5,7,8), # data source nrow = 2, # two rows byrow = TRUE) # filling values by row y [,1] [,2] [1,] 2 5 [2,] 7 8 3.7 More References Readability of your code is an art. Please consult the following recommended readings if you are interested in more principles of clean code. 3.8 Template for Script Assignments When you submit your R scripts, please follow the format specified below. Important notes include: Please include the practice codes discussed in each chapter. Please specify the start and end of each of your exercise solution. Please indicate very clearly the chapter number and title as well as the exercise number in your script. Please name your R script as follows: ch2-alvin.R, ch3-alvin.R Please provide your descriptions/explanations in comments # (when you are asked to get familiar with packages, functions, or data sets). Finally, in case that you still don’t know where to find the exercises for assignments, please look for the exercise green box in each chapter (see below). All exercises are numbered. Exercise 3.1 This is a demo of the Exercise Box you would look for in each chapter. "],["subsetting.html", "Chapter 4 Subsetting 4.1 Vector 4.2 Factor 4.3 List 4.4 Data Frame 4.5 Tibble", " Chapter 4 Subsetting Subsetting is very important. To subset is to select a particular subset of elements from a data structure (e.g., vector, matrix, data.frame, list). In Chapter 2, we discuss very briefly about data structures. Here we will look at each type of data structure in more detail and introduce ways of subsetting them. 4.1 Vector As we have shown in Chapter 2 R Fundamentals, there are three types of primitive vectors in R: character vectors numeric vectors Boolean vectors You can access a particular subset of a vector by using[ ] right after the object name. Within the [], you can make use of at least three types of indexes: Subsetting with numeric index char.vec &lt;- c(&quot;one&quot;, &quot;two&quot;, &quot;three&quot;,&quot;four&quot;, &quot;five&quot;) char.vec[1] [1] &quot;one&quot; You can also retrieve several elements from a vector all at once, using a numeric vector as the indices, c(), in the []: char.vec[c(1,4)] [1] &quot;one&quot; &quot;four&quot; Subsetting with Boolean index You can also use a Boolean vector as the index: whether.to.extract &lt;- c(TRUE, FALSE, TRUE, FALSE, FALSE) char.vec[whether.to.extract] [1] &quot;one&quot; &quot;three&quot; You may use different logical operators to check each element of the vector according to some criteria. R will decide whether elements of the vector satisfy the condition given in the logical expression and return a Boolean vector of the same length. Common logical operators include: ==: equal to &amp;: and |: or &gt;: greater than &gt;=: greater than or equal to &lt;: less than &lt;=: less than or equal to !=: not equal This can be very useful for vector subsetting: num.vec &lt;- c(1:20) num.vec &gt; 10 [1] FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE TRUE TRUE [13] TRUE TRUE TRUE TRUE TRUE TRUE TRUE TRUE num.vec[num.vec &gt; 10] [1] 11 12 13 14 15 16 17 18 19 20 num.vec[num.vec != 10] [1] 1 2 3 4 5 6 7 8 9 11 12 13 14 15 16 17 18 19 20 num.vec[num.vec &gt; 18 | num.vec &lt; 2] [1] 1 19 20 Subsetting with negative numeric index If you use negative numbers in the index [], you will get a new vector printed on the console, with those indexed elements removed: char.vec[-2] [1] &quot;one&quot; &quot;three&quot; &quot;four&quot; &quot;five&quot; However, please note that the original vector is still the same in length: char.vec [1] &quot;one&quot; &quot;two&quot; &quot;three&quot; &quot;four&quot; &quot;five&quot; If you want to save the shortened vector, you can either (a) assign the shortened vector to a new object name or (b) assign the shortened vector to the same object name: char.vec.short &lt;- char.vec[-2] char.vec.short [1] &quot;one&quot; &quot;three&quot; &quot;four&quot; &quot;five&quot; char.vec [1] &quot;one&quot; &quot;two&quot; &quot;three&quot; &quot;four&quot; &quot;five&quot; char.vec &lt;- char.vec[-2] char.vec [1] &quot;one&quot; &quot;three&quot; &quot;four&quot; &quot;five&quot; For the two alternatives, which one would be better? Why? Exercise 4.1 Create a vector m with the small letters from a to j (in an alphabetical order). hint: check the object letters in R. m [1] &quot;a&quot; &quot;b&quot; &quot;c&quot; &quot;d&quot; &quot;e&quot; &quot;f&quot; &quot;g&quot; &quot;h&quot; &quot;i&quot; &quot;j&quot; Exercise 4.2 Create a vector n with the small letters from a to j (in a random order). hint: check sample(). Also, your results may vary (because of the random ordering of the letters). n [1] &quot;e&quot; &quot;h&quot; &quot;d&quot; &quot;i&quot; &quot;c&quot; &quot;a&quot; &quot;b&quot; &quot;g&quot; &quot;f&quot; &quot;j&quot; Exercise 4.3 Determine whether letters in n (i.e., the one with the random order) are at the same positions as in m (i.e., the one with the alphabetical order). How many such cases do you find? Which letters are these? hint: check table() FALSE TRUE 9 1 [1] &quot;j&quot; 4.2 Factor In Chapter 2, we did not talk about this data structure –factor. There is an obvious reason for that. A factor is very similar to a vector in R. One of the key features for a factor is that its values are limited to a finite number of distinct categories (i.e., levels). In many statistical experimental designs, a factor is usually a grouping factor, i.e., a factor that groups the subjects into sub-groups. We usually create a factor from a numeric or character vector. To create a factor, use factor(): sbj_gender_num &lt;- c(1, 0, 0, 1, 1, 0, 1) sbj_gender_num [1] 1 0 0 1 1 0 1 sbj_gender_num_fac &lt;- factor(x = sbj_gender_num) sbj_gender_num_fac [1] 1 0 0 1 1 0 1 Levels: 0 1 But please note that the numbers that you see in a factor do not represent numeric values. Instead, they are labels in the form of digits. sbj_gender_char &lt;- c(&quot;female&quot;,&quot;male&quot;,&quot;male&quot;,&quot;female&quot;,&quot;female&quot;,&quot;male&quot;,&quot;female&quot;) sbj_gender_char [1] &quot;female&quot; &quot;male&quot; &quot;male&quot; &quot;female&quot; &quot;female&quot; &quot;male&quot; &quot;female&quot; sbj_gender_char_fac &lt;- factor(x = sbj_gender_char) sbj_gender_char_fac [1] female male male female female male female Levels: female male For a factor, the most important information is its levels, i.e., the limited set of all possible values this factor can take. We can extract the levels as a vector of character strings using levels(): levels(sbj_gender_num_fac) [1] &quot;0&quot; &quot;1&quot; levels(sbj_gender_char_fac) [1] &quot;female&quot; &quot;male&quot; When do we need a factor? In data annotation, we often use arbitrary numbers as labels for certain categorical variables. For example, we may use arbitrary numbers from 1 to 4 to label learners’ varying proficiency levels: 1 = beginners, 2 = low-intermediate, 3 = upper-intermediate, 4 = advanced. When we load the data into R, R may first treat the data as a numeric vector: sbj_prof_num&lt;- c(1, 2, 4, 4, 2, 3, 3, 1, 1) sbj_prof_num [1] 1 2 4 4 2 3 3 1 1 However, these numbers may be confusing: R may even consider them really to be numbers and perform unnecessary mathematical computations on them; They are not semantically transparent because numbers do not have meanings. In this case, we can convert the numeric vector into a factor and re-label these numeric values as categorical labels that are more semantically transparent. We can do this by setting more arguments in factor(), such as levels=..., labels=.... sbj_prof_fac &lt;- factor(x = sbj_prof_num, levels = c(1:4), labels = c(&quot;beginner&quot;,&quot;low-inter&quot;,&quot;upper-inter&quot;,&quot;advanced&quot;)) sbj_prof_fac [1] beginner low-inter advanced advanced low-inter upper-inter [7] upper-inter beginner beginner Levels: beginner low-inter upper-inter advanced levels = ...: this argument specifies all possible values this factor can take labels = ...: this argument provides own intuitive labels for each level It should now therefore be clear that labels = ... is a good way for us to re-label any arbitrary annotations into meaningful labels. In addition, we can decide whether the ranking of the levels is meaningful. If the order of the levels of the factor is meaningful, we can set the argument ordered = TRUE: sbj_prof_fac_ordered &lt;- factor(x = sbj_prof_num, levels = c(1:4), labels = c(&quot;beginner&quot;,&quot;low-inter&quot;,&quot;upper-inter&quot;,&quot;advanced&quot;), ordered = T) sbj_prof_fac_ordered [1] beginner low-inter advanced advanced low-inter upper-inter [7] upper-inter beginner beginner Levels: beginner &lt; low-inter &lt; upper-inter &lt; advanced Now from the R console we can see not only the levels of the factor but also the signs &lt;, indicating their order. Using this ordered factor, we can perform relational comparison: sbj_prof_fac_ordered[1] [1] beginner Levels: beginner &lt; low-inter &lt; upper-inter &lt; advanced sbj_prof_fac_ordered[4] [1] advanced Levels: beginner &lt; low-inter &lt; upper-inter &lt; advanced sbj_prof_fac_ordered[1] &lt; sbj_prof_fac_ordered[4] [1] TRUE But we cannot do the comparison for unordered factors (characters neither): sbj_prof_fac[1] [1] beginner Levels: beginner low-inter upper-inter advanced sbj_prof_fac[4] [1] advanced Levels: beginner low-inter upper-inter advanced sbj_prof_fac[1] &lt; sbj_prof_fac[4] Warning in Ops.factor(sbj_prof_fac[1], sbj_prof_fac[4]): &#39;&lt;&#39; not meaningful for factors [1] NA The difference between vector and factor may look trivial for the moment but they are statistically very crucial. The choice of whether to instruct R to treat a vector as a factor, or even an ordered factor, will have important consequences in the implementation of many statistical methods, such as regression or other generalized linear modeling. Rule of thumb: Always pay attention to what kind of object class you are dealing with:) 4.3 List A List is like a vector, which is a one-dimensional data structure. However, the main difference is that a List can include a series of objects of different classes: # A list consists of (i) numeric vector, (ii) character vector, (iii) Boolean vector list.example &lt;- list(&quot;one&quot; = c(1,2,3), &quot;two&quot; = c(&quot;Joe&quot;, &quot;Mary&quot;, &quot;John&quot;,&quot;Angela&quot;), &quot;three&quot; = c(TRUE, TRUE)) list.example $one [1] 1 2 3 $two [1] &quot;Joe&quot; &quot;Mary&quot; &quot;John&quot; &quot;Angela&quot; $three [1] TRUE TRUE Please note that not only the class of each object in the List does not have to be the same; the length of each list element may also vary. You can subset a List in two ways: [...]: This always returns a List back [[...]]: This returns the object of the List element, which is NOT NECESSARILY a List list.example[1] $one [1] 1 2 3 list.example[[1]] [1] 1 2 3 list.example[[&quot;one&quot;]] [1] 1 2 3 We can also subset a List by the names of its elements. Before you try the following codes in the R console, could you first predict the outputs? ind &lt;- c(&quot;one&quot;, &quot;three&quot;) list.example[ind] list.example[[ind]] Exercise 4.4 Create a list that contains, in this order: a sequence of 20 evenly spaced numbers between -4 and 4; (hint: check seq()) a 3 x 3 matrix of the logical vector c(F,T,T,T,F,T,T,F,F) filled column-wise; a character vector with the two strings “don”, and “quixote”; a factor containing the observations c(\"LOW',\"MID\",\"LOW\",\"MID\",\"MID\",\"HIGH\"). [[1]] [1] -4.0000000 -3.5789474 -3.1578947 -2.7368421 -2.3157895 -1.8947368 [7] -1.4736842 -1.0526316 -0.6315789 -0.2105263 0.2105263 0.6315789 [13] 1.0526316 1.4736842 1.8947368 2.3157895 2.7368421 3.1578947 [19] 3.5789474 4.0000000 [[2]] [,1] [,2] [,3] [1,] FALSE TRUE TRUE [2,] TRUE FALSE FALSE [3,] TRUE TRUE FALSE [[3]] [1] &quot;don&quot; &quot;quixote&quot; [[4]] [1] LOW MID LOW MID MID HIGH Levels: HIGH LOW MID Exercise 4.5 Based on Exercise ??, extract row elements 2 and 1 of columns 2 and 3, in that order, of the logical matrix. [,1] [,2] [1,] FALSE FALSE [2,] TRUE TRUE Exercise 4.6 Based on Exercise ??, obtain all values from the sequence between -4 and 4 that are greater than 1. [1] 1.052632 1.473684 1.894737 2.315789 2.736842 3.157895 3.578947 4.000000 Exercise 4.7 Make yourself familiar with the function which(). Based on Exercise ??, using which(), determine which indexes in the factor are assigned the “MID” level. [1] 2 4 5 4.4 Data Frame A data.frame is the most frequently used object that we will work with in data analysis. It is a typical two-dimensional spreadsheet-like table. Normally, the rows are the subjects or tokens we are analyzing; the columns are the variables or factors we are interested in. We can also use [... , ... ] to subset a data frame. The indexes in [... , ...] are Row-by-Column. ex_df &lt;- data.frame( WORD = c(&quot;the&quot;, &quot;boy&quot;, &quot;you&quot;,&quot;him&quot;), POS = c(&quot;ART&quot;,&quot;N&quot;,&quot;PRO&quot;,&quot;PRO&quot;), FREQ = c(1104,35, 104, 34) ) ex_df You can subset a particular row of the data frame: ex_df[1,] ex_df[c(1,3),] You can subset a particular column of the data frame: ex_df[,1] [1] &quot;the&quot; &quot;boy&quot; &quot;you&quot; &quot;him&quot; ex_df[,c(1,3)] ex_df[,c(&quot;WORD&quot;,&quot;FREQ&quot;)] Please compare the following two ways of accessing a column from the data frame. Can you tell the differences in the returned results? ex_df[, c(&quot;FREQ&quot;)] ex_df[, c(&quot;FREQ&quot;), drop = FALSE] Exercise 4.8 Create and store the following data frame as dframe in your R workspace. person should be a character vector sex should be a factor with levels F and M funny should be a factor with levels Low, Mid, and High Exercise 4.9 Stan and Francine are 41 years old, Steve is 15, Hayley is 21, and Klaus is 60. Roger is extremely old–1,600 years. Following Exercise ??, append these data as a new numeric column variable in dframe called age. Exercise 4.10 Following Exercise ??, write a single line of code that will extract from dframe just the names and ages of any records where the individual is male and has a level of funniness equal to Low OR Mid. 4.5 Tibble A tibble is a new data structure with lots of advantages. For the moment, we treat tibble and data.frame as the same structures, with the former being an augmented version of the latter. In fact, almost all functions that work with a data.frame are compatible with a tibble. Now the tibble is the major structure that R users work with under the tidy framework. If you are interested in the power of tibbles, the best place to start with is the chapter on Tibbles in R for data science. require(tibble) ex_tb &lt;- tibble( WORD = c(&quot;the&quot;, &quot;boy&quot;, &quot;you&quot;,&quot;him&quot;), POS = c(&quot;ART&quot;,&quot;N&quot;,&quot;PRO&quot;,&quot;PRO&quot;), FREQ = c(1104,35, 104, 34)) ex_tb There is another way to create a tibble. You can use tribble(), short for transposed tibble. tribble() is customized for data entry in code: column headings are defined by formulas (i.e. they start with ~); entries are separated by commas. This makes it possible to lay out small amounts of data in easy-to-read form. ex_tb_2 &lt;- tribble( ~WORD, ~POS, ~FREQ, #----|--------|------ &quot;the&quot;, &quot;ART&quot;, 1104, &quot;boy&quot;, &quot;N&quot;, 35, &quot;you&quot;, &quot;PRO&quot;, 104, &quot;him&quot;, &quot;PRO&quot;, 34 ) ex_tb_2 You can subset a tibble in exactly the same ways as you work with a data.frame: ex_tb[1,] ex_tb[,1] ex_tb[,c(1:3)] Exercise 4.11 Please compare again the following codes and see if you can tell the major differences between tibble and data.frame? ex_tb[,c(&quot;FREQ&quot;)] # indexing tibble ex_df[,c(&quot;FREQ&quot;)] # indexing data.frame [1] 1104 35 104 34 There are three major advantages with tibble() when compared with data.frame(): A tibble set strings to default to character vectors while data.frame(, stringsAsFactors = T) converts all character vectors to factors by default When auto-printing the contents, tibble would only display the first ten rows, but data.frame would print out everything. This could be devastating! (Imagine that you have a table with hundreds of thousands rows.) The auto-printing of the tibble is a lot more informative, providing additional attributes of the tibble such as (a) row and column numbers and (b) data type of each column Exercise 4.12 Download the csv file, data-word-freq.csv from the DEMO_DATA Dropbox Drive and load the CSV data into R using two different functions: the default read.csv() and the read_csv from the readr package. Please discuss the differences of the objects loaded from these two methods. ## Please download the csv file from `DEMO_DATA` drive wf_df = read.csv( file = &#39;demo_data/data-word-freq.csv&#39;, stringsAsFactors = T) str(wf_df) &#39;data.frame&#39;: 3135 obs. of 3 variables: $ WORD : Factor w/ 2476 levels &quot;__add__&quot;,&quot;__dict__&quot;,..: 2213 1633 2213 1804 1510 171 82 82 1510 171 ... $ CORPUS: Factor w/ 2 levels &quot;perl&quot;,&quot;python&quot;: 1 1 2 2 1 1 1 2 2 2 ... $ FREQ : int 346 243 229 194 166 160 151 148 138 137 ... wf_df require(readr) ## you may need to install this package wf_tb = readr::read_csv( file = &#39;demo_data/data-word-freq.csv&#39;) wf_tb "],["conditions-and-loops.html", "Chapter 5 Conditions and Loops 5.1 Conditions 5.2 if Statements 5.3 for 5.4 while loop 5.5 Toy Example", " Chapter 5 Conditions and Loops When you start to write more sophisticated programs with R, you will very often need to control the flow and order the execution in your code. You will usually run into two types of scenarios: Make the execution of a particular code chunk dependent on a condition (i.e., an expression that evaluates to TRUE or FALSE) Repeat a particular code chunk a certain number of times, which is often referred to as loops. In this Chapter, we will explore these core programming techniques using: if-else statements for and while loops However, in Chapter 11, we will talk about loops more and point you to the idiomatic ways of dealing with loops in R. 5.1 Conditions Before we talk about the flow controls, let’s deal with the more fundamental element of the control structures: what is a condition? To that end, let’s first explore a few important concepts: Boolean Values Comparison Operators Boolean Operators 5.1.1 Boolean Values Unlike numbers or characters, the Boolean data type has only two values, TRUE and FALSE. In R, the Boolean values TRUE and FALSE lack the quotes you place around strings, and they are always uppercase. cond1 &lt;- TRUE class(cond1) [1] &quot;logical&quot; 5.1.2 Comparison Operators Comparison Operators are important in programming. They compare two values and evaluate down to a single Boolean value. They are also referred to as relational operators. Comparison Operators in R Operator Meaning == Equal to != Not equal to &gt; Greater than &lt; Less than &gt;= Greater than or equal to &lt;= Less than or equal to X %in% Y X Is an member of Y These comparison operators return TRUE or FALSE depending on the values we give them. 45 == 45 [1] TRUE 45 &gt; 50 [1] FALSE 45 != 4 [1] TRUE Please note that these operators work not only with numbers but also characters as well. a &lt;- &quot;run&quot; b &lt;- &quot;run&quot; c &lt;- &quot;walk&quot; all &lt;- c(&quot;run&quot;,&quot;walk&quot;,&quot;march&quot;) a == b [1] TRUE a == c [1] FALSE c %in% all [1] TRUE When using comparison operators, be careful of the data types (i.e., numeric or character). a &lt;- &quot;42&quot; b &lt;- 42 a == 42.0 [1] TRUE a &gt; 40 [1] TRUE a == b [1] TRUE Please note the difference between == and =. The == operator asks whether two objects are the same as each other while the = operator assigns the value/object on the right into the variable name on the left. In R, the preferred way of assignment is to use &lt;- operator instead. 5.1.3 Boolean Operators There are three Boolean operators in R to compare two conditions: &amp; (and), | (or), and ! (not). That is, we can combine two or more conditions with these operators for more complex conditions. x &lt;- 47 x &gt; 30 | x &lt; 50 [1] TRUE x &lt;- 55 x &gt; 30 &amp; x &lt; 50 [1] FALSE x &lt;- 55 x &gt; 50 [1] TRUE !x &gt; 50 [1] FALSE 2 + 2 == 4 &amp; 2 + 2 == 5 &amp; 2 * 2 == 2 + 2 [1] FALSE 2 + 2 == 4 &amp; !2 + 2 == 5 &amp; 2 * 2 == 2 + 2 [1] TRUE The Boolean operators follow the order of operations in math. That is, R evaluates the ! (not) operator first, then the &amp; (and) operator, and then the | (or) operators. 5.1.4 Elements of Flow Control Flow control statements often start with a condition and are followed by a block of code. A quick recap: Conditions: Any Boolean expressions can be a potential condition, which evaluates down to a Boolean value (i.e., TRUE or FALSE). A flow control statement decides what to do and what to skip based on whether the condition is TRUE or FALSE. Block of Code: Lines of R code can be grouped together in blocks, using initial and ending curly brackets { and }. The beginning and ending of the block of code are clearly indicated. 5.2 if Statements The main purpose of if is to control precisely which operations are carried out in a given code chunk. An if statement runs a code chunk only if a certain condition is true. This conditional expression allows R to respond differently depending on whether the condition is TRUE or FALSE. The basic template of if is as follows: if(CONDITION IS TRUE){ DO THIS CODE CHUNK 1 } else { DO THIS CODE CHUNK 2 } The condition is placed in the parenthesis after if within (). The condition must be an expression that returns only a single logical value (TRUE or FALSE). If it is TRUE, the code chunk 1 in the curly braces will be executed; if the condition is not satisfied, the code chunk 2 in the curly braces after else will be executed. Let’s create a simple example simulating the password checking. Imagine that your system password is stored on the server. You can only get into the system if you enter the correct password. For every password you enter, the system gatekeeper will check if your input password matches the one stored on the server. If it does not match, you will be banned from entry. input &lt;- 113 # assuming that you have the input 113 ## Assuming that the system pass code is `987` if(input == 987){ writeLines(&quot;Congratulations! Now you may get in!&quot;) } else{ writeLines(&quot;Sorry! Wrong password.&quot;) } Sorry! Wrong password. If the input matches with the system pass code, you will be allowed to get through. input &lt;- 987 # assuming that you have the input 987 if(input == 987){ writeLines(&quot;Congratulations! Now you may get in!&quot;) } else{ writeLines(&quot;Sorry! Wrong password.&quot;) } Congratulations! Now you may get in! Now we can ask R to read the input directly from the user’s input in the R console: input &lt;- readline(prompt=&quot;Please enter your password:&quot;) if(input == 987){ writeLines(&quot;Congratulations! Now you may get in!&quot;) } else { writeLines(&quot;Sorry! Wrong password.&quot;) } In R, there are two very similar functions, readline() and readLines(). Please check the documentations of these two to make sure you understand their differences. 5.3 for The for loop statement is to repeat a code chunk, often while incrementing an index or a counter. The most frequent scenario is to repeat a code chunk through a vector/list, element by element, or through a data frame row by row (or column by column). The basic for loop template is as follows: for(LOOP_INDEX in LOOP_VECTOR){ DO THIS CODE CHUNK } The LOOP_INDEX is a placeholder that represents an element in the LOOP_VECTOR. When the loop begins, the LOOP_INDEX starts off as the first element in the LOOP_VECTOR. When the loop reaches the end of the brace, the LOOP_INDEX is incremented, taking on the next element in the LOOP_VECTOR. This process continues until the loop reaches the final element of the LOOP_VECTOR. At this point, the code chunk is executed for the last time, and the loop exits. For example, if we have a character vector with a few words in it. We can use a for loop to get the number of characters for each element in the vector. word_vec &lt;- c(&quot;apple&quot;,&quot;banana&quot;,&quot;watermelon&quot;,&quot;papaya&quot;) for(w in word_vec){ word_nchar &lt;- nchar(w) writeLines(as.character(word_nchar)) } 5 6 10 6 For the above example, there is another way to write the for loop: for(i in 1:length(word_vec)){ word_nchar &lt;- nchar(word_vec[i]) writeLines(as.character(word_nchar)) } 5 6 10 6 ## Comparing results with `print` # for(i in 1:length(word_vec)){ # word_nchar &lt;- nchar(word_vec[i]) # print(as.character(word_nchar)) # } In our first example, the LOOP_INDEX serves as the exact object in the LOOP_VECTOR. In our second example, the LOOP_INDEX serves as the index of the object in the LOOP_VECTOR. Please note that the control structures are to direct the flow of execution of the codes. Therefore, the control structure itself DOES NOT return any object. That is, you CANNOT assign a for-loop structure to an object. It is NOT meaningful and grammatical. The following code chunk would give you an error. ####################################################### ## WARNING!!! This code chunk is UNGRAMMATICAL!!!!!! ## ####################################################### numOfChars &lt;- for(i in 1:length(word_vec)){ word_nchar &lt;- nchar(word_vec[i]) writeLines(as.character(word_nchar)) } Exercise 5.1 Use the data set from stringr::sentences for this exercise. Create a for-loop structure to get the number of characters for all sentences in the stringr::sentences. Present your results in a data frame of three columns: Column 1 includes an unique integer ID for each sentence; Column 2 includes the texts of each sentence; Column 3 includes the number of characters of each sentence. Note: A for-loop structure is needed for this exercise. But it may not necessarily be the most efficient way. The data set stringr::sentences includes 720 English sentences. The first six sentences are shown here. [1] &quot;The birch canoe slid on the smooth planks.&quot; [2] &quot;Glue the sheet to the dark blue background.&quot; [3] &quot;It&#39;s easy to tell the depth of a well.&quot; [4] &quot;These days a chicken leg is a rare dish.&quot; [5] &quot;Rice is often served in round bowls.&quot; [6] &quot;The juice of lemons makes fine punch.&quot; Your results may look like the following data frame: Exercise 5.2 Use the data set stringr::fruit for this exercise. Create a for-loop and if-statement to instruct R to go through each fruit name and print out those fruit names that start with the vowel letters only (i.e., a, e, i, o, u). [1] &quot;apple&quot; [1] &quot;apricot&quot; [1] &quot;avocado&quot; [1] &quot;eggplant&quot; [1] &quot;elderberry&quot; [1] &quot;olive&quot; [1] &quot;orange&quot; [1] &quot;ugli fruit&quot; 5.4 while loop There is another type of loop. Unlike the for loop, which repeats a code chunk by going through every element in a vector/list/data frame, the while loop repeats a code chunk UNTIL a specific condition evaluates to FALSE (It’s like the opposite of if-statement) The basic template is as follows: while(LOOP_CONDITION){ DO THIS CODE CHUNK (UNTIL THE LOOP_CONDITION BECOMES FALSE) } Upon the start of a while loop, the LOOP_CONDITION is evaluated. If the condition is TRUE, the braced code chunk is executed line by line till the end of the chunk. At this point, the LOOP_CONDITION will be checked again. The loop terminates immediately when the condition is evaluated to be FALSE. Based on the template above, it is important to note that the code chunk executed must somehow cause the loop to exit. In particular, the code chunk needs to change the values of certain objects, which would eventually lead to the change of the LOOP_CONDITION. If nothing ever changes the LOOP_CONDITION, R will crash due to the infinite loops. Let’s come back to our password checker. This time let’s create a dumb checker. When you give a wrong password which is smaller than the true passcode, it will automatically approach the right answer for you (and of course no real-world application would do that!) ans &lt;- 90 guess &lt;- 83 while(guess != ans){ cat(&quot;Your `guess` is too small! \\nThe system will take care for you!\\n&quot;) guess &lt;- guess + 1 cat(&quot;Now the system is adjusting your `guess` to &quot;, guess, &quot;\\n\\n&quot;) } Your `guess` is too small! The system will take care for you! Now the system is adjusting your `guess` to 84 Your `guess` is too small! The system will take care for you! Now the system is adjusting your `guess` to 85 Your `guess` is too small! The system will take care for you! Now the system is adjusting your `guess` to 86 Your `guess` is too small! The system will take care for you! Now the system is adjusting your `guess` to 87 Your `guess` is too small! The system will take care for you! Now the system is adjusting your `guess` to 88 Your `guess` is too small! The system will take care for you! Now the system is adjusting your `guess` to 89 Your `guess` is too small! The system will take care for you! Now the system is adjusting your `guess` to 90 cat(&#39;Great! The passcode is finally cracked.\\n&#39;) Great! The passcode is finally cracked. Exercise 5.3 In the above example, if the guess is smaller than ans, our script works fine. However, if the guess is larger than ans, then our script will crash. How to fix it? In other words, a revised script should produce the following results when guess=83 &lt; ans=90: Your `guess` is too small! The system will take care for you! Now the system is adjusting your `guess` to 84 Your `guess` is too small! The system will take care for you! Now the system is adjusting your `guess` to 85 Your `guess` is too small! The system will take care for you! Now the system is adjusting your `guess` to 86 Your `guess` is too small! The system will take care for you! Now the system is adjusting your `guess` to 87 Your `guess` is too small! The system will take care for you! Now the system is adjusting your `guess` to 88 Your `guess` is too small! The system will take care for you! Now the system is adjusting your `guess` to 89 Your `guess` is too small! The system will take care for you! Now the system is adjusting your `guess` to 90 And your script should produce the following results when guess=100 &gt; ans=90: Your `guess` is too large! The system will take care for you! Now the system is adjusting your `guess` to 99 Your `guess` is too large! The system will take care for you! Now the system is adjusting your `guess` to 98 Your `guess` is too large! The system will take care for you! Now the system is adjusting your `guess` to 97 Your `guess` is too large! The system will take care for you! Now the system is adjusting your `guess` to 96 Your `guess` is too large! The system will take care for you! Now the system is adjusting your `guess` to 95 Your `guess` is too large! The system will take care for you! Now the system is adjusting your `guess` to 94 Your `guess` is too large! The system will take care for you! Now the system is adjusting your `guess` to 93 Your `guess` is too large! The system will take care for you! Now the system is adjusting your `guess` to 92 Your `guess` is too large! The system will take care for you! Now the system is adjusting your `guess` to 91 Your `guess` is too large! The system will take care for you! Now the system is adjusting your `guess` to 90 5.5 Toy Example Now we are playing the Guess Game. The game is as follows: The program will pick a random number from 1 to 100. A user has to guess which number the computer has picked. Every time the user makes a wrong guess, the computer will tell the user whether the correct answer is higher or lower. We first pack the game as an R function object: guessMyNumber &lt;- function(){ ## Randomly select an integer from 1 to 100 ans &lt;- sample(1:100, size = 1) ## Instructions for user print(&quot;Now I am thinking of a number between 1 and 100.&quot;) ## Read the prompt input from user guess &lt;- readline(prompt = &quot;Please guess my number(1~100):&quot;) ## Convert input string into integer guess &lt;- as.numeric(guess) ## As long as user&#39;s guess is not the answer while(guess != ans){ ## if user&#39;s guess is smaller than the answer if(guess &lt; ans){ writeLines(&quot;The answer is HIGHER.&quot;) guess &lt;- readline(prompt = &quot;Please guess my number(1~100):&quot;) guess &lt;- as.numeric(guess) ## if user&#39;s guess is larger than the answer }else{ writeLines(&quot;The asnwer is LOWER&quot;) guess &lt;- readline(prompt = &quot;Please guess my number(1~100):&quot;) guess &lt;- as.numeric(guess) } } ## Exit the While-loop writeLines(paste0(&quot;Good Job! You had the correct answer! My number is &quot;, guess)) } # endfunc After you load the above code chunk and create the guessMyNumber() function in your current R environment, you can play the game by running the function guessMyNumber(): guessMyNumber() Exercise 5.4 The above guessMyNumber() can be improved. Sometimes naughty (careless) users would not input numbers as requested. Instead, they may accidentally (or on purpose) enter characters that are NOT digits at all in their guesses. How can you adjust the guessMyNumber() so that when users enter non-digit characters, your program will send out a warning message automatically? An example output from the revised version is provided below. &gt; guessMyNumber_v2() Please guess my number(0~100):12 The asnwer is HIGHER. Please guess my number(0~100):80 The asnwer is LOWER Please guess my number(0~100):1000 The asnwer is LOWER Please guess my number(0~100):a &lt;WARNING&gt;Please behave. Enter an INTEGER!!!&lt;WARNING&gt; Please guess my number(0~100):df &lt;WARNING&gt;Please behave. Enter an INTEGER!!!&lt;WARNING&gt; Please guess my number(0~100):`13` &lt;WARNING&gt;Please behave. Enter an INTEGER!!!&lt;WARNING&gt; Please guess my number(0~100):frw &lt;WARNING&gt;Please behave. Enter an INTEGER!!!&lt;WARNING&gt; Please guess my number(0~100):50 The asnwer is LOWER Please guess my number(0~100):30 The asnwer is HIGHER. Please guess my number(0~100):40 The asnwer is HIGHER. Please guess my number(0~100):45 The asnwer is LOWER Please guess my number(0~100):43 The asnwer is LOWER Please guess my number(0~100):42 The asnwer is LOWER Please guess my number(0~100):41 Correct! "],["functions.html", "Chapter 6 Functions 6.1 A Quick Start 6.2 Why do we need functions? 6.3 Functions with parameters 6.4 Recap of Important Concepts So Far 6.5 RETURN Statements 6.6 Parameters Order 6.7 Stacking Functions 6.8 Local and Global Scope 6.9 Exception Handling", " Chapter 6 Functions We have been using R functions in the default base R package, such as c(), list(), sample(). R provides a lot of useful built-in functions like these, but we can write our own task-specific functions as well. A function is like a mini-program within a program. In this unit, we discuss how to write functions in R. 6.1 A Quick Start To better understand how a function works, let’s create a simple one. The following code chunk creates a function object, named hello. hello &lt;- function() { print(&quot;How are you doing?&quot;) } A function object includes several important elements: We use the function() to define a new function object. After the function() is the code in the block ({...}), which is the body of the function. Every function is assigned to a user-defined name (e.g., hello in the above example.) After the function is defined, the code in the body of the function will be executed every time when the function object is called. hello() [1] &quot;How are you doing?&quot; hello() [1] &quot;How are you doing?&quot; 6.2 Why do we need functions? A major advantage of creating functions in our programs is to group codes that get executed multiple times. Without a function defined, one may need to copy-and-paste same code chunks many times. Second, with functions, it is easier to update the programs. We often try to avoid duplicating code because if we need to update the code (e.g., to fix a bug in the original code), we don’t have to change the code everywhere we have copied it. In short, functions can greatly reduce the chances of duplicating code, rendering the programs shorter, easier to read and update. 6.3 Functions with parameters When we use the built-in R functions like cat(), length(), or matrix(), we can pass them values, called arguments, in the parentheses. That is, some functions have parameters and users can pass values to each parameter as arguments. In our self-defined functions, we can also define a function which accepts arguments. hello &lt;- function(name) { cat(&quot;How are you doing,&quot;, name) } hello(name = &quot;Alvin&quot;) How are you doing, Alvin The new hello() function has a parameter called name. Parameters are variables that expect arguments in the function call. When a function is called with an argument (e.g., Alvin), this argument is stored in the parameter (e.g., name). More specifically, when the function hello(name = 'Alvin') is called: The argument Alvin is assigned to the parameter name; The program then continues the code block of the function; Within the code block, the parameter name is automatically set to Alvin. It is important to note that the value stored in the parameter is forgotten when the function returns. That is, we cannot access the parameter name in the main program: cat(name) Error in cat(name): object &#39;name&#39; not found In short, the parameters of a function are destroyed after a function call hello(name = 'Alvin') returns. 6.4 Recap of Important Concepts So Far To utilize a function object, there are several key steps: We need to define the function by creating it using hello &lt;- function(){...} and assigning it with an object name like any other objects in R. Then we can call the now-created function using hello(). The function call will start the execution of the code block in the function by first passing or assigning the arguments/values to the parameters within the function (e.g., hello(name = 'Alvin')). A value being passed to a function in a function call is an argument, (e.g., Alvin) Variables that have arguments assigned to them are parameters, (e.g., name =). 6.5 RETURN Statements When we define a function, we can specify what the return values should be using the return() statement. The returned values can be assigned to another object for later use in the program. In R, there are many built-in functions that return values: num &lt;- sample(1:10, 3) num [1] 3 5 8 When a function returns nothing, by default the return value of the function is NULL, which is a unique data type in R referring to NoneType. out &lt;- cat(&quot;This is a sentence&quot;) # `cat()` has no return This is a sentence out NULL Now how about the hello() function we created earlier? We didn’t specify the return() statement in the function definition. out &lt;- hello(name = &quot;John&quot;) How are you doing, John out NULL In the definition of hello(), we did not specify the return() statement; therefore, by default, this function returns NULL. But how come we can still see the outputs of the function? In the code block of hello() definition, the cat() displays text on the R console only. Therefore, displaying texts in the R console and returning the values are two different things. Exercise 6.1 Without any change of the function, hello(), how can we assign the values printed in the console by hello() to an object out? That is, how can you modify the following code chunk so that out can store the values printed by hello(name=\"Alvin\")? out &lt;- hello(name=&quot;Alvin&quot;) out Exercise 6.2 Can you try to create a revised version of hello(), which returns the strings so that one can assign the outputs of the hello() to another object name? (Please note that in the following example, the return value out is not a NULL anymore.) out &lt;- hello2(name = &quot;Alvin&quot;) out [1] &quot;How are you doing, Alvin&quot; hello2(name = &quot;John&quot;) [1] &quot;How are you doing, John&quot; 6.6 Parameters Order We’ve seen functions with parameters. When a function has many parameters, there are two alternatives to assign the arguments to the parameters in the function call. First, we can assign the arguments to the parameters specified in the function call: set.seed(123) sample(x = c(1:10), size = 5, replace = FALSE, prob = NULL) [1] 3 10 2 8 6 Alternatively, we can assign the arguments to the parameters according to the order of the parameters in th function definition without specifying the parameter names: set.seed(123) sample(c(1:10), 5, FALSE, NULL) [1] 3 10 2 8 6 In the function definition, we can also assign default values to the parameters. For example, in the documentation of sample(x, size, replace = FALSE, prob = NULL), we can see that the parameters replace= and prob= have default values. That means in the function call we can use these default values as the arguments without specifying them in the call. sample(c(1:10), 5) [1] 5 4 6 8 1 6.7 Stacking Functions A function can also call another function within its code block. If Function A calls Function B in its code block, the execution would return to Function B first, before returning from the original function call. For example, let’s define two functions, hello() and email(). It is clear to see that within the code block of hello(), we have a function call of email(). That is, the latter is embedded in the former. hello &lt;- function(name) { user_email &lt;- email(user = name) out &lt;- paste0(&quot;How are you doing, &quot;, name, &quot;. &quot;, user_email) return(out) } email &lt;- function(user) { out &lt;- paste0(&quot;Your email is: &quot;, tolower(user), &quot;@whatever.org&quot;) return(out) } When hello() is called, it calls email() first and returns the user’s email address. Once execution returns to the code in hello() that called email(), it returns to the line in hello() that called email(). Then the execution continues to the end of hello(). hello(&quot;Alvin&quot;) [1] &quot;How are you doing, Alvin. Your email is: alvin@whatever.org&quot; With this embedding structure, we can create effective functions for more sophisticated tasks. 6.8 Local and Global Scope Now we know in our main program, we can define functions to accomplish specific tasks and these functions can be used multiple times to reduce code duplication. Variables that are assigned in a called function are said to exist in that function’s local scope. These variables are referred to as local variables. Variables that are assigned outside all functions are said to exist in the global scope. These variables are referred to as global variables. A scope is like the life-span of the variable. A local scope is created whenever a function is called. Any variables assigned in the function exist within the function’s local scope. When the function returns, the local scope is destroyed, and these local variables are forgotten (i.e., removed from the memory of the current working environment). The global scope is created when the main program starts. When the program terminates, the global scope is destroyed, and all the global variables are forgotten. There are a few important considerations for variable scope: Code in the global scope (i.e., outside of all functions) cannot use any local variables (i.e., variables within functions). Code in a local scope can access global variables. Code in a function’s local scope cannot use variables in any other local scope. We can use the same name for different variables if they are in different scopes (e.g., they can be local variables within different functions). In small programs, using global variables within functions is fine . But it is a bad habit to rely on global variables when your program gets larger and larger. The following code chunk shows that local variables cannot be used in the global scope. customer &lt;- function() { id = 123 age = 25 nation = &quot;TW&quot; } customer() cat(id) Error in cat(id): argument 1 (type &#39;closure&#39;) cannot be handled by &#39;cat&#39; The following code chunk shows that local scopes cannot use variables in other local scopes. customer &lt;- function() { id = 123 age = 25 nation = &quot;TW&quot; print(age) } client &lt;- function() { age = 50 } customer() # returning `age` from `customer()` not from `client()` [1] 25 The following code chunk shows a local scope can access global variables. customer &lt;- function() { age = 25 cat(&quot;The customer works at&quot;, company) } company &lt;- &quot;NTNU&quot; customer() The customer works at NTNU Technically, it is OK to use the same variable name for a global variable and local variable in different scopes. But to make your life easier, please avoid doing this. customer &lt;- function() { age &lt;- 25 cat(age) } client &lt;- function() { age &lt;- 55 cat(age) } age &lt;- 100 customer() 25 client() 55 cat(age) 100 6.9 Exception Handling A good function handles exceptions properly so that the main program would not be terminated by unexpected errors from the function. For example, if we create a function myLog(), which takes a number and computes the log value of the number with the specified base. myLog &lt;- function(x, myBase) { return(log(x, myBase)) } myLog(100, 10) [1] 2 myLog(8, 2) [1] 3 There are a few cases where the return values may be problematic: myLog(10, -1) # base is negative Warning in log(x, myBase): NaNs produced [1] NaN myLog(-10, 10) # x is negative Warning in log(x, myBase): NaNs produced [1] NaN myLog(&quot;100&quot;, 10) # x is not numeric Error in log(x, myBase): non-numeric argument to mathematical function To make sure that the function myLog() does not terminate the main program when encountering errors or warnings, it is often a good idea to include exception handling in the function code block. In R, tryCatch() function can help deal with (both expected or unexpected) errors and warnings. Its structure is as follows: result = tryCatch({ expr }, warning = function(w) { warning-handler-code }, error = function(e) { error-handler-code }, finally = { cleanup-code }) tryCatch() includes the following important elements: expr: the expression/code to be evaluated. warning: When the expr causes a warning, the program execution immediately moves to the code in the warning code block. error: When the expr causes an error, the program execution immediately moves to the code in the error code block. Now let’s try to include tryCatch() in our code block of the function myLog(): myLog &lt;- function(x, myBase) { tryCatch({ return(log(x, myBase)) }, warning = function(w) { if (x &lt; 0) print(&quot;x needs to be a positive number&quot;) if (myBase &lt; 0) print(&quot;myBase needs to be a positive number&quot;) }, error = function(e) { if (!is.numeric(x) | !is.numeric(myBase)) print(&quot;x/myBase needs to be a positive number not a string&quot;) }, finally = { }) } myLog(10, -1) [1] &quot;myBase needs to be a positive number&quot; myLog(&quot;w12&quot;, 0) [1] &quot;x/myBase needs to be a positive number not a string&quot; myLog(8, &quot;2&quot;) [1] &quot;x/myBase needs to be a positive number not a string&quot; Exercise 6.3 Create a function that produces a simple animation, i.e., the zigzag outputs as shown below. The function will slowly create a back-and-forth zigzag pattern with the laps and the indent size as the parameters of the function. Alternatively, users can stop the animation anytime by pressing CTRL+C. zigzag(lap = 5, indent_max = 10) Please note that the user can interrupt the program/function by pressing CTRL+C and your function should stop properly (using tryCatch). Exercise 6.4 Create a simple function to play rock, paper, scissors with the user. Your program should achieve the following: Invite the user to make a move with text inputs (i.e., rock, paper, or scissors). The program randomly makes a move. The program makes sure that the user can only make legitimate moves. The program reports the result of each hand game (i.e., win, lose, or tie) The user can continue playing the game until they indicate quitting. Upon user’s quitting of the game, the program reports the total results of all the games, in terms of the number of the user’s wins, loses, and ties. An example of how the function works is provided below. "],["data-visualization.html", "Chapter 7 Data Visualization 7.1 Why Visualization? 7.2 ggplot2 7.3 Variables and Data Type 7.4 One-variable Graph 7.5 Two-variable Graph 7.6 Adding More Aesthetic Features or Layers 7.7 Saving Plots 7.8 Exercises on iris 7.9 Exercises on COVID-19", " Chapter 7 Data Visualization 7.1 Why Visualization? Data visualization is very important. I would like to illustrate this point with two interesting examples. 7.1.1 Datasaurus Dozen Dataset First, let us take a look at an interesting dataset—Datasaurus, which is available in demo_data/data-datasaurus.csv (source: Datasaurus data package. This data set was first created by Alberto Cairo). Table 7.1: An Interesting Dataset group x y dino 95.38460 36.794900 dino 98.20510 33.718000 away 91.63996 79.406603 away 82.11056 1.210552 h_lines 98.28812 30.603919 h_lines 95.24923 30.459454 v_lines 89.50485 48.423408 v_lines 89.50162 45.815179 x_shape 84.84824 95.424804 x_shape 85.44619 83.078294 star 82.54024 56.541052 star 86.43590 59.792762 high_lines 92.24840 32.377154 high_lines 96.08052 28.053601 dots 77.92604 50.318660 dots 77.95444 50.475579 circle 85.66476 45.542753 circle 85.62249 45.024166 bullseye 91.72601 52.623353 bullseye 91.73554 48.970211 slant_up 92.54879 42.901908 slant_up 95.26053 46.008830 slant_down 95.44349 36.189702 slant_down 95.59342 33.234129 wide_lines 77.06711 51.486918 wide_lines 77.91587 45.926843 This data set includes 1846 rows (items), with three columns describing the properties of the items: group, x and y. As we have a grouping factor group, we can break the data set into several subsets by group and for each subset we compute their respective mean scores and standard deviations of x and y. According to the summary statistics of each sub-group (cf. Table 7.2), they all look quite similar in terms of each group’s mean and standard deviation of x and y: Table 7.2: An Interesting Dataset - Summary group x_mean y_mean x_sd y_sd away 54.266 47.835 16.770 26.940 bullseye 54.269 47.831 16.769 26.936 circle 54.267 47.838 16.760 26.930 dino 54.263 47.832 16.765 26.935 dots 54.260 47.840 16.768 26.930 h_lines 54.261 47.830 16.766 26.940 high_lines 54.269 47.835 16.767 26.940 slant_down 54.268 47.836 16.767 26.936 slant_up 54.266 47.831 16.769 26.939 star 54.267 47.840 16.769 26.930 v_lines 54.270 47.837 16.770 26.938 wide_lines 54.267 47.832 16.770 26.938 x_shape 54.260 47.840 16.770 26.930 So it may be tempting for us to naively conclude that all groups show similar behaviors in x and y measures. But what if we plot all items according to their x and y values by group ? See? When we visualize our data, sometimes the patterns reveal themselves. What you see in numbers may sometimes be very misleading. 7.1.2 Simpson’s Paradox Another example is Simpson’s Paradox, which refers to a statistical phenomenon where an association between two variables in a population emerges, disappears or reverses when the population is divided into sub-groups. For example, the following graph shows the association/correlation between x and y for the entire population. Based on the above graph, you would probably conclude that when x increases, y decreases. That is, the correlation analysis suggests a negative relationship between x and y when the entire population is analyzed as a whole. However, if we plot the scatter plots by groups (i.e., a Z grouping factor), you may get the opposite conclusions. All correlations between x and y in each sub-group are now positive. That is, the association you observe in the population now is reversed in each sub-group. 7.2 ggplot2 R is famous for its power in data visualization. In this chapter, I will introduce you a very powerful graphic library in R, ggplot2. For any data visualization, there are three basic elements: Data: The raw material of your visualization, i.e., a data frame. Aesthetics: The mapping of your data to aesthetic attributes, such as x, y, color, size, linetype, fill. Geometric Objects: The layers of geometric objects you would like to include on the plots, e.g., lines, points, bars, boxplots, etc. I will demonstrate some basic functions of ggplot2, with the pre-loaded dataset mpg: library(tidyverse) mpg For data visualization, the first step is to know your dataset, i.e., the meanings of rows and columns. In the dataset mpg, each row refers to a car and the columns include: model: manufacturer model name displ: engine displacement, in litres (排氣量) hwy: highway miles per gallon cty: city miles per gallon cyl: number of cylinders (汽缸數目) class: car type drv: the type of drive train, where f = front-wheel drive (前輪驅動), r = rear wheel drive (後輪驅動), 4 = 4wd (四輪傳動) There are two very useful functions for exploration of a data frame: str() and summary(). str(mpg) tibble [234 × 11] (S3: tbl_df/tbl/data.frame) $ manufacturer: chr [1:234] &quot;audi&quot; &quot;audi&quot; &quot;audi&quot; &quot;audi&quot; ... $ model : chr [1:234] &quot;a4&quot; &quot;a4&quot; &quot;a4&quot; &quot;a4&quot; ... $ displ : num [1:234] 1.8 1.8 2 2 2.8 2.8 3.1 1.8 1.8 2 ... $ year : int [1:234] 1999 1999 2008 2008 1999 1999 2008 1999 1999 2008 ... $ cyl : int [1:234] 4 4 4 4 6 6 6 4 4 4 ... $ trans : chr [1:234] &quot;auto(l5)&quot; &quot;manual(m5)&quot; &quot;manual(m6)&quot; &quot;auto(av)&quot; ... $ drv : chr [1:234] &quot;f&quot; &quot;f&quot; &quot;f&quot; &quot;f&quot; ... $ cty : int [1:234] 18 21 20 21 16 18 18 18 16 20 ... $ hwy : int [1:234] 29 29 31 30 26 26 27 26 25 28 ... $ fl : chr [1:234] &quot;p&quot; &quot;p&quot; &quot;p&quot; &quot;p&quot; ... $ class : chr [1:234] &quot;compact&quot; &quot;compact&quot; &quot;compact&quot; &quot;compact&quot; ... summary(mpg) manufacturer model displ year Length:234 Length:234 Min. :1.600 Min. :1999 Class :character Class :character 1st Qu.:2.400 1st Qu.:1999 Mode :character Mode :character Median :3.300 Median :2004 Mean :3.472 Mean :2004 3rd Qu.:4.600 3rd Qu.:2008 Max. :7.000 Max. :2008 cyl trans drv cty Min. :4.000 Length:234 Length:234 Min. : 9.00 1st Qu.:4.000 Class :character Class :character 1st Qu.:14.00 Median :6.000 Mode :character Mode :character Median :17.00 Mean :5.889 Mean :16.86 3rd Qu.:8.000 3rd Qu.:19.00 Max. :8.000 Max. :35.00 hwy fl class Min. :12.00 Length:234 Length:234 1st Qu.:18.00 Class :character Class :character Median :24.00 Mode :character Mode :character Mean :23.44 3rd Qu.:27.00 Max. :44.00 To begin with, I like to use one simple example to show you how we can create a plot using ggplot2. With the dataset mpg, we can look at the relationship between displ and hwy: whether the engine displacement has to do with the car miles per gallon. We can draw a scatter plot as shown below. ggplot(data = mpg, aes(x = displ, y = hwy)) + geom_point() A ggplot object often includes lat least three important components: ggplot() initializes the basic frame of the graph, with data = mpg specifying the data frame on which the plot is built aes() further specifies the mapping of axises and the factors in the data frame. aes(x = displ, y = hwy) indicates that displ is mapped as the x axis and hwy as y axis + means that you want to add one layer of the graph to the template. geom_point() means that you want to add a layer of point graph. 7.3 Variables and Data Type When creating the graphs for your data, you need to know very well the data type of all the variables to be included in the graph. There are at least three important data types you need to know: Categorical variables: these variables usually have only limited set of discrete values, i.e., levels. They are usually coded as character vector or factor in R. Numeric variables: these variables are continuous numeric values. They are usually coded as numeric vector. Date-Time variables: these variables, although being numeric sometimes, refer to calendar dates or times. They are usually coded as Date-TimeClasses in R. The general principle in data visualization is that always pay attention to the data type for variables on the x-axis and y-axis. 7.4 One-variable Graph If your graph includes only one variable from the data, usually this would indicate that you are interested in the distribution of the variable. 7.4.1 Continuous Variable Histogram Density plot ggplot(data = mpg, aes(hwy)) + geom_histogram(color=&#39;white&#39;) ggplot(data = mpg, aes(hwy)) + geom_density(kernel=&quot;gaussian&quot;) We can also combine the histogram and density plots into one: Any thoughts about how to do that? The way we examine the distribution of the continuous variable (i.e., numbers) is to divide the entire range of values into a series of intervals, i.e., bins, and then count how many values in the data set fall into each interval. In other words, the shape of your histogram may vary depending on two parameters: Number of bins: the number of intervals you have Bin width: the size of each interval Changes of either of the parameters would lead to a histogram of a different shape. ggplot(data = mpg, aes(hwy)) + geom_histogram( color = &#39;white&#39;, fill = &#39;steelblue&#39;, alpha = 0.7, bins = 10 ) + scale_x_continuous(breaks = seq(10, 46, 1)) ggplot(data = mpg, aes(hwy)) + geom_histogram( color = &#39;white&#39;, fill = &#39;steelblue&#39;, alpha = 0.7, binwidth = 2 ) + scale_x_continuous(breaks = seq(10, 46, 1)) ## You can check the min or max of each bin g &lt;- ggplot(data = mpg, aes(hwy)) + geom_histogram(color = &quot;white&quot;) ## Auto-print the ggplot g ## Checking bin interval min and max ggplot_build(g)$data[[1]]$xmin [1] 11.58621 12.68966 13.79310 14.89655 16.00000 17.10345 18.20690 19.31034 [9] 20.41379 21.51724 22.62069 23.72414 24.82759 25.93103 27.03448 28.13793 [17] 29.24138 30.34483 31.44828 32.55172 33.65517 34.75862 35.86207 36.96552 [25] 38.06897 39.17241 40.27586 41.37931 42.48276 43.58621 ggplot_build(g)$data[[1]]$xmax [1] 12.68966 13.79310 14.89655 16.00000 17.10345 18.20690 19.31034 20.41379 [9] 21.51724 22.62069 23.72414 24.82759 25.93103 27.03448 28.13793 29.24138 [17] 30.34483 31.44828 32.55172 33.65517 34.75862 35.86207 36.96552 38.06897 [25] 39.17241 40.27586 41.37931 42.48276 43.58621 44.68966 7.4.2 Categorical Variable Bar plot ggplot(data = mpg, aes(x = class)) + geom_bar() When creating the bar plot, we can also use the normalized frequencies of each category, instead of the raw frequency counts. Any idea? Exercise 7.1 How can we create a bar plot as above but with the bars arranged according to the counts in a descending order from left to right? (see below) Hint: check reorder() 7.5 Two-variable Graph If your graph includes two variables, then very likely one variable would go to the x-axis and the other, y-axis. Depending on their data types (categorical or numeric), you may need to create different types of graphs. 7.5.1 Continuous X, Continuous Y Scatter Plot ggplot(data = mpg, aes(x = displ, y = hwy)) + geom_point() We can add a regression line to the scatter plot: ggplot(data = mpg, aes(x = displ, y = hwy)) + geom_point() + geom_smooth(method=&#39;lm&#39;, formula= y~x) 7.5.2 Categorical X, Continuous Y Boxplot ggplot(data = mpg, aes(x = class, y = hwy)) + geom_boxplot() If you would like to know more about boxplots, please check this blog post. The following illustration is taken from the blog post, which shows the meanings of different boxplot parts. Error Plot ggplot(data = mpg, aes(x = class, y = hwy)) + stat_summary(fun.data = mean_cl_boot, geom = &quot;pointrange&quot;) The functions, mean_cl_normal() and mean_cl_boot() are two wrappers around functions from Hmisc library. The mean_cl_normal() computes the mean and the confidence limits based on a t-distribution. As an alternative, mean_cl_boot would produce a less assumption laden bootstrapped confidence interval. ggplot(data = mpg, aes(x = class, y = hwy)) + stat_summary(fun.data = mean_cl_normal, geom = &quot;pointrange&quot;) If you run into problems plotting the error plot using stat_summary(), probably you did not have the necessary packages installed in your current R environment. Please make sure that you have installed the package tidyverse or ggplot2 properly without any error messages in the process of installation. Also, please note that you need to install the tidyverse from source. (For the other relevant packages, it is ok to install those packages in a normal way from CRAN). For more detail, please refer back to Chapter 2.10. 7.5.3 Categorical X, Categorical Y Bubble Plot Heatmap ggplot(data = mpg, aes(x = manufacturer, y = class)) + geom_count() + theme(axis.text.x = element_text(angle=-90)) We can also create a heatmap for two categorical variables: Exercise 7.2 Please create a heat map as shown above. In order to create a heat map, you may also need the frequency counts of each level combination. Also, please include these frequency counts in the heat map as well. Hint: geom_tile(); geom_text() 7.6 Adding More Aesthetic Features or Layers 7.6.1 color Now I would like to demonstrate how we can add additional aesthetic mappings to your graphs. Earlier we create a scatter plot using the following code: ggplot(data = mpg, aes(x = displ, y = hwy)) + geom_point() The above plot includes two variables into the graph, x = displ and y = hwy. The additional aesthetic features may include things like colors, sizes, shapes, line-types, widths etc. The idea is that we can introduce a third variable into the plot by modifying these aesthetic attributes based on the value of that third variable. For example, you can add color = ... in the aes(x = ..., y = ..., color = ...) to create the graphs on the basis of another grouping factor. ggplot(data = mpg, aes(x = displ, y = hwy, color = drv)) + geom_point() In the above example, color is an aesthetics (put in the aes()). This would suggest that the color of each point is now mapped to the variable drv. In this case, points belonging to different groups of drv would be of different colors—different drive train types have different colors in points. Note that the x-coordinates and y-coordinates are aesthetics too, and they are mapped to the displ and hwy variables, respectively. Now we enrich the graph by further mapping the color to the third variable drv, which indicates whether a car is front wheel drive, rear wheel drive, or 4-wheel drive. If you would like to know more about the color names available in R, I would highly recommend this R Color Cheat Sheet. Exercise 7.3 When creating a graph, the aesthetic feature color can also be specified within the geom_*() as well. Please compare the following two ways of color specification and describe their respective functional differences. ## Method 1 ggplot(data = mpg, aes(x = displ, y = hwy, color = drv)) + geom_point() ## Method 2 ggplot(data = mpg, aes(x = displ, y = hwy)) + geom_point(color = &quot;steelblue&quot;) 7.6.2 alpha Transparency (alpha) can sometimes be helpful in data visualization. ggplot(data = mpg, aes(x = displ, y = hwy, color = drv)) + geom_point(alpha = .5, size = 4) 7.6.3 size We can also map a grouping factor to the aesthetic feature size. That is, different groups will be represented by geometric objects of varying sizes. ggplot(data = mpg, aes(x = displ, y = hwy, size = drv, color= drv)) + geom_point(alpha = .5) 7.6.4 fill For bar plots or histograms, we can fill the bars with different colors by adding fill = ... in the aes(). ggplot(data = mpg, aes(x = class, fill= class)) + geom_bar(color=&#39;white&#39;) ggplot(data = mpg, aes(x = class, y = hwy, fill = class)) + geom_boxplot(color=&#39;black&#39;) 7.6.5 shape We can map a third variable to the graph using shape as well. ggplot(data = mpg, aes(x = displ, y = hwy, shape = drv)) + geom_point() And of course you can map both shape and color to the same third variable: ggplot(data = mpg, aes(x = displ, y = hwy, color = drv, shape=drv)) + geom_point() Exercise 7.4 In Section 7.5, we talked about how to create a bubble plot. ggplot(data = mpg, aes(x = manufacturer, y = class)) + geom_count() + theme(axis.text.x = element_text(angle=-90)) Please adjust the codes to create a similar bubble plot with not only the sizes but also the colors of the bubbles indicating the varying token numbers in each level combination. 7.6.6 Other geom_... Layers The ggplot object consists of layers of geometric objects. We can also add another geom_*() object, such as a smooth line by using the +: ggplot(data = mpg, aes(x = displ, y = hwy)) + geom_point() + geom_smooth(method = &quot;lm&quot;) Could you predict what kind of graph you would get with the following code? ggplot(data = mpg, aes(x = displ, y = hwy, color = drv)) + geom_point() + geom_smooth(method=&quot;lm&quot;) 7.6.7 Labels and Annotations We can add self-defined labels of the x and y axes and main titles to the graphs using labs(). ggplot(data = mpg, aes(x = displ, y = hwy)) + geom_point() + geom_smooth(method=&#39;lm&#39;) + labs(title = &quot;Correlation between Displacement and Highway Miles per Gallon&quot;, x = &quot;Displacement&quot;, y = &quot;Miles/Per Gallon&quot;) ggplot(data = mpg, aes(x = displ, y = hwy, color = drv)) + geom_point() + labs(x = &quot;Engine Displacement (litres)&quot;, y = &quot;Highway Miles per Gallon&quot;, title = &quot;Scatter Plot -- DISPL by HWY&quot;) 7.6.8 Facets Sometimes we may want to create plots based on a conditional factor. For example, we can check the relationship between cty and hwy for cars by different manufacturers. ggplot(data = mpg, aes(x = cty, y = hwy)) + geom_point() + geom_smooth(method = &quot;lm&quot;) + facet_wrap(vars(class)) Please check facet_grid() on your own. 7.6.9 Themes We can easily change the aesthetic themes of the ggplot by adding one layer of theme_*(). graph1 &lt;- ggplot(data = mpg, aes(x = displ, y = hwy, color = drv)) + geom_point() + labs(x = &quot;Engine Displacement (litres)&quot;, y = &quot;Highway Miles per Gallon&quot;, title = &quot;Scatter Plot -- DISPL by HWY&quot;) graph1 graph1 + theme_bw(base_family = &quot;Times New Roman&quot;) graph1 + theme_minimal() graph1 + theme_dark() graph1 + theme_classic() graph1 + theme_light() 7.7 Saving Plots Saving a ggplot can be easily done by ggsave(). You can first assign a ggplot object to a variable and then use ggsave() to output the ggplot object to an external file. It is recommended to use common image formats for publications, e.g., png, jpg. Also, please remember to set the width and height (in inches) of your graph. These settings will greatly affect the look of the graph in print. my_first_graph &lt;- ggplot(data = mpg, aes(x = displ, y = hwy, color = drv)) + geom_point() + labs(x = &quot;Engine Displacement (litres)&quot;, y = &quot;Highway Miles per Gallon&quot;, title = &quot;Scatter Plot -- DISPL by HWY&quot;) class(my_first_graph) # check the class [1] &quot;gg&quot; &quot;ggplot&quot; # summary(my_first_graph) # check the properties of the graph my_first_graph # auto-print the ggplot ggsave( filename = &quot;my_first_plot.png&quot;, plot = my_first_graph, width = 6, height = 6 ) Useful References The R Graph Gallery is a website where you can find lots of fancy graphs created with R. Most importantly, you can study their R codes and learn how to create similar fancy graphs with your own data. Highly recommend it!! The ggplot2 Official Documentation Website provides a comprehensive list of all functions included in the package. Very useful! R Graphics Cookbook, 2nd Edition is a great on-line book, which provides hundreds of examples of high-quality graphs produced with R. 7.8 Exercises on iris The following exercises will use the preloaded dataset iris in R. iris Exercise 7.5 Please create a scatter plot showing the relationship between Sepal.Length and Petal.Length for different iris Species. Also, please add the regression lines for each species. Your graph should look as close to the sample as possible. Exercise 7.6 Please create a boxplot showing the Petal.Width distributions of each iris Species. Exercise 7.7 Please create boxplots showing the distributions of Petal.Width and Sepal.Width of different iris Species on the same graph. Hint: You may need to transform your data into a longer format, as shown below, before you create the boxplot. See tidyr::pivot_longer(). Please work on this exercise when we finish Chapter 8. 7.9 Exercises on COVID-19 Please work on the exercises included this section after we finish the Chapter 8. (In other words, I may ask you to submit your assignments on these two chapters together.) The following exercises are based on a dataset downloaded from Kaggle. The dataset is also available in demo_data/data-covid19.csv. Exercise 7.8 Load the dataset in demo_data/data-covid19.csv into R as a data frame named covid19. Hint: Check readr::read_csv() Please note that in this dataset, the column Confirmed includes the cumulative numbers of confirmed cases on different days. These cumulative numbers allow us to keep track of the development of COVID-19. It is the same for the other columns as well (i.e., Deaths and Recovered). Also, for countries like Mainland China, the numbers are reported by Province/State. (Same for US as well). To get the total number of confirmed cases on a particular day for the entire country, you may need to sum up all the numbers in individual provinces first. Exercise 7.9 Use ggplot2 to create a line plot showing the number of confirmed cases by month for the following countries: Taiwan, Japan, US, UK, Germany, Netherlands, Mainland China. A sample graph is shown below. Exercise 7.10 Create a bar plot showing the top 10 countries ranked according to their number of confirmed cases of the COVID19. Exercise 7.11 Create a bar plot showing the top 10 countries ranked according to their death rates of the COVID19. (Death rates are defined as the number of deaths divided by the number of confirmed cases.) Exercise 7.12 (bonus) Create a world map showing the current outbreak of covid19. Hint: Please check ggplot2::geom_polygon() and the package library(maps). This exercise is made to see if you know how to find resources online for more complex tasks like this. Please note that the country names may not match. "],["data-manipulation.html", "Chapter 8 Data Manipulation 8.1 Dataset 8.2 rename() 8.3 Pipe %&gt;% 8.4 mutate() 8.5 select() 8.6 filter() 8.7 arrange() 8.8 group_by() and summarize() 8.9 count() 8.10 Tidy Data 8.11 Exercises", " Chapter 8 Data Manipulation In this chapter, we will be working with two powerful packages, dplyr and tidyr, which provide a consistent “grammar” for data manipulation and exploration by simplifying operations on data frames to a great deal. We first load the library: library(dplyr) library(tidyr) library(ggplot2) In the library dplyr, there are a list of key verbs: %&gt;%: the “pipe” operator is used to connect multiple verb actions together into a pipeline mutate(): add new variables/columns or transform existing variables select(): return a subset of the columns of a data frame, using a flexible notation filter(): extract a subset of rows from a data frame based on logical operators summarise(): generate summary statistics of different variables in the data frame, possibly within strata group_by(): group the data frame into sub-tables according to a grouping factor arrange(): reorder rows of a data frame (according to a particular variable) rename(): rename variables in a data frame Several useful functions for joining two data frames: inner_join() left_join() right_join() full_join() anti_join() Exercise 8.1 Please check the documentations of all the above functions of merging data frames and make sure you understand how two data frames are merged with each function. In the second library tidyr, we will focus on: pivot_longer(): to tidy the data from wide to long pivot_wider(): to tidy the data from long to wide 8.1 Dataset The dateaset we use in this chapter is a student performance dataset from kaggle. library(readr) student &lt;- read_csv(&quot;demo_data/data-students-performance.csv&quot;) student Usually we would start from an overview of the dataset, using summary() and str(): summary(student) gender race/ethnicity parental level of education Length:1000 Length:1000 Length:1000 Class :character Class :character Class :character Mode :character Mode :character Mode :character lunch test preparation course math score reading score Length:1000 Length:1000 Min. : 0.00 Min. : 17.00 Class :character Class :character 1st Qu.: 57.00 1st Qu.: 59.00 Mode :character Mode :character Median : 66.00 Median : 70.00 Mean : 66.09 Mean : 69.17 3rd Qu.: 77.00 3rd Qu.: 79.00 Max. :100.00 Max. :100.00 writing score Min. : 10.00 1st Qu.: 57.75 Median : 69.00 Mean : 68.05 3rd Qu.: 79.00 Max. :100.00 str(student) spc_tbl_ [1,000 × 8] (S3: spec_tbl_df/tbl_df/tbl/data.frame) $ gender : chr [1:1000] &quot;female&quot; &quot;female&quot; &quot;female&quot; &quot;male&quot; ... $ race/ethnicity : chr [1:1000] &quot;group B&quot; &quot;group C&quot; &quot;group B&quot; &quot;group A&quot; ... $ parental level of education: chr [1:1000] &quot;bachelor&#39;s degree&quot; &quot;some college&quot; &quot;master&#39;s degree&quot; &quot;associate&#39;s degree&quot; ... $ lunch : chr [1:1000] &quot;standard&quot; &quot;standard&quot; &quot;standard&quot; &quot;free/reduced&quot; ... $ test preparation course : chr [1:1000] &quot;none&quot; &quot;completed&quot; &quot;none&quot; &quot;none&quot; ... $ math score : num [1:1000] 72 69 90 47 76 71 88 40 64 38 ... $ reading score : num [1:1000] 72 90 95 57 78 83 95 43 64 60 ... $ writing score : num [1:1000] 74 88 93 44 75 78 92 39 67 50 ... - attr(*, &quot;spec&quot;)= .. cols( .. gender = col_character(), .. `race/ethnicity` = col_character(), .. `parental level of education` = col_character(), .. lunch = col_character(), .. `test preparation course` = col_character(), .. `math score` = col_double(), .. `reading score` = col_double(), .. `writing score` = col_double() .. ) - attr(*, &quot;problems&quot;)=&lt;externalptr&gt; 8.2 rename() The column names in student are a mess. These names include spaces in them, which would be difficult to index these columns in R. This is however normal in the real world, where the dataset we get is often very messy. So, the first thing we can do with the dataset is to rename all the column names in a R-compatible way. rename(student, race = `race/ethnicity`, parent_edu = `parental level of education`, prep_course = `test preparation course`, math = `math score`, reading = `reading score`, writing = `writing score`) -&gt; student1 student1 Please note that in our earlier code, we save the output of rename() to a new object named student1. In other words, the object student1 should contain a new data frame with all column names fixed as above. Most importantly, the original data frame student is still available in the working memory. 8.3 Pipe %&gt;% Now let’s look at a fantastic syntax in R, the pipe operator %&gt;%, which is definitely one of my favorite R idioms! To start with, the following two expressions are the same, giving you the same results: sum(c(1:10)) [1] 55 c(1:10) %&gt;% sum() [1] 55 The pipe operator %&gt;% passes the object returned by the expression on its left to the function on its right. That is, the meaning of %&gt;% is that the object on the left of the pipe is passed on to the right side of the pipe for further processing. By default, the object is passed onto to be the first argument of the function on the right-hand side. This pipe-based syntax would render the script more reader-friendly. For example, it is difficult to conceptualize the following code with several layers of embedding structures. sqrt(sum(abs(c(-10:10)))) [1] 10.48809 But the above code can be re-written with the %&gt;% as follows: source_data &lt;- c(-10:10) # create a vector source_data %&gt;% abs() %&gt;% # take each element&#39;s absolute value sum() %&gt;% # sum all elements sqrt() # take the square root of the sum [1] 10.48809 The pipe operators make the entire codes more human-readable. Now we understand the idiomatic expression of %&gt;%, our earlier rename() can be re-written as follows as well (cf. student1 and student1a): student %&gt;% rename(race = `race/ethnicity`, parent_edu = `parental level of education`, prep_course = `test preparation course`, math = `math score`, reading = `reading score`, writing = `writing score`) -&gt; student1a student1a From now on, we will use the pipe-based syntax more often. The pipe operator %&gt;% is from the library magrittr, and now is predominantly used in the tidyverse packages. However, starting from R 4.1, there is a new built-in pipe operator in base R, i.e., |&gt;: c(-10:10) |&gt; # create a vector abs() |&gt; # take each element&#39;s absolute value sum() |&gt; # sum all elements sqrt() [1] 10.48809 For more detail, you can check this YouTube clip: 8.4 mutate() Now imagine that you would like to create a new variable called final_grade, which is a weighted average of the student’s academic performance. Let us assume that you have the following weights in mind: math (50%), reading (25%), writing (25%). You can use mutate() to create a new column (i.e., variable) in your data frame: student1 %&gt;% mutate(final_grade = math*0.5 + reading*0.25 + writing*0.25) We can create more than one new variables as well: student1 %&gt;% mutate(language = reading*0.5 + writing*0.5, final_grade = math + language) In the above practices of mutate(), we did not save the output of mutate() to a new object name. We only print the output directly to the console. In other words, the original data frame is still the same (i.e., student, student1); no new variables have been created with respect to these original data frames. 8.5 select() select() is to select particular columns of the data frame that you would like to focus on. You can select just one column student1 %&gt;% select(math) Or multiple columns: student1 %&gt;% select(math, reading, writing) student1 %&gt;% select(reading, writing, math) Or columns within a range: student1 %&gt;% select(math:writing) You can also omit variables using select() student1 %&gt;% select(-c(race:lunch)) 8.6 filter() While select() is for subsetting columns, filter() is for subsetting rows. We can extract subsets of rows from a data frame. Most importantly, we often need to extract rows based on their values in a particular column (i.e., variable). one logical condition student1 %&gt;% filter(math &gt; 90) AND &amp; conditions: student1 %&gt;% filter(math &lt; 40 &amp; reading &lt; 40) OR | conditions: student1 %&gt;% filter(math &lt; 40 | reading &lt; 40) XOR xor conditions: student1 %&gt;% filter(xor(math &lt; 40, reading &lt; 40)) Exercise 8.2 Please check the row numbers of the above three filtered data frames. Any connection? Please check Chapter 4.1 Vector for more logical operations. 8.7 arrange() We can arrange the rows of the data frame according to a particular variable. student1 %&gt;% arrange(math) By default, R will arrange the rows in an ascending order. If you like to arrange your data in a descending order, put a desc() around your variable name: student1 %&gt;% arrange(desc(math)) 8.8 group_by() and summarize() The group_by() function is used to generate summary statistics from the data frame within strata defined by a grouping variable. For example, in this student1 dataset, you might want to know what the average math scores are for students of different genders. In conjunction with the group_by() function we often use the summarize() function to create the summarized statistics for each subgroup (i.e., male and female). Two important steps: Split the big data frame into smaller sub data frames according to a grouping factor/variable (group_by()) Summarize each sub data frame with respect to specific parameters (summarize()) student1 %&gt;% group_by(gender) %&gt;% summarize(math_average = mean(math), math_median = median(math), math_sd = sd(math)) In summarize(), there are a lot of powerful and useful functions that can be applied to the sub-data-frames created by group_by(). Please check the documentation of summarize() to learn how to use the following functions within summarize(): Center: mean(), median() Spread: sd(), IQR(), mad() Range: min(), max(), quantile() Position: first(), last(), nth(), Count: n(), n_distinct() Logical: any(), all() Another more complex example. We can quickly extract the number of students by gender and at the same time extract the 90%-quantile and 10%-quantile of their math scores by each gender group. student1 %&gt;% group_by(gender) %&gt;% summarize(N=n(), RANK90TH=quantile(math, 0.9), RANK10TH=quantile(math, 0.1)) 8.9 count() One of the most-often used feature when we have data frames is to tally the frequencies of the subjects according to some of the columns. These columns are often categorical variables in the forms of character or factor (serving as grouping factors). The function count() is born for this. For example, we can create a frequency distribution of male and female students of different parental levels of education (i.e., parent_edu x gender contingency table): student1 %&gt;% count(parent_edu, gender) The function count() can be seen as a short-hand for group_by() + summarize(). Can you create the same frequency distributions as above using only group_by() and summarize()? Exercise 8.3 Continuing the above example, how can you create another column, which includes the percentage of male and female students for those of the same parental level education (see below)? 8.10 Tidy Data Now I would like to talk about the idea of tidy dataset. Wickham &amp; Grolemund (2017) suggests that a tidy dataset needs to satisfy the following three interrelated rules: Each variable must have its own column. Each observation must have its own row. Each value must have its own cell. However, in real life, we often encounter datasets that are NOT tidy at all. Instead of expecting others to do the tidying work for you (which is very unlikely), we might as well learn how to deal with messy dataset. Wickham &amp; Grolemund (2017) suggests two common strategies data scientists often apply to the untidy dataset: One variable might be spread across multiple columns (from long to wide) One observation might be scattered across multiple rows (from wide to long) 8.10.1 A Long-to-Wide Example Here I would like to illustrate the idea of tidy dataset and also ways of tidying with a simple dataset provided in Wickham &amp; Grolemund (2017), Chapter 12. people &lt;- tribble( ~name, ~profile, ~values, #-----------------|--------|------ &quot;Phillip Woods&quot;, &quot;age&quot;, 45, &quot;Phillip Woods&quot;, &quot;height&quot;, 186, &quot;Jessica Cordero&quot;, &quot;age&quot;, 37, &quot;Jessica Cordero&quot;, &quot;height&quot;, 156 ) people The above dataset people is not tidy because the column profile contains more than one variable. An observation (e.g., Phillip Woods) is scattered across several rows. To tidy up people, we need strategy I: One variable might be spread across multiple columns The function tidyr::pivot_wider() is made for this. There are two important parameters in pivot_wider(): names_from = ...: The column to take variable names from. Here it’s profile. values_from = ...: The column to take values from. Here it’s values. Figure 8.1: From Long to Wide: pivot_wider() require(tidyr) people %&gt;% pivot_wider(names_from = profile, values_from = values) 8.10.2 A Wide-to-Long Example preg &lt;- tribble( ~pregnant, ~male, ~female, &quot;yes&quot;, NA, 10, &quot;no&quot;, 20, 12 ) preg The above dataset preg may not be tidy enough because not all the observations have their own rows. Also, there is an underlying factor that gets spread into different columns by its levels, i.e., GENDER -&gt; [male, female]. This dataset can be tidied up as follows: We can have a column gender We can have a column pregnant We can have a column count (representing the number of observations for the combinations of gender and pregnant) In other words, we can use strategy II: One observation might be scattered across multiple rows (from wide to long) (Each level combination of pregnant and gender can be one observation.) And the function tidyr::pivot_longer() is made for this. There are three important parameters: cols = ...: The set of columns whose names are values, not variables. Here they are male and female. names_to = ...: The name of the variable to move the column names to. Here it is gender. values_to = ...: The name of the variable to move the values to. Here it is count. Figure 8.2: From Wide to Long: pivot_longer() preg %&gt;% pivot_longer(cols=c(&quot;male&quot;,&quot;female&quot;), names_to = &quot;gender&quot;, values_to = &quot;count&quot;) You probably would wonder why we need to convert a data frame from a wide format to a long one. Now that we have one independent column gender, we can use it for statistical analysis and data visualization! preg %&gt;% pivot_longer(cols=c(&quot;male&quot;,&quot;female&quot;), names_to = &quot;gender&quot;, values_to = &quot;count&quot;, ) -&gt; preg_longer preg_longer %&gt;% ggplot(aes(pregnant,count, fill= gender)) + geom_bar(stat=&quot;identity&quot;, position=position_dodge2()) Exercise 8.4 Please get familiar with tidyr::separate() and tidyr::unite(), which are two important functions to manipulate the columns of the data frame. 8.11 Exercises Exercise 8.5 In the dataset demo_data/data-students-performance.csv, please load the dataset in R and print out those students who are female and whose math scores are &lt; 40. In your output, please show the following columns only: gender, math. Exercise 8.6 With the same dataset, please compute the mean scores and standard deviations of math for different races. Also, please include the number of students for each race sub-group. Exercise 8.7 With the same dataset, please create a summary data frame, which includes the number of students, math mean scores, math standard deviations, for students of different genders and parental education levels. Exercise 8.8 In terms of Parental Education Levels (i.e., parent_edu), it would be better to be coded as an ordered factor. Can you transform the variable parent_edu into a ordered factor and regenerate the outputs requested in Exercise 8.7. Let us assume that the factor parent_edu follows the following order: some high school &lt; high school &lt; some college &lt; associate's degree &lt; bachelor's degree &lt; master's degree Exercise 8.9 Have you any ideas how to generate the following graphs using ggplot2()? Your goal is to re-create graphs that look as similar to the following as possible. Exercise 8.10 In this exercise, please first download the dataset demo_data/data-word-freq.csv. You may use readr::read_csv() to load the dataset into R. This is a dataset including word frequencies in two different corpora. For example, the word the appears 346 times in perl corpus but 229 times in python corpus. In other words, each row in word_freq in fact represents the combination of (WORD, CORPUS) because the column FREQ contains the values for those variables. In addition, the same word appears twice in the dataset in the rows (e.g., the, a). Please transform word_freq into a wider format, where the word frequencies in each corpus can be independent columns (as shown in the second table). If the word appears in only one of the corpora, its frequency would be 0. require(readr) word_freq &lt;- read_csv(&quot;demo_data/data-word-freq.csv&quot;) word_freq References Wickham, H., &amp; Grolemund, G. (2017). R for data science: Import, tidy, transform, visualize, and model data (1st ed.). O’Reilly Media, Inc. "],["string-manipulation.html", "Chapter 9 String Manipulation 9.1 What is Regular Expression? 9.2 String Basics 9.3 A Good Tool: RegExplain 9.4 Regular Expression Grammar 9.5 Pattern Matching 9.6 Advanced Pattern Matching: Look Ahead and Behind 9.7 More Practices 9.8 Case Study: Chinese Four-Character Idioms", " Chapter 9 String Manipulation In data analysis, most of the time we are dealing with texts/strings. In other words, when wrangling with the data, we need all kinds of techniques in string manipulations, such as finding/replacing a particular string, removing unnecessary strings, combining shorter strings into a longer one, or splitting a long string into smaller chunks/tokens. My experience tells me that a competent data scientist often needs a certain level of skills on string processing. In particular, an effective use of regular expressions plays the most important role. In this chapter, I would like to introduce some frequently-used techniques relating to string manipulation, with a special focus on regular expression. Also, I will use the package stringr for illustration. It is part of the tidyverse framework as well. library(tidyverse) ## library(stringr) # loaded when loading tidyverse 9.1 What is Regular Expression? In text processing, we often do “find-and-replace” in our documents. I am sure that you do this very often in MS-Word or MS-Excel. The routines reflect the fact that we often need to locate particular sets of strings and perform specific processing on these strings (e.g., replacing, removing, modifying them etc.). This is the exact niche where the regular expression can be of great help. Regular expression is a language, which allows us to create a schematic textual pattern and use this pattern to match other strings that may fall into this schematic pattern. This idea of one-pattern-for-multiple-matches is the beauty/essence of regular expression. Several advantages of regular expressions are self-evident: Effective/Efficient pattern matching E-mail format checking, phone number checking Reduplicated strings Date format control Information extraction and text mining Extract texts according to a particular format Proper names, e-mails, phone numbers, etc. Therefore, the nature of one-to-many mapping with regular expressions allows us to effectively retrieve strings of similar properties in a much simpler and coherent way. Another advantage is that with the knowledge of regular expression and coding capability, you can perform pattern matching tasks on any machine readable data set available (i.e., corpora) without being limited to the platform created by the corpus provider. Otherwise, every time when we need to retrieve patterns from a corpus, we need to learn the system-specific syntax for corpus query. What we can do will always be limited to what the platform is capable of. (But of course, we need to first obtain a licensed use of the full-text corpus data. That’s another issue !) 9.2 String Basics Before we introduce regular expressions, let’s look at some of the basic string-related functions. Functions from the library stringr often start with str_*(). There are three basic functions: str_length(): get the length of the string (i.e., number of characters) word_string &lt;- c(&quot;the&quot;, &quot;word&quot;, &quot;string&quot;) word_string %&gt;% str_length [1] 3 4 6 str_c(): combine strings into a longer one str_c(&quot;the&quot;,&quot;word&quot;,&quot;string&quot;) [1] &quot;thewordstring&quot; str_c(&quot;the&quot;,&quot;word&quot;,&quot;string&quot;,sep = &quot;_&quot;) [1] &quot;the_word_string&quot; From the above output, can you tell what is the default value for the argument str_c(..., sep = ...)? Please note that the following code generates a different result from the above. Can you tell the differences? How can you create exactly the same results by using str_c(word_string,…)? Please check ?str_c. str_c(word_string, sep = &quot;_&quot;) [1] &quot;the&quot; &quot;word&quot; &quot;string&quot; When you have several objects in the str_c(), please use the argument str_c(..., sep = ...) to combine them into a long string. When you have only one object (but it is a multiple-element character vector), please use the argument str_c(..., collpase = ...) to collapse a vector into a long string. str_sub(): substract part of the string by positions str_sub(string = &quot;international&quot;, start = 1, end = 5) [1] &quot;inter&quot; 9.3 A Good Tool: RegExplain There is a very useful tool for the use of regular expressions–RegExplain, which is an RStudio addin. It allows you to: interactively build your regexp and check the output of common string matching functions Figure 9.1: Taken from RegExplain Github Page use the included resources to learn regular expressions Figure 9.2: Taken from RegExplain Github Page consult the interactive help pages Figure 9.3: Taken from RegExplain Github Page This is very useful because we can prepare our regular expressions and use them in the code chunk after we have made sure that they work properly in the RegExplain. You can install the addin using `remotes``: ## Please install `remotes` if you haven&#39;t install.packages(&quot;remotes&quot;) remotes::install_github(&quot;gadenbuie/regexplain&quot;) Sometimes you may find interesting R packages on the Internet but they are not available in the official R library provider, CRAN. The remotes::install_github() provides a way to install a non-official R library available on GitHub. 9.4 Regular Expression Grammar Now let’s look at the grammar of regular expressions in more detail. In this section, we will discuss the standard Perl-compatible regular expression syntax. This is by now the most widely used version of regular expressions in most programming languages. To start with, in stringr, there is a very useful function, str_view(STRING, PATTERN), which can show us the match of the pattern in the string in a visually intuitive way: x &lt;- c(&quot;apple&quot;, &quot;banana&quot;, &quot;pear&quot;) str_view(string = x, pattern = &quot;an&quot;) [2] │ b&lt;an&gt;&lt;an&gt;a For basic syntax of regular expressions, I will use this str_view() to show you how the regular pattern works in string-matching. You can also use RegExplain addin to test your regular expressions. So we know that the pattern (i.e., an) exists in the second string of x only in the above example. Then depending on your purpose, we can retrieve different information from each element of x based on this regular expression: str_detect(string = x, pattern = &quot;an&quot;) [1] FALSE TRUE FALSE str_match(string = x, pattern = &quot;an&quot;) [,1] [1,] NA [2,] &quot;an&quot; [3,] NA str_match_all(string = x, pattern = &quot;an&quot;) [[1]] [,1] [[2]] [,1] [1,] &quot;an&quot; [2,] &quot;an&quot; [[3]] [,1] str_extract(string = x, pattern = &quot;an&quot;) [1] NA &quot;an&quot; NA str_extract_all(string = x, pattern = &quot;an&quot;) [[1]] character(0) [[2]] [1] &quot;an&quot; &quot;an&quot; [[3]] character(0) str_subset(string = x, pattern = &quot;an&quot;) [1] &quot;banana&quot; 9.4.1 Metacharacters To implement the idea of one-to-many mapping, RegEx defines several metacharacters, which are of special use in regular expressions. Their meanings are NOT the same as their literal counterparts. In RegEx, . is a special character, referring to any character: x &lt;- c(&quot;apple&quot;, &quot;banana&quot;, &quot;pear&quot;) str_view(string = x, pattern = &quot;.a.&quot;) [2] │ &lt;ban&gt;ana [3] │ p&lt;ear&gt; But what if you really want to match a period . symbol literally in your string? x &lt;- c(&quot;apple&quot;, &quot;banana&quot;,&quot;pear&quot;, &quot;orange. And&quot;) str_view(string = x, pattern = &quot;.&quot;) [1] │ &lt;a&gt;&lt;p&gt;&lt;p&gt;&lt;l&gt;&lt;e&gt; [2] │ &lt;b&gt;&lt;a&gt;&lt;n&gt;&lt;a&gt;&lt;n&gt;&lt;a&gt; [3] │ &lt;p&gt;&lt;e&gt;&lt;a&gt;&lt;r&gt; [4] │ &lt;o&gt;&lt;r&gt;&lt;a&gt;&lt;n&gt;&lt;g&gt;&lt;e&gt;&lt;.&gt;&lt; &gt;&lt;A&gt;&lt;n&gt;&lt;d&gt; str_view(string = x, pattern = &quot;\\\\.&quot;) [4] │ orange&lt;.&gt; And This leads us to the notion of escaping character \\. In R, \\ is used if you want to tell R that the metacharacter after \\ should be treated literally, not metaphorically as a metacharacter. But why two slashes \\\\? It’s simple: because \\ itself is a metacharacter in R as well. We use it to escape quotes like \" and '. Therefore, the first backslash is needed in order to tell R engine that the following character (i.e., the second slash) should be taken literally; the second backslash is needed in order to tell RegEx engine that the following character (i.e., .) should be taken literally. So, if you have the following three elements in x. How can you identify the double quotes \" in the strings? my &quot;apple&quot; banana apple peel [1] │ my &lt;&quot;&gt;apple&lt;&quot;&gt; [2] │ banana [3] │ apple peel 9.4.2 Anchors RegEx defines a few metacharacters, which serve as anchors in pattern matching. These anchoring metacharacters allow us to find a match in a particular position of the string (e.g., at the beginning/ending of the string). ^: The start of the string x &lt;- c(&quot;apple&quot;, &quot;banana&quot;, &quot;pear&quot;) str_view(x, &quot;^a&quot;) [1] │ &lt;a&gt;pple $: The end of the string x &lt;- c(&quot;apple&quot;, &quot;banana&quot;, &quot;pear&quot;) str_view(x, &quot;a$&quot;) [2] │ banan&lt;a&gt; x &lt;- c(&quot;apple pie&quot;, &quot;apple&quot;, &quot;apple cake&quot;) str_view(x, &quot;^apple$&quot;) [2] │ &lt;apple&gt; The anchors are evaluated according to the base unit you are matching. In our previous examples, the RegEx pattern is applied to find a match in each element of the vector. The vector includes words. Therefore, the ^ indicates a word-initial position; $ indicates a word-final position. If you have a vector of sentences, the ^ would indicate a sentence-initial position; $ would indicate a sentence-final position. (See below) x &lt;- c(&quot;apple is good&quot;, &quot;banana is better than apple&quot;, &quot;an apple a day keeps the doctor away&quot;) str_view(x, &quot;^apple&quot;) [1] │ &lt;apple&gt; is good str_view(x, &quot;apple$&quot;) [2] │ banana is better than &lt;apple&gt; 9.4.3 Character Set RegEx also defines a few character sets because in our patten-matching, the characters included in a set often show similar behaviors. Common predefined character sets include: \\\\d: matches any digit. \\\\s: matches any whitespace (e.g. space, tab, newline). \\\\w: matches any alphanumeric characters x&lt;-c(&quot;apple&quot;,&quot;apple123&quot;,&quot;banana1&quot;) str_view(string = x , pattern = &quot;\\\\d&quot;) [2] │ apple&lt;1&gt;&lt;2&gt;&lt;3&gt; [3] │ banana&lt;1&gt; In pattern-matching, very often you will have cases where one base unit may have more than one match. In the previous example, str_view() identifies only the first match of each base unit from x. If you need to identify all the matches from each base unit, you need to use str_view_all(). x &lt;- c(&quot;aeiouAEIOU1234_ .\\\\$%-*()&quot;) str_view_all(string = x, pattern = &quot;\\\\w&quot;) [1] │ &lt;a&gt;&lt;e&gt;&lt;i&gt;&lt;o&gt;&lt;u&gt;&lt;A&gt;&lt;E&gt;&lt;I&gt;&lt;O&gt;&lt;U&gt;&lt;1&gt;&lt;2&gt;&lt;3&gt;&lt;4&gt;&lt;_&gt; .\\$%-*() #compare str_view_all(string = x, pattern = &quot;.&quot;) [1] │ &lt;a&gt;&lt;e&gt;&lt;i&gt;&lt;o&gt;&lt;u&gt;&lt;A&gt;&lt;E&gt;&lt;I&gt;&lt;O&gt;&lt;U&gt;&lt;1&gt;&lt;2&gt;&lt;3&gt;&lt;4&gt;&lt;_&gt;&lt; &gt;&lt;.&gt;&lt;\\&gt;&lt;$&gt;&lt;%&gt;&lt;-&gt;&lt;*&gt;&lt;(&gt;&lt;)&gt; The difference of finding-the-first-match (str_view()) vs. finding-all-the-matches (str_view_all()) will turn out to be very important in practical tasks. Please bear this in mind. In the above comparison of the two meta-character sets, . and \\w, it is clear that the \\w includes alphanumeric characters plus the underscore _. It does NOT include the hyphen -, which however can be a word-internal component. 9.4.4 Alternatives Section 9.4.3 describes a few prefined character sets in RegEx. We can also define our own character set using the square brackets [ ]. And we can use [^...] to define a complementary character set. (Please note that ^ has a different RegEx meaning within [].) [abc]: matches a, b, or c. [^abc]: matches anything except a, b, or c. x &lt;- c(&quot;grey&quot;, &quot;gray&quot;) str_view(string = x, pattern = &quot;gr[ea]y&quot;) [1] │ &lt;grey&gt; [2] │ &lt;gray&gt; If you know very well which characters you are to match/find, use inclusive character sets, i.e., […]. If you know very well which characters you do NOT like to match/find, use exclusive character sets, i.e., [^...]. For example, what if we would like to find all non-vowel letters in the words? Instead of coming up with an inclusive character set [...], which include all possible consonant letters, it would be more efficient if you create an exclusive character set, [^aeiou], which suggests that you need any characters that do not belong to vowels. x &lt;- c(&quot;grey&quot;, &quot;gray&quot;) str_view_all(string = x, pattern = &quot;[^aeiou]&quot;) [1] │ &lt;g&gt;&lt;r&gt;e&lt;y&gt; [2] │ &lt;g&gt;&lt;r&gt;a&lt;y&gt; 9.4.5 Quantifiers Usually we do not know beforehand the exact length of the match. The match can be variable in sizes. For example, you may want to find words starting with “a”. In that case, you need to create a regular expression that can match strings of variable lengths. We can use quantifiers to specify the number of occurrences of a particular unit (i.e., the character preceding the quantifier) in the regular expression: ?: 0 or 1 +: 1 or more *: 0 or more x &lt;- &quot;Roman numerals: MDCCCLXXXVIII&quot; str_view(x, &quot;CC?&quot;) [1] │ Roman numerals: MD&lt;CC&gt;&lt;C&gt;LXXXVIII str_view(x, &quot;X+&quot;) [1] │ Roman numerals: MDCCCL&lt;XXX&gt;VIII We can specify an exact range of number of occurrences using the curly brackets { , }: {n}: exactly n occurrences {n,}: n or more occurrences {,m}: at most m occurrences {n,m}: between n and m occurrences x &lt;- &quot;Roman numerals: MDCCCLXXXVIII&quot; str_view(x, &quot;C{2}&quot;) [1] │ Roman numerals: MD&lt;CC&gt;CLXXXVIII str_view(x, &quot;C{2,}&quot;) [1] │ Roman numerals: MD&lt;CCC&gt;LXXXVIII str_view(x, &quot;C{2,3}&quot;) [1] │ Roman numerals: MD&lt;CCC&gt;LXXXVIII When we use the quantifiers, be very careful about the scope of the quantifier. By default, the quantifier takes only its preceding character as the scope. If you need to specify the number of occurrences for a group of characters or a specific sub-pattern, you need to put the pattern in a group (...) and then put your quantifier right after the group. x &lt;- &quot;aaabbbababcdf&quot; str_view(x, &quot;ab{2,}&quot;) # the scope of the quantifier is `b` [1] │ aa&lt;abbb&gt;ababcdf str_view(x, &quot;(ab){2,}&quot;) # the scope of the quantifier is `ab` [1] │ aaabbb&lt;abab&gt;cdf 9.4.6 Greedy vs. Non-greedy match The earlier example, as repeated here, shows you that when the RegEx locates the pattern in the string, it prefers to find a longest match that satisfies the pattern. x &lt;- &quot;Roman numerals: MDCCCLXXXVIII&quot; str_view(x, &quot;C{2,}&quot;) [1] │ Roman numerals: MD&lt;CCC&gt;LXXXVIII In the above example, the substring CC should satisfy the RegEx C{2,} already but the RegEx returns CCC as the first match. This is the idea of greedy match. In other words, by default, when we apply quantifiers in our regular expressions, the RegEx engine assumes a greedy match (i.e., to find a longest possible match). To cancel this default greedy match, we can add ? after the quantifiers. It applies to all quantifiers we’ve looked at (e.g., ?, +, *). Before running the following code chunk, please predict their respective outputs. x &lt;- &quot;Roman numerals: MDCCCLXXXVIII&quot; str_view(x, &quot;CL?&quot;) # find longest match str_view(x, &quot;CL??&quot;) # find shortest match str_view(x, &quot;CLX+&quot;) # find longest match str_view(x, &quot;CLX+?&quot;) # find shortest match str_view(x, &quot;CLX*&quot;) # find longest match str_view(x, &quot;CLX*?&quot;) # find shortest match 9.4.7 Group and Back-reference # `fruit` is a preloaded vector from `stringr` x &lt;- fruit %&gt;% head(10) x [1] &quot;apple&quot; &quot;apricot&quot; &quot;avocado&quot; &quot;banana&quot; &quot;bell pepper&quot; [6] &quot;bilberry&quot; &quot;blackberry&quot; &quot;blackcurrant&quot; &quot;blood orange&quot; &quot;blueberry&quot; Now let’s look at a more complicated example.What if we want to extract English fruit words which have a letter repeating twice in a row (e.g, apple, bell pepper). The main problem is: we don’t know which letters are going to be repeated in the word. How should we create our regular expression? Can we use the metacharacter . plus a quantifier {2} to match any possible alphanumeric character that repeats twice, as below? str_view(x, &quot;.{2}&quot;) [1] │ &lt;ap&gt;&lt;pl&gt;e [2] │ &lt;ap&gt;&lt;ri&gt;&lt;co&gt;t [3] │ &lt;av&gt;&lt;oc&gt;&lt;ad&gt;o [4] │ &lt;ba&gt;&lt;na&gt;&lt;na&gt; [5] │ &lt;be&gt;&lt;ll&gt;&lt; p&gt;&lt;ep&gt;&lt;pe&gt;r [6] │ &lt;bi&gt;&lt;lb&gt;&lt;er&gt;&lt;ry&gt; [7] │ &lt;bl&gt;&lt;ac&gt;&lt;kb&gt;&lt;er&gt;&lt;ry&gt; [8] │ &lt;bl&gt;&lt;ac&gt;&lt;kc&gt;&lt;ur&gt;&lt;ra&gt;&lt;nt&gt; [9] │ &lt;bl&gt;&lt;oo&gt;&lt;d &gt;&lt;or&gt;&lt;an&gt;&lt;ge&gt; [10] │ &lt;bl&gt;&lt;ue&gt;&lt;be&gt;&lt;rr&gt;y The results are not what we have expected. The above pattern would only give us the first two characters of each word. The quantifier {2} in the regular expression only indicates the number of occurrences (i.e., twice), but it says nothing about the requirement that the two letters have to be exactly the same. This is a time when we need to introduce the concept of back-reference. The trick is that when you use . to match any character, the quantifier does not help much as any character that repeats would fit the pattern. We need a new strategy to ask the RegEx engine to remember the previously matched character and quantify the number of occurrences of the remembered character: str_view(x, &quot;(.)\\\\1&quot;) [1] │ a&lt;pp&gt;le [5] │ be&lt;ll&gt; pe&lt;pp&gt;er [6] │ bilbe&lt;rr&gt;y [7] │ blackbe&lt;rr&gt;y [8] │ blackcu&lt;rr&gt;ant [9] │ bl&lt;oo&gt;d orange [10] │ bluebe&lt;rr&gt;y The regular expression can be conceptualized as follows: .: matches any character (.): the parenthesis would label the matched as a group. Internally, the RegEx engine numbers all groups serially from left to right \\\\1: back-reference the first group. The same logic applies to the second group of the regular expression (i.e., \\\\2) So (.)\\\\1 means that when the engine matches a character (i.e., . = any character), there has to be another same character following the former. Exercise 9.1 With the same set of fruit names in x, how do we match fruits with a abab pattern, such as “banana”? [4] │ b&lt;anan&gt;a Exercise 9.2 With the same set of fruit names in x, how do we match fruits with a abba pattern, such as “pepper”? [5] │ bell p&lt;eppe&gt;r Exercise 9.3 With the same set of fruit names in x, please find fruit names which has at least one letter that is the same as their initial letters [3] │ &lt;avoca&gt;do [6] │ &lt;bilb&gt;erry [7] │ &lt;blackb&gt;erry [10] │ &lt;blueb&gt;erry 9.5 Pattern Matching This section will show you examples of how we can make use of regular expresions to process strings. In stringr, there are a list of verbs that we use with regular expressions: In the following example, we use the upper-casing STRING to refer to the character vector to which the PATTERN (i.e., regular expression) is matched. 9.5.1 str_detect() str_detect(STRING, PATTERN): Determine which strings in STRING has a match of the PATTERN (binary) str_detect(x, &quot;e$&quot;) [1] TRUE FALSE FALSE FALSE FALSE FALSE FALSE FALSE TRUE FALSE 9.5.2 str_subset() str_subset(STRING, PATTERN): Subset the STRING by identifying elements that have either a full or partial match of the PATTERN (character) str_subset(x, &quot;e$&quot;) [1] &quot;apple&quot; &quot;blood orange&quot; 9.5.3 str_extract() str_extract(STRING, PATTERN): Extract the content of the matches of the strings in STRING (character) str_extract(x, &quot;e$&quot;) [1] &quot;e&quot; NA NA NA NA NA NA NA &quot;e&quot; NA Also, please note that str_extract() only extracts the first match of the string. To extract all matches from the strings: str_extract(x, &quot;[aeiou]&quot;) # find only the first match [1] &quot;a&quot; &quot;a&quot; &quot;a&quot; &quot;a&quot; &quot;e&quot; &quot;i&quot; &quot;a&quot; &quot;a&quot; &quot;o&quot; &quot;u&quot; str_extract_all(x, &quot;[aeiou]&quot;) # find all matches in each string [[1]] [1] &quot;a&quot; &quot;e&quot; [[2]] [1] &quot;a&quot; &quot;i&quot; &quot;o&quot; [[3]] [1] &quot;a&quot; &quot;o&quot; &quot;a&quot; &quot;o&quot; [[4]] [1] &quot;a&quot; &quot;a&quot; &quot;a&quot; [[5]] [1] &quot;e&quot; &quot;e&quot; &quot;e&quot; [[6]] [1] &quot;i&quot; &quot;e&quot; [[7]] [1] &quot;a&quot; &quot;e&quot; [[8]] [1] &quot;a&quot; &quot;u&quot; &quot;a&quot; [[9]] [1] &quot;o&quot; &quot;o&quot; &quot;o&quot; &quot;a&quot; &quot;e&quot; [[10]] [1] &quot;u&quot; &quot;e&quot; &quot;e&quot; 9.5.4 str_match() str_match(STRING, PATTERN): Extract the content of the matches of the strings in STRING as well as each capture group (character) in the regular expression. str_match(x, &quot;(bl)([aeiou]+)&quot;) [,1] [,2] [,3] [1,] NA NA NA [2,] NA NA NA [3,] NA NA NA [4,] NA NA NA [5,] NA NA NA [6,] NA NA NA [7,] &quot;bla&quot; &quot;bl&quot; &quot;a&quot; [8,] &quot;bla&quot; &quot;bl&quot; &quot;a&quot; [9,] &quot;bloo&quot; &quot;bl&quot; &quot;oo&quot; [10,] &quot;blue&quot; &quot;bl&quot; &quot;ue&quot; For each match, we will get not only the full match, but also the capture groups substrings specified in the parentheses in the regular expression. Each group (i.e., parenthesis) in the regular expression will have a partial match in the str_match() results. We can compare the results from str_extract(): str_extract(x, &quot;(bl)([aeiou]+)&quot;) [1] NA NA NA NA NA NA &quot;bla&quot; &quot;bla&quot; &quot;bloo&quot; &quot;blue&quot; Exercise 9.4 How do you use str_match() to find out all the c+Vowel structures, and at the same time identify which vowels follow the letter c? [2] │ apri&lt;co&gt;t [3] │ avo&lt;ca&gt;do [8] │ black&lt;cu&gt;rrant [,1] [,2] [1,] NA NA [2,] &quot;co&quot; &quot;o&quot; [3,] &quot;ca&quot; &quot;a&quot; [4,] NA NA [5,] NA NA [6,] NA NA [7,] NA NA [8,] &quot;cu&quot; &quot;u&quot; [9,] NA NA [10,] NA NA Exercise 9.5 Please use str_match() to find out all fruit names whose initial letter is a consonant letter (i.e., not any of a, e, i, o, u) and gets repeated in the remaining part of the word. The following is a sample output from str_match(). Column 1 refers to the match; Column 2 refers to the initial letter; Column 3 refers to the letters between the initial letter and the repeated same letter; Column 4 refers to the repeated letter, which is the same as the initial letter. [,1] [,2] [,3] [,4] [1,] NA NA NA NA [2,] NA NA NA NA [3,] NA NA NA NA [4,] NA NA NA NA [5,] NA NA NA NA [6,] &quot;bilb&quot; &quot;b&quot; &quot;il&quot; &quot;b&quot; [7,] &quot;blackb&quot; &quot;b&quot; &quot;lack&quot; &quot;b&quot; [8,] NA NA NA NA [9,] NA NA NA NA [10,] &quot;blueb&quot; &quot;b&quot; &quot;lue&quot; &quot;b&quot; 9.5.5 str_replace() str_replace(STRING, PATTERN, REPLACEMENT): Replace matches of the PATTERN with REPLACEMENT in STRING. str_replace(string = x, pattern = &quot;[aeiou]&quot;, replacement = &quot;V&quot;) [1] &quot;Vpple&quot; &quot;Vpricot&quot; &quot;Vvocado&quot; &quot;bVnana&quot; &quot;bVll pepper&quot; [6] &quot;bVlberry&quot; &quot;blVckberry&quot; &quot;blVckcurrant&quot; &quot;blVod orange&quot; &quot;blVeberry&quot; It should be noted that str_replace() only replaces the first match of each string. str_replace_all(string = x, pattern = &quot;[aeiou]&quot;, replacement = &quot;V&quot;) [1] &quot;VpplV&quot; &quot;VprVcVt&quot; &quot;VvVcVdV&quot; &quot;bVnVnV&quot; &quot;bVll pVppVr&quot; [6] &quot;bVlbVrry&quot; &quot;blVckbVrry&quot; &quot;blVckcVrrVnt&quot; &quot;blVVd VrVngV&quot; &quot;blVVbVrry&quot; 9.5.6 str_split() str_split(STRING, PATTERN): Split a string in STRING based on a PATTERN (character) x &lt;- sentences %&gt;% head(5) x [1] &quot;The birch canoe slid on the smooth planks.&quot; [2] &quot;Glue the sheet to the dark blue background.&quot; [3] &quot;It&#39;s easy to tell the depth of a well.&quot; [4] &quot;These days a chicken leg is a rare dish.&quot; [5] &quot;Rice is often served in round bowls.&quot; str_split(string = x, pattern = &quot;\\\\s&quot;) [[1]] [1] &quot;The&quot; &quot;birch&quot; &quot;canoe&quot; &quot;slid&quot; &quot;on&quot; &quot;the&quot; &quot;smooth&quot; [8] &quot;planks.&quot; [[2]] [1] &quot;Glue&quot; &quot;the&quot; &quot;sheet&quot; &quot;to&quot; &quot;the&quot; [6] &quot;dark&quot; &quot;blue&quot; &quot;background.&quot; [[3]] [1] &quot;It&#39;s&quot; &quot;easy&quot; &quot;to&quot; &quot;tell&quot; &quot;the&quot; &quot;depth&quot; &quot;of&quot; &quot;a&quot; &quot;well.&quot; [[4]] [1] &quot;These&quot; &quot;days&quot; &quot;a&quot; &quot;chicken&quot; &quot;leg&quot; &quot;is&quot; &quot;a&quot; [8] &quot;rare&quot; &quot;dish.&quot; [[5]] [1] &quot;Rice&quot; &quot;is&quot; &quot;often&quot; &quot;served&quot; &quot;in&quot; &quot;round&quot; &quot;bowls.&quot; Please note that the return of str_split() is a list. fields &lt;- c(&quot;Name: Hadley&quot;, &quot;Country: NZ&quot;, &quot;Age: 35&quot;) fields %&gt;% str_split(&quot;[^\\\\w]+&quot;) [[1]] [1] &quot;Name&quot; &quot;Hadley&quot; [[2]] [1] &quot;Country&quot; &quot;NZ&quot; [[3]] [1] &quot;Age&quot; &quot;35&quot; # To get a simpler structure in return: fields %&gt;% str_split(&quot;[^\\\\w]+&quot;, simplify = T) [,1] [,2] [1,] &quot;Name&quot; &quot;Hadley&quot; [2,] &quot;Country&quot; &quot;NZ&quot; [3,] &quot;Age&quot; &quot;35&quot; A list is considered a more complex structure compared to a data.frame because a list element can be any kind of data structures, including a complex list as well. Exercise 9.6 Convert American dates American.dates to British dates using str_replace_all(). Please note that in your output, you need to preserve the original delimiters for each date. American.dates &lt;- c(&quot;7/31/1976&quot;, &quot;02.15.1970&quot;, &quot;11-31-1986&quot;, &quot;04/01.2020&quot;) [1] &quot;31/7/1976&quot; &quot;15.02.1970&quot; &quot;31-11-1986&quot; &quot;01/04.2020&quot; Exercise 9.7 Please use the default sentences vector as your input and find all patterns of “any BE verbs + words ending with ‘en’ or ‘ed’”. Please extract these matches from the sentences and your result should be a vector of these matches, as shown below. sentences[1:5] [1] &quot;The birch canoe slid on the smooth planks.&quot; [2] &quot;Glue the sheet to the dark blue background.&quot; [3] &quot;It&#39;s easy to tell the depth of a well.&quot; [4] &quot;These days a chicken leg is a rare dish.&quot; [5] &quot;Rice is often served in round bowls.&quot; length(sentences) [1] 720 [1] &quot;is often&quot; &quot;were fed&quot; &quot;is used&quot; &quot;was cooked&quot; [5] &quot;was seized&quot; &quot;is used&quot; &quot;was spattered&quot; &quot;is red&quot; [9] &quot;was fired&quot; &quot;is ten&quot; &quot;is used&quot; &quot;are pushed&quot; [13] &quot;are men&quot; &quot;are used&quot; &quot;were hired&quot; &quot;was covered&quot; [17] &quot;were lined&quot; &quot;was ten&quot; &quot;is used&quot; &quot;are paved&quot; [21] &quot;is carved&quot; &quot;were led&quot; &quot;is needed&quot; &quot;were painted&quot; [25] &quot;were mailed&quot; &quot;was pressed&quot; &quot;is seen&quot; &quot;was packed&quot; [29] &quot;was barred&quot; &quot;was crowded&quot; &quot;was carved&quot; &quot;was drilled&quot; [33] &quot;was hidden&quot; &quot;was seen&quot; &quot;were pierced&quot; &quot;are jangled&quot; [37] &quot;is tinged&quot; &quot;were stamped&quot; &quot;was jammed&quot; &quot;was robbed&quot; [1] │ Rice &lt;is often&gt; served in round bowls. [2] │ The hogs &lt;were fed&gt; chopped corn and garbage. [3] │ A rod &lt;is used&gt; to catch pink salmon. [4] │ The meal &lt;was cooked&gt; before the bell rang. [5] │ The walled town &lt;was seized&gt; without a fight. [6] │ A Tusk &lt;is used&gt; to make costly gifts. [7] │ Mud &lt;was spattered&gt; on the front of his white shirt. [8] │ The sofa cushion &lt;is red&gt; and of light weight. [9] │ The new girl &lt;was fired&gt; today at noon. [10] │ There the flood mark &lt;is ten&gt; inches. [11] │ The lure &lt;is used&gt; to catch trout and flounder. [12] │ They &lt;are pushed&gt; back each time they attack. [13] │ They &lt;are men&gt; who walk the middle of the road. [14] │ Fruit flavors &lt;are used&gt; in fizz drinks. [15] │ Nine men &lt;were hired&gt; to dig the ruins. [16] │ The old pan &lt;was covered&gt; with hard fudge. [17] │ The store walls &lt;were lined&gt; with colored frocks. [18] │ The purple tie &lt;was ten&gt; years old. [19] │ Code &lt;is used&gt; when secrets are sent. [20] │ Roads &lt;are paved&gt; with sticky tar. ... and 20 more Exercise 9.8 Please create a regular expression to extract all word tokens of the sentences from the vector x, which is defined as follows. x &lt;- c(&quot;It&#39;s a three-legged char.&quot;, &quot;The book (you read) was quite boring!&quot;) The returned object is a list, including the word vectors of each text in x. [[1]] [1] &quot;It&#39;s&quot; &quot;a&quot; &quot;three-legged&quot; &quot;char&quot; [[2]] [1] &quot;The&quot; &quot;book&quot; &quot;you&quot; &quot;read&quot; &quot;was&quot; &quot;quite&quot; &quot;boring&quot; Exercise 9.9 In stringr::sentences, there are 720 English sentences. Please create a regular expression to subset sentences with at least one word containing a hyphen. There are TWO sentences that satisfy the condition. [1] &quot;A zestful food is the hot-cross bun.&quot; Exercise 9.10 Please extract all the word tokens that are tagged as NOUNS from the following text using a self-defined regular expressions. NOUNS are defined as words with parts-of-speech tags starting with N. x &lt;- &quot;中央(Nc) 流行(VH) 疫情(Na) 指揮(VC) 中心(Nc) 醫療(VC) 應變組(Nc) 副組長(Na) 羅一鈞(Nb) 今天(Nd) 說明(VE) ，(COMMACATEGORY) 截至(P) 12月(Nd) 1日(Nd) 全球(Nc) 累計(VJ) 至少(Da) 27(Neu) 國(Nc) 、(PAUSECATEGORY) 共有(VJ) 370(Neu) 例(Na) 確診(VA) 感染(VJ) Omicron(FW) 變異株(Na) ，(COMMACATEGORY) 多(D) 來自(VJ) 南非(Nc) 或(Caa) 具(VJ) 非洲(Nc) 國家(Na) 旅遊史(Na) 。(PERIODCATEGORY)&quot; [[1]] [1] &quot;中央(Nc)&quot; &quot;疫情(Na)&quot; &quot;中心(Nc)&quot; &quot;應變組(Nc)&quot; &quot;副組長(Na)&quot; [6] &quot;羅一鈞(Nb)&quot; &quot;今天(Nd)&quot; &quot;12月(Nd)&quot; &quot;1日(Nd)&quot; &quot;全球(Nc)&quot; [11] &quot;27(Neu)&quot; &quot;國(Nc)&quot; &quot;370(Neu)&quot; &quot;例(Na)&quot; &quot;變異株(Na)&quot; [16] &quot;南非(Nc)&quot; &quot;非洲(Nc)&quot; &quot;國家(Na)&quot; &quot;旅遊史(Na)&quot; Exercise 9.11 Please use the same Chinese texts as the input. Please use str_replace_all() along with a self-defined regular expression to remove all part-of-speech tags in the original texts. x &lt;- &quot;中央(Nc) 流行(VH) 疫情(Na) 指揮(VC) 中心(Nc) 醫療(VC) 應變組(Nc) 副組長(Na) 羅一鈞(Nb) 今天(Nd) 說明(VE) ，(COMMACATEGORY) 截至(P) 12月(Nd) 1日(Nd) 全球(Nc) 累計(VJ) 至少(Da) 27(Neu) 國(Nc) 、(PAUSECATEGORY) 共有(VJ) 370(Neu) 例(Na) 確診(VA) 感染(VJ) Omicron(FW) 變異株(Na) ，(COMMACATEGORY) 多(D) 來自(VJ) 南非(Nc) 或(Caa) 具(VJ) 非洲(Nc) 國家(Na) 旅遊史(Na) 。(PERIODCATEGORY)&quot; [1] &quot;中央 流行 疫情 指揮 中心 醫療 應變組 副組長 羅一鈞 今天 說明 ， 截至 12月 1日 全球 累計 至少 27 國 、 共有 370 例 確診 感染 Omicron 變異株 ， 多 來自 南非 或 具 非洲 國家 旅遊史 。&quot; 9.6 Advanced Pattern Matching: Look Ahead and Behind The regular expressions we have introduced so far will consume the input strings when doing the pattern matching. I would like to illustrate this idea with the following simple example. If we want to find Windows, but only when it is followed by \"95, 98, NT, 2000\", how should we write our RegEx pattern? win &lt;- c(&quot;Windows2000&quot;, &quot;Windows&quot;, &quot;WindowsNT&quot;, &quot;Windows7&quot;, &quot;Windows10&quot;) str_view(win, &quot;Windows(95|98|NT|2000)&quot;) [1] │ &lt;Windows2000&gt; [3] │ &lt;WindowsNT&gt; The pattern seems OK because we did find the Windows2000 that satisfies our RegEx. But what if you would like to replace the word “Windows” with “OldSystem” but only when “Windows” is followed by \"95, 98, NT, 2000\"? str_replace(win, pattern = &quot;Windows(95|98|NT|2000)&quot;, replacement = &quot;OldSystem&quot;) [1] &quot;OldSystem&quot; &quot;Windows&quot; &quot;OldSystem&quot; &quot;Windows7&quot; &quot;Windows10&quot; Now you see the problem? Not only “Windows” was replaced, but also the entire string. This is not what we expect to get. Instead, we would expect something like: [1] &quot;OldSystem2000&quot; &quot;Windows&quot; &quot;OldSystemNT&quot; &quot;Windows7&quot; [5] &quot;Windows10&quot; That is why we need lookahead function in RegEx. (?=...): Positive lookahead—extract a match only when ... (the conditional pattern) is on the right (?!...): Negative lookahead—extract a match only when ... (the conditional pattern) is NOT on the right str_view(win, &quot;Windows(?=95|98|NT|2000)&quot;) [1] │ &lt;Windows&gt;2000 [3] │ &lt;Windows&gt;NT In the above regular expression, the () after Windows is a lookahead condition for matching. The strings of “2000” and “NT” in the condition are NOT consumed. The RegEx engine looks ahead the following few characters first to check the patterns. Most importantly, after it finds a match, the lookahead characters will still be available as the input of the next pattern-matching. We can make use of this lookahead to do the string replacement: str_replace(string = win, pattern = &quot;Windows(?=95|98|NT|2000)&quot;, replacement = &quot;OldSystem&quot;) [1] &quot;OldSystem2000&quot; &quot;Windows&quot; &quot;OldSystemNT&quot; &quot;Windows7&quot; [5] &quot;Windows10&quot; Moreover, we can create a negative lookahead as well: str_view(win, &quot;Windows(?!7|10)&quot;) [1] │ &lt;Windows&gt;2000 [2] │ &lt;Windows&gt; [3] │ &lt;Windows&gt;NT str_replace(string = win, pattern = &quot;Windows(?!7|10)&quot;, replacement = &quot;NewSystem&quot;) [1] &quot;NewSystem2000&quot; &quot;NewSystem&quot; &quot;NewSystemNT&quot; &quot;Windows7&quot; [5] &quot;Windows10&quot; In addition to lookahead, we can also specify look-behind conditions: Look-behind conditions: (?&lt;=...): Positive look-behind—extract a match only when it is preceded by ... (conditional pattern). (?&lt;!...): Negative look-behind—extract a match only when it is NOT preceded by ... (conditional pattern). win &lt;- c(&quot;2000Windows&quot;, &quot;Windows&quot;, &quot;NTWindows&quot;, &quot;7Windows&quot;, &quot;10Windows&quot;) str_replace_all(win, &quot;(?&lt;=95|98|NT|2000)Windows&quot;, &quot;OldSystem&quot;) [1] &quot;2000OldSystem&quot; &quot;Windows&quot; &quot;NTOldSystem&quot; &quot;7Windows&quot; [5] &quot;10Windows&quot; win &lt;- c(&quot;2000Windows&quot;, &quot;Windows&quot;, &quot;NTWindows&quot;, &quot;7Windows&quot;, &quot;10Windows&quot;) str_replace_all(win, &quot;(?&lt;!95|98|NT|2000)Windows&quot;, &quot;NewSystem&quot;) [1] &quot;2000Windows&quot; &quot;NewSystem&quot; &quot;NTWindows&quot; &quot;7NewSystem&quot; &quot;10NewSystem&quot; Exercise 9.12 Please use the first ten words in the fruit vector for this exercise. Based on the fruit vocabulary, can you identify all the a that is followed by STOP_SOUNDS and replace them with “V”? STOP_SOUNDS refer to p, t, k, b, d, g Hint: str_replace_all() dataset fruit[1:10] [1] &quot;apple&quot; &quot;apricot&quot; &quot;avocado&quot; &quot;banana&quot; &quot;bell pepper&quot; [6] &quot;bilberry&quot; &quot;blackberry&quot; &quot;blackcurrant&quot; &quot;blood orange&quot; &quot;blueberry&quot; target matches [1] │ &lt;a&gt;pple [2] │ &lt;a&gt;pricot [3] │ avoc&lt;a&gt;do [4] │ banana [5] │ bell pepper [6] │ bilberry [7] │ blackberry [8] │ blackcurrant [9] │ blood orange [10] │ blueberry your result [1] &quot;Vpple&quot; &quot;Vpricot&quot; &quot;avocVdo&quot; &quot;banana&quot; &quot;bell pepper&quot; [6] &quot;bilberry&quot; &quot;blackberry&quot; &quot;blackcurrant&quot; &quot;blood orange&quot; &quot;blueberry&quot; Exercise 9.13 Similar to the previous example, Exercise 9.12, also based on the first ten words in fruit, please identify all the vowels that are both followed and preceded by STOP_SOUNDS and replace them with “V”. Vowels are defined as letters including a, e, i, o,and u, dataset fruit[1:10] [1] &quot;apple&quot; &quot;apricot&quot; &quot;avocado&quot; &quot;banana&quot; &quot;bell pepper&quot; [6] &quot;bilberry&quot; &quot;blackberry&quot; &quot;blackcurrant&quot; &quot;blood orange&quot; &quot;blueberry&quot; target matches [1] │ apple [2] │ apricot [3] │ avocado [4] │ banana [5] │ bell p&lt;e&gt;pper [6] │ bilberry [7] │ blackberry [8] │ blackcurrant [9] │ blood orange [10] │ blueberry your result [1] &quot;apple&quot; &quot;apricot&quot; &quot;avocado&quot; &quot;banana&quot; &quot;bell pVpper&quot; [6] &quot;bilberry&quot; &quot;blackberry&quot; &quot;blackcurrant&quot; &quot;blood orange&quot; &quot;blueberry&quot; 9.7 More Practices This section will show you more examples of the RegEx applications. Most importantly, I will specifically point out the capacities and potentials of regular expressions in helping us manipulating the datasets. In Chapter 8, we have talked about important ways in which we can manipulate our data as a data.frame/tibble. Please refer to the Chapter 8 for a review of the important verbs in dplyr. Exercise 9.14 In the library tidyr, there are two very useful functions for data manipulation: separate(), extract() and unnest(). Please read the documentations of these two functions and run the examples provided in the documentation to make sure that you understand how they work. 9.7.1 Case 1 If we have a data frame like dt below, how do we extract only the numbers of the weeks from the y column, and add this information to a new column, z? Original data frame: dt &lt;- tibble( x = 1:4, y = c(&quot;wk 3&quot;, &quot;week-1&quot;, &quot;7&quot;, &quot;w#9&quot;) ) dt Expected data frame: Hints: We need to know how to extract numbers from the values in y columns. We need to create a new column for the data frame dt. Exercise 9.15 If we have a data frame like dt below, how do we extract all the vowels of the words in the WORD column and create two additional columns: Because a word may have several vowels, create a new column, which shows all the vowels in the word by combining them into a long string with the delimiter “_” Create another column for the number of vowels for each word Vowels are defined as [aeiou]. dt &lt;- tibble( WORD = fruit[1:10] ) dt 9.7.2 Case 2 How to separate the English and Chinese strings in x column and create two new columns, EN, CH? Original data frame: tb &lt;- tibble(x = c(&quot;I我&quot;, &quot;love愛&quot;, &quot;you你&quot;)) tb Expected data frame: Hints: Please check tidyr::extract(), which is a function to split a column into several columns using regular expression. We need to know how to extract alphanumeric (or non-alphanumeric) characters from the values of x column. Exercise 9.16 How to extract the numbers and split the numbers into START and END? Original data frame: df &lt;- tibble(x = c(&quot;1-12周&quot;, &quot;1-10周&quot;, &quot;5-12周&quot;)) df Expected data frame: 9.7.3 Case 3 How to extract all the individual digits of each token and compute the sum of the numbers and save the results in a new column SUM? Original data frame: df &lt;- tibble( x = c(&quot;1234&quot;, &quot;B246&quot;, &quot;217C&quot;, &quot;2357f&quot;, &quot;21WD4&quot;) ) df Expected data frame: Hints: We need to know how to extract all numbers from the values in x. We need to know how to compute the sum of the numbers extracted from each value in x. We need to add these sums to the new column. Exercise 9.17 How to extract all the numbers that follow a upper-casing letter? For example, 34 after W; 217 after B? Original data frame: df &lt;- tibble( x = c(&quot;12W34&quot;, &quot;AB2C46&quot;, &quot;B217C&quot;, &quot;akTs6df&quot;, &quot;21WD4&quot;) ) df Expected data frame: Exercise 9.18 Based on Exercise 9.17, can you add another column to the resulting data frame, which records the upper-casing letter that the numbers follow for each row? 9.8 Case Study: Chinese Four-Character Idioms Many studies have shown that Chinese makes use of large proportion of four-character idioms (四字成語) in discourse. Let’s have an exploratory analysis of four-character idioms in Chinese. 9.8.1 Dictionary Entries In our demo_data directory, there is a file demo_data/dict-ch-idiom.txt, which includes a list of four-character idioms in Chinese. These idioms are collected from 搜狗輸入法詞庫 and the original file formats (.scel) have been combined, removed of duplicate cases, and converted to a more machine-readable format, i.e., .txt. Let’s first load the idioms dataset in R. all_idioms &lt;- readLines(con = &quot;demo_data/dict-ch-idiom.txt&quot;,encoding = &quot;UTF-8&quot;) head(all_idioms) [1] &quot;阿保之功&quot; &quot;阿保之勞&quot; &quot;阿鼻地獄&quot; &quot;阿鼻叫喚&quot; &quot;阿斗太子&quot; &quot;阿芙蓉膏&quot; tail(all_idioms) [1] &quot;罪無可逭&quot; &quot;罪人不帑&quot; &quot;作纛旗兒&quot; &quot;坐纛旂兒&quot; &quot;作姦犯科&quot; &quot;作育英才&quot; length(all_idioms) [1] 56536 In order to make use of the tidy structure in R, we convert the data into a tibble (or a data.frame): idiom &lt;- tibble(string = all_idioms) idiom %&gt;% head 9.8.2 Case Study: X來Y去 We can create a regular expression pattern to extract all idioms with the format of X來Ｙ去: idiom %&gt;% filter(str_detect(string, &quot;.來.去&quot;)) To analyze the meaning of this constructional schema, we may need to extract the X and Y in the schema: idiom_laiqu &lt;-idiom %&gt;% filter(str_detect(string, &quot;.來.去&quot;)) %&gt;% mutate(pattern = str_replace(string, &quot;(.)來(.)去&quot;, &quot;\\\\1_\\\\2&quot;)) %&gt;% separate(pattern, into = c(&quot;w1&quot;, &quot;w2&quot;), sep = &quot;_&quot;) idiom_laiqu # # version 2 # require(tidyr) # idiom %&gt;% # filter(str_detect(string, &quot;.來.去&quot;)) %&gt;% # mutate(string2 = string) %&gt;% # extract(col=&quot;string2&quot;, # into=c(&quot;w1&quot;,&quot;w2&quot;), # regex = &quot;(.)來(.)去&quot;) One empirical question is how many of these idioms are of the pattern W1 = W2 (e.g., 想來想去, 直來直去) and how many are of the pattern W1 != W2 (e.g., 說來道去, 朝來暮去): # Create `structure` column idiom_laiqu_2 &lt;- idiom_laiqu %&gt;% mutate(structure = ifelse(w1==w2, &quot;XX&quot;,&quot;XY&quot;)) idiom_laiqu_2 # Count `structure` frequecnies idiom_laiqu_count &lt;- idiom_laiqu_2 %&gt;% count(structure) idiom_laiqu_count # Create barplots idiom_laiqu_count %&gt;% ggplot(aes(structure, n, fill = structure)) + geom_col() ########################## ### Another alterantive### ########################## # idiom_laiqu %&gt;% # mutate(structure = ifelse(w1==w2, &quot;XX&quot;,&quot;XY&quot;)) %&gt;% # count(structure) %&gt;% # ggplot(aes(structure, n, fill = structure)) + # geom_col() Exercise 9.19 Please use same dataset idiom (loaded from demo_data/dict-ch-idiom.txt) and extract all the idioms that fall into the schema of 一X一Y. idiom &lt;- tibble(string = readLines(&quot;demo_data/dict-ch-idiom.txt&quot;)) Exercise 9.20 Also with the idiom as our data source, now if we are interested in all idioms that have duplicated characters in them, with schemas like either _A_A or A_A_, where A is a fixed character. How can we extract all idioms of these two types from idiom? Also, please visualize the distribution of the two idiom types using a bar plot. Sample answers have been provided below. Idioms with duplicate characters in them Type Distribution Exercise 9.21 Following Exercise 9.20, for each type of the idioms (i.e., “A_A_” or “_A_A”), please provide their respective proportions of W1 = W2 vs. W1 != W2, where W1 and W2 refer to the words filled in the variable slots of the idiomatic templates. The following table is a random sample of each idiom type (5 tokens for each type) (Not sure if you can get the exact sample results with set.seed(123)): "],["data-import.html", "Chapter 10 Data Import 10.1 Overview 10.2 Importing Data 10.3 What is a CSV file? (Self-study) 10.4 Character Encoding (Self-study) 10.5 Character, Code Point, and Hexadecimal Mode (Self-study) 10.6 R Base Functions 10.7 readr Functions 10.8 Directory Operations", " Chapter 10 Data Import Most of the time, we need to work with our own data. In this chapter, we will learn the fundamental concepts and techniques in data I/O (input/output). In particular, we have two main objectives: Learn how to load our data in R from external files Learn how to save our data in R to external files 10.1 Overview There are two major file types that data analysts often work with: txt and csv files. Following the spirit of tidy structure, we will introduce the package, readr, which is also part of the tidyverse. This package provides several useful functions for R users to load their data efficiently from plain-text files. In particular, we will introduce the most effective functions: read_csv() and write_csv() for the loading of CSV files. 10.2 Importing Data Figure 10.1: Data I/O 10.3 What is a CSV file? (Self-study) A CSV is a comma-separated values file, which allows data to be saved in a tabular format. CSVs look like a spreadsheet but with a .csv extension. A CSV file has a fairly simple structure. It’s a list of data separated by commas. For example, let’s say you have a few contacts in a contact manager, and you export them as a CSV file. You’d get a file containing texts like this: Name,Email,Phone Number,Address Bob Smith,bob@example.com,123-456-7890,123 Fake Street Mike Jones,mike@example.com,098-765-4321,321 Fake Avenue CSV files can be easily viewed with any of the text editors (e.g., Notepad++, TextEdit), or spreadsheet programs, such as Microsoft Excel or Google Spreadsheets. But you can only have one single sheet in a file and all data are kept as normal texts in the file. 10.3.1 Why are .CSV files used? There are several advantages of using CSV files for data exchange: CSV files are plain-text files, making them easier for the developer to create Since they’re plain text, they’re easier to import into a spreadsheet or another storage database, regardless of the specific software you’re using To better organize large amounts of data 10.3.2 How do I save CSV files? Saving CSV files is relatively easy. You just need to know where to change the file type. With a normal spreadsheet application (e.g., MS Excel), under the “File” section in the “Save As” tab, you can select it and change default file extension to “CSV (Comma delimited) (*.csv)“. Although people mostly use the comma character to separate (or delimit) data, sometimes people use other characters like the tab, i.e., \\t. Therefore, sometimes people use the file extension TSV to indicate that the tabular data in the file are delimited by tab (indicating the column boundaries). Please also note that all these tabular files can be named with the extension .txt as well. However, a more intuitive file extension is definitely better for data management. 10.3.3 What about other types of data? In data analysis, we sometimes may need to deal with some other types of data files in addition to the plain-texts. For the import/export of other types of data, R also has specific packages designed for them: haven - SPSS, Stata, and SAS files readxl - excel files (.xls and .xlsx) DBI - databases jsonlite - json xml2 - XML httr - Web APIs rvest - HTML (Web Scraping) readtext - large text data (corpus) 10.4 Character Encoding (Self-study) Before we move on to the functions for data I/O, I would like to talk about the issues of character encoding. For all characters in languages, computers use numbers like 1 and 0 to encode all these characters. The more characters a language has, the more numbers are needed in the encoding. For example, for an English text, it usually consists of only Latin alphabets, and limited sets of essential numbers and punctuation marks. A 7-bit encoding scheme is enough to cover all the possible characters in English. The 7-bit encoding gives us the maximum of 128 (27 = 128) possible different characters to encode: each coding number corresponds to one unique character. The ASCII (American Standard Code for Information Interchange) encoding, a 7-bit character encoding developed from telegraph code, is a well-known encoding for English texts. 10.4.1 Problems with ASCII Many languages have more characters German umlauts (über) Accents in Indo-European Languages (déjà) Asciification/Romanization ASCII equivalents were defined for foreign characters that have not been included in the original character set Indo-European languages developed extended verions of ASCII 10.4.2 From 7-bit to One-Byte Encoding Single byte (8-bit) encoding Reserve the first 128 characters for ASCII characters 8-bit allows at most 256 possibilities ISO-8859-1 Encoding 10.4.3 Problems with Single-Byte Encoding Inconsistency A large number of overlapping character sets for encoding characters in different languages Often more than one symbol maps to the same code point/number Compatibility Still can’t deal with writing systems with large character sets (CKJ languages) Two-byte character sets Represent up to 65,536 distinct characters (216 = 65536) Multiple byte encoding Big-5 encoding for traditional Chinese GB encoding for simplified Chinese 10.4.4 Problems with Multi-byte Encoding Different languages still use different encodings Some are single-byte, while some are multiple-byte Digital texts usually have many writing systems single-byte texts, letters, spaces, punctuations, Arabic numerals Interspersed with 2-byte Chinese characters Problems Inconsistency in the byte-encoding number Compatibility across different languages 10.4.5 Unicode and UTF-8 Objective Seek to eliminate this character set ambiguity by specifying a Universal Character Set Including over 100,000 distinct coded characters Used in all the common writing systems today UTF-8 Each character is coded by a one to four byte encoding ASCII characters require 1 byte in UTF-8 (0-127) ISO-8859 characters require 2 bytes in UTF-8 (128-2,047) CKJ characters require 3 bytes in UTF-8 (2,048-65,535) Rare characters require 4 bytes in UTF-8 (65,536-1,112,064) Strengths Encodes text in any language Encodes characters in variable-length character encoding Encodes characters with no overlap or confusion between conflicting bytes ranges THE standard encoding now Web page, XML, JSON for data transmission 10.4.6 Suggestions Always use the UTF-8 when you create your dataset Always check the encoding of the dataset When loading the dataset, always specify the encoding of the file Be very careful of the default encoding used in the applications from which the dataset is created/collected/edited (e.g., MS-Word, MS-Excel, Praat, SPSS etc.) In Mac/Linux, the default encoding for files is UTF-8; in Windows, it is NOT. Be very careful if you are a Windows user. 10.5 Character, Code Point, and Hexadecimal Mode (Self-study) Character: A minimal unit of text that has semantic value in the language (cf. morpheme vs. grapheme) Code Point: Any legal numeric value in the character encoding set Hexadecimal: A positional system that represents numbers using a base of 16. In R, there are a few base functions that work with these concepts: Encoding(): Read or set the declared encodings for a character vector iconv(): Convert a character vector between encodings utf8ToInt(): Convert a UTF-8 encoded character to integers (code number in decimals) as.hexamode(): Convert numbers into Hexadecimals x1 &lt;- &quot;Q&quot; Encoding(x1) [1] &quot;unknown&quot; ## Convert the encoding to UTF-8 x2 &lt;- iconv(x1, to = &quot;UTF-8&quot;) Encoding(x2) # ASCII chars are never marked with a declared encoding [1] &quot;unknown&quot; x1_decimal &lt;- utf8ToInt(x1) x1_decimal # code point of `Q` [1] 81 x1_hex &lt;- as.hexmode(x1_decimal) x1_hex # code point in hexadecimal mode of `Q` [1] &quot;51&quot; We can represent characters in UTF-8 code point (hexadecimals) by using the escape \"\\u....\": print(&quot;\\u51&quot;) [1] &quot;Q&quot; The following is an example of a Chinese character. y1 &lt;- &quot;臺&quot; Encoding(y1) # Non-ASCII char encoding in R. What&#39;s the output in Windows? [1] &quot;UTF-8&quot; y1_decimal&lt;- utf8ToInt(y1) y1_decimal [1] 33274 y1_hex&lt;-as.hexmode(y1_decimal) y1_hex [1] &quot;81fa&quot; print(&quot;\\u81fa&quot;) [1] &quot;臺&quot; Exercise 10.1 What is the character of the Unicode code point (hexadecimal) U+20AC? How do you find out the character in R? Exercise 10.2 What is the Unicode code point (hexadecimal) for the character 我 and 你? Which character is larger in terms of the code points? Hexadecimal numerals are widely used by computer system designers and programmers, as they provide a human-friendly representation of binary-coded values. One single byte can encode 256 different characters, whose values may range from 00000000 to 11111111 in binary form. These binary forms can be represented as 00 to FF in hexadecimal. 10.6 R Base Functions 10.6.1 readLines() As we are often dealing with text data, we may need to import text files in R for further data processing. In R, there is a base function readLines(), which reads a txt file with the line breaks as the delimiter and returns the content of the file as a (character) vector. That is, each line in the text will be one element in the vector. alice &lt;- readLines(con = &quot;demo_data/corp-alice.txt&quot; ) alice[1:10] [1] &quot;[Alice&#39;s Adventures in Wonderland by Lewis Carroll 1865]&quot; [2] &quot;&quot; [3] &quot;CHAPTER I. Down the Rabbit-Hole&quot; [4] &quot;&quot; [5] &quot;Alice was beginning to get very tired of sitting by her sister on the&quot; [6] &quot;bank, and of having nothing to do: once or twice she had peeped into the&quot; [7] &quot;book her sister was reading, but it had no pictures or conversations in&quot; [8] &quot;it, &#39;and what is the use of a book,&#39; thought Alice &#39;without pictures or&quot; [9] &quot;conversation?&#39;&quot; [10] &quot;&quot; class(alice) [1] &quot;character&quot; length(alice) [1] 3331 Depending on how you arrange the contents in the text file, you may sometimes get a vector of different types: If each paragraph in the text file is a word, you get a word-based vector. If each paragraph in the text file is a sentence, you get a sentence-based vector. If each paragraph in the text file is a paragraph, you get a paragraph-based vector. Exercise 10.3 Based on the inspection of the vector alice created above, what is the content of each line in the original txt file (demo_data/corp-alice.txt)? If you need to import text files with specific encoding (e.g., big-5, utf-8, ISO8859-1), the recommended method is as follows: infile &lt;- file(description = &quot;demo_data/data-chinese-poem-big5.txt&quot;, encoding = &quot;big-5&quot;) ## file as a connection text_ch_big5 &lt;- readLines(infile) ## read texts from the connection close(infile) ## close the connection writeLines(text_ch_big5) 春 眠 不 覺 曉 ， 處 處 聞 啼 鳥 。 夜 來 風 雨 聲 ， 花 落 知 多 少 。 infile &lt;- file(description = &quot;demo_data/data-chinese-poem-utf8.txt&quot;, encoding = &quot;utf-8&quot;) text_ch_big5 &lt;- readLines(infile) close(infile) writeLines(text_ch_big5) 春 眠 不 覺 曉 ， 處 處 聞 啼 鳥 。 夜 來 風 雨 聲 ， 花 落 知 多 少 。 You can play with the following methods of loading the text files into R. Like I said, the above method is always recommended. It seems that the encoding settings within the readlines() or other R-native data loading functions (e.g., scan()) do not always work properly. (This is due to the variation of the operation systems and also the default locale of the OS.) x &lt;- readLines(&quot;demo_data/data-chinese-poem-big5.txt&quot;, encoding=&quot;big-5&quot;) y &lt;- scan(&quot;demo_data/data-chinese-poem-big5.txt&quot;, what=&quot;c&quot;,sep=&quot;\\n&quot;, encoding=&quot;big-5&quot;) y1 &lt;- scan(&quot;demo_data/data-chinese-poem-big5.txt&quot;, what=&quot;c&quot;,sep=&quot;\\n&quot;, fileEncoding=&quot;big-5&quot;) ## The input texts do not show up properly? writeLines(x) writeLines(y) writeLines(y1) ## convert the input texts into your system default encoding writeLines(iconv(x, from=&quot;big-5&quot;,to=&quot;utf-8&quot;)) writeLines(iconv(y, from=&quot;big-5&quot;, to=&quot;utf-8&quot;)) 10.6.2 writeLines() After processing the data in R, we often need to save our data in an external file for future reference. For text data, we can use the base function writeLines() to save a character vector. By default, each element will be delimited by a line break after it is exported to the file. output &lt;- sample(alice[nzchar(alice)],10) writeLines(output, con = &quot;corp-alice-2.txt&quot;) Please note that when you writeLines(), you may also need to pay attention to the default encoding of the output file. This is especially important for Windows users. I think R will use the system default encoding as the expected encoding of the output file. For Mac, it’s UTF-8, which is perfect. However, for Windows, it is NOT. It depends on your OS language. Can you try to do the following and check the encoding of the output file? x &lt;- &quot;鳳凰臺上鳳凰遊，鳳去臺空江自流。&quot; Encoding(x) # `iconvlist()` check all encodings [1] &quot;UTF-8&quot; ## For Mac Users, we can output files in different encodings as follows. ## method1 writeLines(x, con = &quot;output_test_1.txt&quot;) ## method2 con &lt;- file(description = &quot;output_test_2.txt&quot;, encoding=&quot;big-5&quot;) writeLines(x, con) close(con) ## method3 con &lt;- file(description = &quot;output_test_3.txt&quot;, encoding=&quot;utf-8&quot;) writeLines(x, con) close(con) ## For Windows Users, please try the following? x_big5 &lt;- iconv(x, from=&quot;utf-8&quot;, to = &quot;big-5&quot;) writeLines(x, con = &quot;output_test_w_1.txt&quot;, useBytes = TRUE) writeLines(x_big5, con = &quot;output_test_w_2.txt&quot;, useBytes = TRUE) It is said that writeLines() will attempt to re-encode the provided text to the native encoding of the system. This works fine when the system default is UTF-8. But in Windows, the default is NOT UTF-8. I can’t say I fully understand how the encoding system works with Windows. If you would like to know more about this, please refer to this article: String Encoding and R. Exercise 10.4 Please describe the meaning of the data processing in the code chunk above: sample(alice[nzchar(alice)],10). What did it do with the vector alice? Exercise 10.5 The above code is repeated below. How do you re-write the code using the %&gt;% pipe-based syntax with a structure provided below? Your output should be exactly the same as the output produced by the original codes. library(tidyverse) alice %&gt;% ... %&gt;% ... ... %&gt;% ... %&gt;% writeLiens(con=&quot;corp-alice-2.txt&quot;) Exercise 10.6 In our demo_data directory, there are three text files in different encodings: demo_data/chinese_gb2312.txt demo_data/chinese_big5.txt demo_data/chinese_utf8.txt Please figure out ways to load these files into R as vectors properly. All three files include the same texts: [1] &quot;這是中文字串。&quot; &quot;文本也有English Characters。&quot; The simplified Chinese version (i.e., chinese_gb2312.txt) [1] &quot;这是中文字串。&quot; &quot;文本也有English Characters。&quot; 10.7 readr Functions 10.7.1 readr::read_csv() Another common source of data is a spreadsheet-like tabular file, which corresponds to the data.frame in R. Usually we save these tabular data in a csv file, i.e., a comma-separated file. Although R has its own base functions for csv-files reading (e.g., read.table(), read.csv() etc.), here we will use the more powerful version read_csv() provided in the library of readr: library(readr) nobel &lt;- read_csv(&quot;demo_data/data-nobel-laureates.csv&quot;) nobel The csv file is in fact a normal plain-text file. Each line consists of a row data, with the columns separated by commas. Sometimes we may receive a data set with other self-defined characters as the delimiter. Another often-seen case is to use the tab as the delimiter. Files with tab as the delimiter are often with the extension tsv. In readr, we can use read_tsv() to read tsv files. gender_freq &lt;- read_tsv(file = &quot;demo_data/data-stats-f1-freq.tsv&quot;) gender_freq 10.7.2 readr::write_csv() In readr, we can also export our data frames to external files, using write_csv() or write_tsv(). Exercise 10.7 Load the plain-text csv file demo_data/data-bnc-bigram.csv into a data frame and print the top 20 bigrams in the R console arranged by their frequencies (i.e., bi.freq column). Exercise 10.8 Following Exercise 10.7, please export the data frame of the top 20 bigrams to an external file, named data-bnc-bigram-10.csv, and save it under your current working directory. 10.8 Directory Operations When we work with external files, we often need to deal with directories as well. Most importantly, we need to know both the paths and filenames of the external data in order to properly load the data into R. 10.8.1 Working Directory Whenever you start the RStudio, R will take a directory as the working directory. If you start RStudio with the app icon, Rstudio will take your system default directory as the working directory. If you start Rstudio by opening a specific R script, RStudio will take the script source file location as the working directory. 10.8.2 Relative vs. Absolute Paths There are two ways to tell R where your external file is. You can always specify the full path to your file: &quot;C:/Users/Alvin/Documents/ENC2055/demo_data/data-bnc-bigrams.csv&quot; However, it can be very troublesome if we need to specify the full paths all the time. The other alternative is to specify the relative path to the file in relation to the current working directory. That is, a relative file path starts with the working directory. By default, if you have only the filename, R will look for the file from the working directory of the current R session. For example, in the following code, R will look for a file called data-bnc-bigram.csv under the working directory. If there is no such file, you will get an error message. x &lt;- read_csv(&quot;data-bnc-bigram.csv&quot;) In the following code, R will look for a sub-directory under the working directory called demo_data, and within the demo_data sub-directory, R will further look for the file data-bnc-bigram-csv. x &lt;- read_csv(&quot;demo_data/data-bnc-bigram.csv&quot;) In the following code, R will look for a file called data-bnc-bigram.csv from the parent directory of the working directory. x &lt;- read_csv(&quot;../data-bnc-bigram.csv&quot;) When using the relative path to specify file locations, the .. signifies the parent directory of the current working directory. People sometimes use the . to refer to the current working directory. 10.8.3 Directory Operations There are a few important directory operations that we often need when working with files (import/export): getwd(): check the working directory of the current R session setwd(): set the working directory for the current R session getwd() setwd() By default, R looks for the filename or the path under the working directory unless the absolute/relative path to the files/directories is particularly specified. dir(path = &quot;demo_data&quot;, full.names = FALSE, recursive = FALSE) file.exists(&quot;demo_data/data-bnc-bigram.csv&quot;) dir(path = &quot;../../&quot;) A common scenario is that we often need to load all the files from a specific directory. This usually requires a few steps: First, we need to get a list of the filenames included in the directory. Then we need to load the data of each file into R based on the filenames. Please download the four text files from demo_data/shakespeare for the following example. ## Corpus root directory corpus_root_dir &lt;- &quot;demo_data/shakespeare&quot; ## Get the filenames from the directory flist &lt;- dir(path = corpus_root_dir, full.names = TRUE) flist [1] &quot;demo_data/shakespeare/Hamlet, Prince of Denmark.txt&quot; [2] &quot;demo_data/shakespeare/King Lear.txt&quot; [3] &quot;demo_data/shakespeare/Macbeth.txt&quot; [4] &quot;demo_data/shakespeare/Othello, the Moor of Venice.txt&quot; ## Holder flist_texts &lt;- list() ## Traverse each file for (i in 1:length(flist)) { flist_texts[[i]] &lt;- readLines(flist[i]) } ## First 50 lines of Text 1 flist_texts[[1]][1:50] [1] &quot;&lt; Shakespeare -- HAMLET, PRINCE OF DENMARK &gt;&quot; [2] &quot;&lt; from Online Library of Liberty (http://oll.libertyfund.org) &gt;&quot; [3] &quot;&lt; Unicode .txt version by Mike Scott (http://www.lexically.net) &gt;&quot; [4] &quot;&lt; from \\&quot;The Complete Works of William Shakespeare\\&quot; &gt;&quot; [5] &quot;&lt; ed. with a glossary by W.J. Craig M.A. &gt;&quot; [6] &quot;&lt; (London: Oxford University Press, 1916) &gt;&quot; [7] &quot;\\tGhost of Hamlet&#39;s Father.&quot; [8] &quot;&lt;STAGE DIR&gt;&quot; [9] &quot;&lt;Scene.—Elsinore.&gt;&quot; [10] &quot;&lt;/STAGE DIR&gt;&quot; [11] &quot;&quot; [12] &quot;&quot; [13] &quot;&lt;ACT 1&gt;&quot; [14] &quot;&quot; [15] &quot;&quot; [16] &quot;&lt;SCENE 1&gt;&quot; [17] &quot;&lt;Elsinore. A Platform before the Castle.&gt;&quot; [18] &quot;&lt;STAGE DIR&gt;&quot; [19] &quot;&lt;Francisco at his post. Enter to him Bernardo.&gt;&quot; [20] &quot;&lt;/STAGE DIR&gt;&quot; [21] &quot;&lt;BERNARDO&gt;\\t&lt;0%&gt;&quot; [22] &quot;\\tWho&#39;s there?&quot; [23] &quot;&lt;/BERNARDO&gt;&quot; [24] &quot;&quot; [25] &quot;&lt;FRANCISCO&gt;\\t&lt;0%&gt;&quot; [26] &quot;\\tNay, answer me; stand, and unfold yourself.&quot; [27] &quot;&lt;/FRANCISCO&gt;&quot; [28] &quot;&quot; [29] &quot;&lt;BERNARDO&gt;\\t&lt;0%&gt;&quot; [30] &quot;\\tLong live the king!&quot; [31] &quot;&lt;/BERNARDO&gt;&quot; [32] &quot;&quot; [33] &quot;&lt;FRANCISCO&gt;\\t&lt;0%&gt;&quot; [34] &quot;\\tBernardo?&quot; [35] &quot;&lt;/FRANCISCO&gt;&quot; [36] &quot;&quot; [37] &quot;&lt;BERNARDO&gt;\\t&lt;0%&gt;&quot; [38] &quot;\\tHe.&quot; [39] &quot;&lt;/BERNARDO&gt;&quot; [40] &quot;&quot; [41] &quot;&lt;FRANCISCO&gt;\\t&lt;0%&gt;&quot; [42] &quot;\\tYou come most carefully upon your hour.&quot; [43] &quot;&lt;/FRANCISCO&gt;&quot; [44] &quot;&quot; [45] &quot;&lt;BERNARDO&gt;\\t&lt;0%&gt;&quot; [46] &quot;\\t&#39;Tis now struck twelve; get thee to bed, Francisco.&quot; [47] &quot;&lt;/BERNARDO&gt;&quot; [48] &quot;&quot; [49] &quot;&lt;FRANCISCO&gt;\\t&lt;0%&gt;&quot; [50] &quot;\\tFor this relief much thanks; &#39;tis bitter cold,&quot; Exercise 10.9 Please make yourself familar with the following commands: file.create(), dir.create(), unlink(), basename(),file.info(), save(), and load(). Exercise 10.10 Please create a sub-directory in your working directory, named temp. Load the dataset demo_data/data-bnc-bigram.csv and subset bigrams whose bigram frequencies (bi.freq column) are larger than 200. Order the sub data frame according to the bigram frequencies in a descending order and save the sub data frame into a csv file named data-bnc-bigram-freq200.csv in the temp directory. bnc_bigram_freq200 &lt;- read_csv(&quot;temp/data-bnc-bigram-freq200.csv&quot;) bnc_bigram_freq200 "],["iteration.html", "Chapter 11 Iteration 11.1 Code Duplication 11.2 vector vs. list in R 11.3 Iteration 11.4 purr 11.5 purr + dplyr 11.6 map() with self-defined functions", " Chapter 11 Iteration 11.1 Code Duplication Code duplication is often a big issue in coding. When you repeat same codes very often, it is also more difficult to maintain and debug the script. There are in general two major ways to reduce duplication in coding: Wrap the duplicate procedures into a function Use iteration According to Wickham &amp; Grolemund (2017) Chapter 21 Iteration, there are three main advantages of reducing code duplication: It’s easier to see the intent/objective of your code, because your eyes are drawn to what’s different, not what stays the same. It’s easier to respond to changes required for code maintenance. Without much code duplication, you only need to make changes in one place, rather than remembering to change every place that you have copied-and-pasted the code. You’re likely to have fewer bugs because each line of code is used in more places. In this chapter, we talk about code efficiency. In particular, we will work with the library purr. 11.2 vector vs. list in R Most of the R-internal functions are vectorized. By default, if we apply a function to a multi-element vector, R will automatically apply the same procedure to each element of the vector, and return the results of the same length. a.vec &lt;- c(1:10) sqrt(a.vec) [1] 1.000000 1.414214 1.732051 2.000000 2.236068 2.449490 2.645751 2.828427 [9] 3.000000 3.162278 round(a.vec, 2) [1] 1 2 3 4 5 6 7 8 9 10 But this is NOT something we can do with a list: a.list &lt;- list(1, 2, 3, 4, 5, 6, 7, 8, 9, 10) sqrt(a.list) Error in sqrt(a.list): non-numeric argument to mathematical function You may now recall that in Chapter 5 , we have introduced the control structure of for-loop, which allows us to perform a specific procedure to every element of a list. a.list &lt;- list(1, 2, 3, 4, 5, 6, 7, 8, 9, 10) results &lt;- vector() # empty list holder for(i in 1:length(a.list)){ results[i] &lt;- sqrt(a.list[[i]]) } results [1] 1.000000 1.414214 1.732051 2.000000 2.236068 2.449490 2.645751 2.828427 [9] 3.000000 3.162278 In this chapter, we will look at more efficient ways of dealing with iteration with other non-vector objects (e.g., list, data.frame etc.) 11.3 Iteration As we work with list and data.frame (tibble) very often, it would be great if we can have an easy way to apply the same procedure to: each element in the list each row in the data.frame each column in the data.frame These three scenarios are the most-often used contexts for iteration. Let’s start with a example. We first create a pseudo data set, i.e., a list with students’ grades from five different classes. exams.list &lt;- list( class1 = round(runif(30, 0, 100)), # 30 tokens of random numbers in the range &lt;0, 100&gt; class2 = round(runif(30, 0, 100)), class3 = round(runif(30, 0, 100)), class4 = round(runif(30, 0, 100)), class5 = round(runif(30, 0, 100)) ) exams.list $class1 [1] 41 41 37 15 14 23 47 27 86 5 44 80 12 56 21 13 75 90 37 67 9 38 27 81 45 [26] 81 81 79 44 75 $class2 [1] 63 71 0 48 22 38 61 35 11 24 67 42 79 10 43 98 89 89 18 13 65 34 66 32 19 [26] 78 9 47 51 60 $class3 [1] 33 49 95 48 89 91 61 41 15 94 30 6 95 72 14 55 95 59 40 65 32 31 22 37 98 [26] 15 9 14 69 62 $class4 [1] 89 67 74 52 66 82 79 98 44 31 41 1 18 84 23 24 8 25 73 85 50 39 25 11 39 [26] 57 22 44 22 50 $class5 [1] 35 65 37 36 53 74 22 41 27 63 18 86 75 67 62 37 53 87 58 84 31 71 27 59 48 [26] 27 56 91 90 27 If we like to compute the mean scores of each cluster, you probably want to use mean(): mean(exams.list) [1] NA It should be clear now that mean() expects a numeric vector, on which the mean score is computed. So you may think that why not do it in a dumb way? We can compute the mean scores for each class and save all the five scores in a list: set.seed(123) # Make sure we get the same results exams.list.means &lt;- list( class1mean = mean(exams.list$class1), class2mean = mean(exams.list$class2), class3mean = mean(exams.list$class3), class4mean = mean(exams.list$class4), class5mean = mean(exams.list$class5) ) exams.list.means $class1mean [1] 46.36667 $class2mean [1] 46.06667 $class3mean [1] 51.2 $class4mean [1] 47.43333 $class5mean [1] 53.56667 The disadvantage is obvious: (a) what if you have 10 classes? 100 classes? (b) what if now you decide to compute standard deviation? The rule-of-thumb is that the more you find code duplication in your script, the more likely you need to restructure your codes with iterations. 11.4 purr library(tidyverse) Now let’s take a look at how iteration structures can help us with repeated procedures. map(exams.list, mean) $class1 [1] 46.36667 $class2 [1] 46.06667 $class3 [1] 51.2 $class4 [1] 47.43333 $class5 [1] 53.56667 ## Or, alternatively: # exams.list %&gt;% map(mean) With only one-line code, you have achieved your goal. map() is a very powerful function to do iteration. Its usage is as follows: To conceptualize this code map(exams.list, mean): For each element in the exams.list, apply the function mean Do the first element, and save the result in the first element of the new list Do the second element, and save the result in the second element of the new list … After finishing all elements in the exams.list, return the new list result In purrr, by default map() returns results in a list format. You can specify a particular data structure as the returned value of map_*()by using other variants of the mapping function: map_df(exams.list, mean) map_dbl(exams.list, mean) class1 class2 class3 class4 class5 46.36667 46.06667 51.20000 47.43333 53.56667 Exercise 11.1 Use the same dataset, exam.list, and compute the median and standard deviation values for each class. Have these values returned as vectors. Median class1 class2 class3 class4 class5 42.5 45.0 48.5 44.0 54.5 Standard Deviation class1 class2 class3 class4 class5 26.98465 27.10126 29.99241 27.07930 22.37407 Exercise 11.2 Similar to the previous exercise, how can you use the same dataset, exam.list, compute the median and standard deviation values for each class, and have both of these values returned as a data.frame (The first row refers to the median values and the second row refers to the standard deviation values.) Please use map_df() to produce the following expected result. 11.5 purr + dplyr The map() function can be very powerful and efficient in data frame manipulation when used in combination with the mutate(). Let’s first load the dataset of four-word idioms from the previous chapter. ## reading utf8 file con &lt;- file(description = &quot;demo_data/dict-ch-idiom.txt&quot;, encoding = &quot;utf-8&quot;) texts &lt;- readLines(con) close(con) ## convert into data frame idiom &lt;- tibble(string = texts) idiom Now if we would like to find out whether each idiom has duplicate characters in it, we can make use of regular expressions: x &lt;- idiom$string[1:10] str_detect(x, &quot;.*(.).*\\\\1.*&quot;) [1] FALSE FALSE FALSE FALSE FALSE FALSE TRUE TRUE TRUE FALSE What if we would like to include this information in an independent column of idiom? Two important things should come up in your mind: We need mutate() to help us create a new column We need to apply the above procedure, str_detect(), to each element in the column idiom$string. So would you give it a try? (The following example shows only rows whose duplicate column is TRUE) Exercise 11.3 This exercise will use the subset of idiom, which include only four-word idioms with at least one duplicate character in them. Please create a new column, showing how many types of duplications there are in each idiom? For example, in 阿狗阿貓, there is only one duplicate character 阿; but in 矮矮胖胖, there are two duplicate characters, 矮 and 胖. Exercise 11.4 Continuing the previous exercise, please create another new column, showing all the duplicate characters in each idiom. For example, in 阿狗阿貓, the duplicate character is 阿; but in 矮矮胖胖, the duplicate character is矮_胖. That is, if the idiom has more than one duplicate character, please use the _ as the delimiter and concatenate all duplicate characters into a long string. Exercise 11.5 Based on the previous exercise, please analyze the distribution of all the duplicate characters in the four-character idioms included in the dictionary (i.e., the duplicate_char column from the previous exercise) and identify the top 20 duplicate characters. Please visualize your results in a bar plot with both the top 20 duplicate characters as well as the number of the character’s duplications in the idiom. 11.6 map() with self-defined functions With the power and flexibility of purrr::map(), we can basically do everything iteratively. More attractively, we can apply a self-defined function as well! (Please see Chapter 6 for how to create a self-defined function in R.) A function object is defined using the following template: FUNCTION_NAME &lt;- function(ARG1, ARG2) { THINGS TO BE DONE WITHIN THE FUNCTION return(...) } A function object usually include: Self-defined name Arguments Return Let’s consider a simple example. First we create a self-defined function my_center(): This function takes a vector object x Subtract each element of x by the mean score of x return the resulting vector as the output of the function my_center &lt;- function(x) { x - mean(x) } Now we can apply our my_center function to each class in exams.list: map_df(exams.list, my_center) Exercise 11.6 Use the built-in the mtcars dataset (?mtcars for more detail). How do you get the class type of each column in the mtcars by using map()? Exercise 11.7 Create a self-defined function to convert each number of a numeric vector to a “z” score. y &lt;- c(1, 4, 6, 10, 20) my_z(y) [1] -0.9779865 -0.5704921 -0.2988292 0.2444966 1.6028112 Exercise 11.8 Use the earlier dataset exams.list. For each element in exams.list, please convert the student’s score to a z-score by applying your self-defined function in an iterative structure (e.g., map). Please present the result as a data frame. References Wickham, H., &amp; Grolemund, G. (2017). R for data science: Import, tidy, transform, visualize, and model data (1st ed.). O’Reilly Media, Inc. "],["data-scientist-first-step.html", "Chapter 12 Data Scientist First Step 12.1 Loading Nobel Laureates Dataset 12.2 Workflow 12.3 Column Names 12.4 Missing Data (NA values) 12.5 Data Preprocessing 12.6 Exploratory Analysis 12.7 Exercises", " Chapter 12 Data Scientist First Step Finally this chapter will demonstrate how you can make use of what you have learned from the previous chapters to perform an exploratory data analysis on the dataset you are interested in. Here we will look at a dataset of Nobel Laureates. Before you start, always remember to load necessary R libraries first. library(tidyverse) 12.1 Loading Nobel Laureates Dataset my_df &lt;- read_csv(&quot;demo_data/data-nobel-laureates.csv&quot;) my_df 12.2 Workflow 12.3 Column Names Before we start, it is clear to see that the column names are full of spaces, which we would like to get rid off. So first, we remove all the spaces in the columns and replace them with _: # original column names names(my_df) [1] &quot;Year&quot; &quot;Category&quot; &quot;Prize&quot; [4] &quot;Motivation&quot; &quot;Prize Share&quot; &quot;Laureate ID&quot; [7] &quot;Laureate Type&quot; &quot;Full Name&quot; &quot;Birth Date&quot; [10] &quot;Birth City&quot; &quot;Birth Country&quot; &quot;Sex&quot; [13] &quot;Organization Name&quot; &quot;Organization City&quot; &quot;Organization Country&quot; [16] &quot;Death Date&quot; &quot;Death City&quot; &quot;Death Country&quot; # overwrite the original with new ones names(my_df) &lt;- str_replace_all(names(my_df), &quot;\\\\s&quot;,&quot;_&quot;) # autoprint updated my_df my_df names(my_df) [1] &quot;Year&quot; &quot;Category&quot; &quot;Prize&quot; [4] &quot;Motivation&quot; &quot;Prize_Share&quot; &quot;Laureate_ID&quot; [7] &quot;Laureate_Type&quot; &quot;Full_Name&quot; &quot;Birth_Date&quot; [10] &quot;Birth_City&quot; &quot;Birth_Country&quot; &quot;Sex&quot; [13] &quot;Organization_Name&quot; &quot;Organization_City&quot; &quot;Organization_Country&quot; [16] &quot;Death_Date&quot; &quot;Death_City&quot; &quot;Death_Country&quot; 12.4 Missing Data (NA values) It is always important to check if the information of each row is complete. We first define a function check_num_NA(), which checks the number of NA values of the input x object We then map() this self-defined function to each column of the my_df # define a function check_num_NA &lt;- function(x){ x %&gt;% is.na %&gt;% sum } # map the function to the data frame my_df %&gt;% map_df(check_num_NA) ## Alternatively, you can write this way: # map_df(my_df, check_num_NA) From the above results, we see that Sex column has 26 cases of NA values. We can check rows with NA’s by filtering out these cases: my_df %&gt;% filter(is.na(Sex)) 12.5 Data Preprocessing Usually before we proceed with the data analysis, we need to preprocess the data to make sure that the data is prepared in an appropriate way for later quantitative (statistical) analysis. my_df %&gt;% filter(Birth_Country == &quot;China&quot;) my_df %&gt;% select(Year, Full_Name, Birth_Date, Category) Common considerations may include: We lower all character vectors (i.e., normalizing the letter casing) We identify duplicate tokens in our dataset We create new columns (that may better reflect the factors we would like to investigate): Decade Prize_Age nobel_winners &lt;- my_df %&gt;% mutate_if(is.character, tolower) %&gt;% # lower all character vectors distinct_at(vars(Full_Name, Year, Category), .keep_all = TRUE) %&gt;% mutate(Decade = 10 * (Year %/% 10), Prize_Age = Year - lubridate::year(Birth_Date)) nobel_winners Given two positive integers, normally, we define the division as follows: a / b in R. There are two variants of the integer division: a %% b (a modulo b): This modulo operation will return the remainder of the division (The expression 5 %% 3 would evaluate to 2). a %/% b: This integer division operation will return the quotient of the division (The expression 5 %/% 3 would evaluate to 1). We often use this modulo operation to check if an output value is a multiple of a specific integer. We can check if our new Prize_Age has any NA values? nobel_winners %&gt;% filter(is.na(Prize_Age)) %&gt;% select(Year, Full_Name, Birth_Date, Prize_Age) Check Chinese laureates again: nobel_winners %&gt;% filter(Birth_Country == &quot;china&quot;) %&gt;% select(Full_Name, Year, Category) 12.6 Exploratory Analysis In this section, we will see how we can create relevant statistics/graphs for the research questions we are interested in. 12.6.1 Discipline Distribution RQ: How many laureates were there in different disciplines? # statistics nobel_winners %&gt;% count(Category) %&gt;% mutate(percent = round(n/sum(n),2)) # barplots nobel_winners %&gt;% count(Category) %&gt;% ggplot(aes(x = Category, y = n, fill = Category)) + geom_col() + geom_text(aes(label = n), vjust = -0.25) + labs(title = &quot;No. of Laureates in Different Disciplines&quot;, x = &quot;Category&quot;, y = &quot;N&quot;) + theme(legend.position = &quot;none&quot;) # barplots (ordered) nobel_winners %&gt;% count(Category) %&gt;% ggplot(aes(x = fct_reorder(Category, -n), y = n, fill = Category)) + geom_col() + geom_text(aes(label = n), vjust = -0.25) + labs(title = &quot;No. of Laureates in Different Disciplines&quot;, x = &quot;Category&quot;, y = &quot;N&quot;) + theme(legend.position = &quot;none&quot;) An even more dynamic graph: # barplot (dynamic) library(gganimate) #install.packages(&quot;gganimate&quot;, dependencies = T) my_df %&gt;% count(Category) %&gt;% mutate(Category = fct_reorder(Category, -n)) %&gt;% ggplot(aes(x = Category, y = n, fill = Category)) + geom_text(aes(label = n), vjust = -0.25) + geom_col()+ labs(title = &quot;No. of Laureates in Different Disciplines&quot;, x = &quot;Category&quot;, y = &quot;N&quot;) + theme(legend.position = &quot;none&quot;) + transition_states(Category) + shadow_mark(past = TRUE) 12.6.2 Age Distribution RQ: At what age did laureates normally win their Nobel Prizes? # statistics summary(nobel_winners$Prize_Age) Min. 1st Qu. Median Mean 3rd Qu. Max. NA&#39;s 17.00 50.00 60.00 59.45 69.00 90.00 30 psych::describe(nobel_winners$Prize_Age) %&gt;% t X1 vars 1.00000000 n 881.00000000 mean 59.45175936 sd 12.41297890 median 60.00000000 trimmed 59.50496454 mad 13.34340000 min 17.00000000 max 90.00000000 range 73.00000000 skew -0.04907038 kurtosis -0.44875709 se 0.41820389 # histogram nobel_winners %&gt;% filter(!is.na(Prize_Age)) %&gt;% ggplot(aes(x = Prize_Age)) + geom_histogram(color=&quot;white&quot;) # boxplot nobel_winners %&gt;% filter(!is.na(Prize_Age)) %&gt;% ggplot(aes(y = Prize_Age)) + geom_boxplot() 12.6.3 Category x Age Interaction RQ: Does the age of prize-winning vary for different prize categories? # Statistics nobel_winners %&gt;% filter(!is.na(Prize_Age)) %&gt;% group_by(Category) %&gt;% summarize(mean_age = mean(Prize_Age), sd_age = sd(Prize_Age)) %&gt;% ungroup %&gt;% arrange(mean_age) # Histogram nobel_winners %&gt;% filter(!is.na(Prize_Age)) %&gt;% ggplot(aes(x = Prize_Age, fill = Category, color = Category)) + geom_histogram(color=&quot;white&quot;) + facet_wrap(~Category) + theme(legend.position = &quot;none&quot;) # Density graphs nobel_winners %&gt;% filter(!is.na(Prize_Age)) %&gt;% ggplot(aes(x = Prize_Age, fill = Category, color = Category)) + geom_density() + facet_wrap(~Category) + theme(legend.position = &quot;none&quot;) # boxplot nobel_winners %&gt;% filter(!is.na(Prize_Age)) %&gt;% ggplot(aes(x = Category, y = Prize_Age, fill = Category))+ geom_boxplot(notch=T) # mean and CI plots nobel_winners %&gt;% filter(!is.na(Prize_Age)) %&gt;% ggplot(aes(Category, Prize_Age, fill = Category)) + stat_summary(fun = mean, geom = &quot;bar&quot;, fill=&quot;white&quot;, color=&quot;black&quot;) + stat_summary(fun.data = function(x) mean_se(x, mult = 1.96), geom = &quot;errorbar&quot;, width = 0.1, color=&quot;grey40&quot;) 12.6.4 Gender Distribution RQ: What is the gender distribution of Nobel winners? # statistics nobel_winners %&gt;% filter(!is.na(Sex)) %&gt;% count(Sex) %&gt;% mutate(percent = round(n/sum(n),2)) # graphs nobel_winners %&gt;% filter(!is.na(Sex)) %&gt;% ggplot(aes(Sex)) + geom_bar(fill=&quot;white&quot;,color=&quot;black&quot;) 12.6.5 Age x Gender Interaction Did the ages differ greatly for male and female winners? # statistics nobel_winners %&gt;% filter(!is.na(Sex) &amp; !is.na(Prize_Age)) %&gt;% group_by(Sex) %&gt;% summarize(mean_prize_age = mean(Prize_Age), sd_prize_age = sd(Prize_Age), min_prize_age = min(Prize_Age), max_prize_age = max(Prize_Age), N = n()) -&gt; sum_sex_age sum_sex_age As for visualization, we can create boxplots for male and female winners. nobel_winners %&gt;% filter(!is.na(Sex) &amp; !is.na(Prize_Age)) %&gt;% ggplot(aes(Sex, Prize_Age, fill=Sex)) + geom_boxplot(notch=T, color=&quot;grey30&quot;) + scale_fill_manual(values = c(&quot;lightpink&quot;,&quot;lightblue&quot;)) Or alternatively, we can create the mean and confidence interval plots for each sex. #require(Hmisc) # you have to have this for `stat_summary()` nobel_winners %&gt;% filter(!is.na(Sex) &amp; !is.na(Prize_Age)) %&gt;% ggplot(aes(Sex, Prize_Age, color=Sex)) + stat_summary(fun = mean, geom = &quot;point&quot;, size = 2) + stat_summary(fun.data = function(x) mean_se(x, mult=1.96), geom = &quot;errorbar&quot;, width = 0.1) We can create an informative graph showing not only the mean ages of male and female winners, but also their respective minimum and maxinum ages. sum_sex_age %&gt;% pivot_longer(cols = c(&quot;mean_prize_age&quot;,&quot;min_prize_age&quot;, &quot;max_prize_age&quot;), names_to = &quot;Prize_Age&quot;, values_to = &quot;Age&quot;) %&gt;% mutate(Prize_Age = str_replace_all(Prize_Age, &quot;_prize_age$&quot;,&quot;&quot;)) %&gt;% ggplot(aes(Sex, Age, fill=Prize_Age)) + geom_bar(stat=&quot;identity&quot;, width = 0.8, color=&quot;white&quot;, position = position_dodge(0.8)) 12.7 Exercises Exercise 12.1 Create a subset of nobel_winners, which includes only winners who won the prizes more than once and in more than one category. Exercise 12.2 Please create a data frame of summary statistics, which shows us the distributions of male and female winners in different categories as shown below. Also, please show the number of males and females as well as the proportions for each prize category. (i.e., frequencies and normalizaed frequencies) Exercise 12.3 Please show us the states distribution of the US Nobel Winners. This would give us an idea which state in the United States has the most Nobel winners. For US winners, you can extract their birth states from their birth cities (using regular expressions of course): nobel_winners %&gt;% filter(Birth_Country == &quot;united states of america&quot;) %&gt;% select(Year, Category, Full_Name, Birth_City) Exercise 12.4 Following Exercise 12.3, can you include the full names of states in the above table by adding another column? In the demo-data/US-states-csv, you can find a csv with the mapping between states abbreviations and their full names. The US-states.csv dataset US_states &lt;- read_csv(&quot;demo_data/US-states.csv&quot;) US_states "],["text-analytics-a-start.html", "Chapter 13 Text Analytics: A Start 13.1 Installing quanteda 13.2 Building a corpus from character vector 13.3 Tokenization 13.4 Keyword-in-Context (KWIC) 13.5 KWIC with Regular Expressions 13.6 Lexical Density Plot 13.7 Document-Feature Matrix 13.8 Feature Selection 13.9 Top Features 13.10 Wordclouds 13.11 Keyness Analysis 13.12 Flowchart 13.13 Exercises", " Chapter 13 Text Analytics: A Start In this chapter, I will present a quick overview of computational text analytics with R. The most important package for exploratory text analysis is quanteda. As computational text analytics itself is an interesting topic, I would recommend other more advanced courses for those who are interested in this field (e.g., Corpus Linguistics, Computational Linguistics) This chapter only provides you a very general overview of the common procedures/tasks in text processing. 13.1 Installing quanteda There are many packages that are made for computational text analytics in R. You may consult the CRAN Task View: Natural Language Processing for a lot more alternatives. To start with, this tutorial will use a powerful package, quanteda, for managing and analyzing textual data in R. You may refer to the official documentation of the package for more detail. The libraryquanteda is not included in the default base R installation. Please install the package if you haven’t done so. install.packages(&quot;quanteda&quot;) install.packages(&quot;readtext&quot;) Also, as noted on the quanteda documentation, because this library compiles some C++ and Fortran source code, you need to install the appropriate compilers. If you are using a Windows platform, this means you will need also to install the Rtools software available from CRAN. If you are using macOS, you should install the macOS tools. If you run into any installation errors, please go to the official documentation page for additional assistance. The library quanteda contains all of the core natural language processing and textual data management functions.The following libraries work with quanteda, providing more advanced functions for computational text analytics. quanteda.textmodels: includes the text models and supporting functions (i.e., textmodel_*() functions). quanteda.textstats: includes statistic processing for textual data (i.e., textstat_*() functions). quanteda.textplots: includes plotting functions for textual data (i.e., textplot_*() functions). library(quanteda) library(quanteda.textplots) library(quanteda.textstats) library(tidyverse) packageVersion(&quot;quanteda&quot;) [1] &#39;3.2.4&#39; 13.2 Building a corpus from character vector To demonstrate a typical corpus analytic example with texts, I will be using a pre-loaded corpus that comes with the quanteda package, data_corpus_inaugural. This is a corpus of US Presidential Inaugural Address texts and metadata for the corpus from 1789 to present. data_corpus_inaugural Corpus consisting of 59 documents and 4 docvars. 1789-Washington : &quot;Fellow-Citizens of the Senate and of the House of Representa...&quot; 1793-Washington : &quot;Fellow citizens, I am again called upon by the voice of my c...&quot; 1797-Adams : &quot;When it was first perceived, in early times, that no middle ...&quot; 1801-Jefferson : &quot;Friends and Fellow Citizens: Called upon to undertake the du...&quot; 1805-Jefferson : &quot;Proceeding, fellow citizens, to that qualification which the...&quot; 1809-Madison : &quot;Unwilling to depart from examples of the most revered author...&quot; [ reached max_ndoc ... 53 more documents ] class(data_corpus_inaugural) [1] &quot;corpus&quot; &quot;character&quot; We create a corpus() object with the pre-loaded corpus in quanteda– data_corpus_inaugural: corp_us &lt;- corpus(data_corpus_inaugural) # save the `corpus` to a short obj name summary(corp_us) After the corpus is loaded, we can use summary() to get the metadata of each text in the corpus, including word types and tokens as well. This allows us to have a quick look at the size of the addresses made by all presidents. In quanteda, it has implemented a default tokenization method for English texts. I think it has also implemented a default tokenization method for Chinese texts as well. For more control on the word segmentation, you may need to consult other segmentation packages (e.g., jiebaR, ckiptagger etc.). More details are usually discussed in ENC2045 or ENC2036. corp_us %&gt;% summary %&gt;% ggplot(aes(x = Year, y = Tokens, group = 1)) + geom_line() + geom_point() + theme_bw() Exercise 13.1 Could you reproduce the above line plot and add information of President to the plot as labels of the dots? Hints: Please check ggplot2::geom_text() or more advanced one, ggrepel::geom_text_repel() 13.3 Tokenization The first step for most textual analyses is usually tokenization, i.e., breaking each long text into word tokens for linguistic analysis. corp_us_tokens &lt;- tokens(corp_us) corp_us_tokens[1] Tokens consisting of 1 document and 4 docvars. 1789-Washington : [1] &quot;Fellow-Citizens&quot; &quot;of&quot; &quot;the&quot; &quot;Senate&quot; [5] &quot;and&quot; &quot;of&quot; &quot;the&quot; &quot;House&quot; [9] &quot;of&quot; &quot;Representatives&quot; &quot;:&quot; &quot;Among&quot; [ ... and 1,525 more ] 13.4 Keyword-in-Context (KWIC) Keyword-in-Context (KWIC), or concordances, are the most frequently used method in corpus linguistics. The idea is very intuitive: we get to know more about the semantics of a word (or any other linguistic unit) by examining how it is being used in a wider context. We can use kwic() to perform a search for a word and retrieve its concordances from the corpus: kwic(corp_us_tokens, &quot;terror&quot;) kwic() returns a data frame, which can be easily exported as a CSV file for later use. Please note that kwic(), when taking a tokens object as the input argument. That is, please tokenize the corpus object with tokens() first before you perform more advanced textual analysis, e.g., kwic(). Also, with kwic(), the pattern you look for cannot be a multi-word linguistic pattern. For Chinese, quanteda can take care of Chinese word segmentation but with rather limited capacity. texts &lt;- c(&quot;舞台正中間擺著一張「空著的導演椅」，影片一下全場鼻酸。&quot;, &quot;第58屆金馬獎頒獎典禮今（27）日在國父紀念館盛大登場，星光大道紅毯於下午5點30分登場。&quot;) corpus_ch &lt;- corpus(texts) corpus_ch Corpus consisting of 2 documents. text1 : &quot;舞台正中間擺著一張「空著的導演椅」，影片一下全場鼻酸。&quot; text2 : &quot;第58屆金馬獎頒獎典禮今（27）日在國父紀念館盛大登場，星光大道紅毯於下午5點30分登場。&quot; corpus_ch_tokens &lt;- tokens(corpus_ch) corpus_ch_tokens[[1]] [1] &quot;舞台&quot; &quot;正&quot; &quot;中間&quot; &quot;擺著&quot; &quot;一張&quot; &quot;「&quot; &quot;空&quot; &quot;著&quot; &quot;的&quot; &quot;導演&quot; [11] &quot;椅&quot; &quot;」&quot; &quot;，&quot; &quot;影片&quot; &quot;一下&quot; &quot;全&quot; &quot;場&quot; &quot;鼻酸&quot; &quot;。&quot; corpus_ch_tokens[[2]] [1] &quot;第&quot; &quot;58&quot; &quot;屆&quot; &quot;金馬獎&quot; &quot;頒獎典禮&quot; [6] &quot;今&quot; &quot;（&quot; &quot;27&quot; &quot;）&quot; &quot;日&quot; [11] &quot;在&quot; &quot;國父紀念館&quot; &quot;盛大&quot; &quot;登場&quot; &quot;，&quot; [16] &quot;星光&quot; &quot;大道&quot; &quot;紅&quot; &quot;毯&quot; &quot;於&quot; [21] &quot;下午&quot; &quot;5&quot; &quot;點&quot; &quot;30&quot; &quot;分&quot; [26] &quot;登場&quot; &quot;。&quot; 13.5 KWIC with Regular Expressions For more complex searches, we can use regular expressions as well in kwic(). For example, if you want to include terror and all its other related word forms, such as terrorist, terrorism, terrors, you can do a regular expression search. corp_us_tokens &lt;- tokens(corp_us) kwic(corp_us_tokens, &quot;terror.*&quot;, valuetype = &quot;regex&quot;) By default, the kwic() is word-based. If you like to look up a multiword combination, use phrase(): kwic(corp_us_tokens, phrase(&quot;our country&quot;)) kwic(corp_us_tokens, phrase(&quot;[a-zA-Z]+ against&quot;), valuetype=&quot;regex&quot;) It should be noted that the output of kwic includes not only the concordances (i.e., preceding/subsequent co-texts + the keyword), but also the sources of the texts for each concordance line. This would be extremely convenient if you need to refer back to the original discourse context of the concordance line. Exercise 13.2 Please create a bar plot, showing the number of uses of the word country in each president’s address. Please include different variants of the word, e.g., countries, Countries, Country, in your kwic() search. 13.6 Lexical Density Plot Plotting a kwic object produces a lexical dispersion plot, which allows us to visualize the occurrences of particular terms throughout the texts. corp_us_tokens %&gt;% tokens_subset(Year &gt; 1949) %&gt;% kwic(pattern= &quot;american&quot;) %&gt;% textplot_xray() corp_us_subset &lt;- corp_us_tokens %&gt;% tokens_subset(Year &gt; 1949) textplot_xray( kwic(corp_us_subset, pattern = &quot;american&quot;), kwic(corp_us_subset, pattern = &quot;people&quot;) ) 13.7 Document-Feature Matrix Another important object class is defined in quanteda: the dfm. It stands for Document-Feature-Matrix. It’s a two-dimensional co-occurrence table, with the rows being the documents in the corpus, and columns being the features used to characterize the documents. The cells in the matrix often refer to the co-occurrence statistics between each document and the feature. Usually, we first create the tokens version of the corpus (using tokens()) and then use dfm() to create the dfm version of the corpus from tokens. That is, it is recommened to use the tokens as the input for dfm. corp_us_dfm &lt;- corp_us_tokens %&gt;% dfm class(corp_us_dfm) [1] &quot;dfm&quot; attr(,&quot;package&quot;) [1] &quot;quanteda&quot; corp_us_dfm Document-feature matrix of: 59 documents, 9,439 features (91.84% sparse) and 4 docvars. features docs fellow-citizens of the senate and house representatives : 1789-Washington 1 71 116 1 48 2 2 1 1793-Washington 0 11 13 0 2 0 0 1 1797-Adams 3 140 163 1 130 0 2 0 1801-Jefferson 2 104 130 0 81 0 0 1 1805-Jefferson 0 101 143 0 93 0 0 0 1809-Madison 1 69 104 0 43 0 0 0 features docs among vicissitudes 1789-Washington 1 1 1793-Washington 0 0 1797-Adams 4 0 1801-Jefferson 1 0 1805-Jefferson 7 0 1809-Madison 0 0 [ reached max_ndoc ... 53 more documents, reached max_nfeat ... 9,429 more features ] We can see that in the first document, i.e., 1789-Washington, there are 2 occurrences of representatives, 48 occurrences of and 13.8 Feature Selection A dfm may not be as informative as we have expected. To better capture the documental semantic similarity, there are several important factors that need to be more carefully considered with respect to the features of the dfm: The granularity of the features The informativeness of the features The distributional properties of the features Not only does dfm() provide many arguments for users to specify conditions for features selection; in quanteda, we can also apply dfm_trim() to select important features for later analysis. corp_dfm_trimmed &lt;- corp_us %&gt;% tokens( remove_punct = T, remove_numbers= T, remove_symbols = T) %&gt;% dfm %&gt;% dfm_remove(stopwords(&quot;en&quot;)) %&gt;% dfm_trim(min_termfreq = 10, termfreq_type = &quot;count&quot;, min_docfreq = 3, max_docfreq = ndoc(corp_us)-1, docfreq_type = &quot;count&quot;) dim(corp_us_dfm) [1] 59 9439 dim(corp_dfm_trimmed) [1] 59 1401 13.9 Top Features With a dfm, we can check important features from the corpus. topfeatures(corp_dfm_trimmed,10) people government us can must upon great 584 564 505 487 376 371 344 may states world 343 334 319 13.10 Wordclouds With a dfm, we can visualize important words in the corpus with a Word Cloud. It is a novel but intuitive visual representation of text data. It allows us to quickly perceive the most prominent words from a large collection of texts. corp_dfm_trimmed %&gt;% textplot_wordcloud(min_count = 50, random_order = FALSE, rotation = .25, color = RColorBrewer::brewer.pal(8, &quot;Dark2&quot;)) We can also compare word clouds for different subsets of the corpus: corpus_subset(corp_us, President %in% c(&quot;Obama&quot;, &quot;Trump&quot;, &quot;Clinton&quot;)) %&gt;% tokens(remove_punct = T, remove_numbers= T, remove_symbols = T) %&gt;% tokens_group(groups = President) %&gt;% dfm() %&gt;% dfm_remove(stopwords(&quot;en&quot;)) %&gt;% dfm_trim(min_termfreq = 5, termfreq_type = &quot;count&quot;) %&gt;% textplot_wordcloud(comparison = TRUE) 13.11 Keyness Analysis When you have two collections of texts, we can use quantitative methods to identify which words are more strongly associated with one of the two sub-corpora. This is the idea of keyword analysis. 13.12 Flowchart Finally, Figure 13.1 below provides a summary flowchart for computatutional text analytics in R. Figure 13.1: Computational Text Processing Flowchart in R 13.13 Exercises In the following exercise, please use the dataset demo_data/TW_President.tar.gz, which is a text collection of the inaugural speeches of Taiwan Presidents (till 2016). You may load the entire text collection as a corpus object using the following code: require(readtext) require(quanteda) corp_tw &lt;- readtext(&quot;demo_data/TW_President.tar.gz&quot;) %&gt;% corpus Exercise 13.3 Please create a data frame, which includes the metadata information for each text. You may start with a data frame you get from summary(corp_tw) and then create two additional columns—President and Year, which can be extracted from the text filenames in the Text column. Hint: tidyr::extract() summary(corp_tw) %&gt;% as_tibble After you create the metadata DF, please assign it to the docvars(corp_tw) for later analysis. Exercise 13.4 Please create a lexical density plot for the use of “台灣” in all presidents’ texts. Exercise 13.5 Please create a word cloud of the entire corpus corp_tw. In the word cloud, please remove punctuations, numbers, and symbols. The word cloud has to only include words whose frequency &gt;= 20. Exercise 13.6 Create word clouds showing the comparison of President Tsai (CAYANGWEN), Ma (MAYANGJIU), and Shuibian Chen (CHENSHUIBIAN). Exercise 13.7 Please create a keyness plot, showing the preferred words used by President Tsai (CAYANGWEN) vs. President Ma (MAYANGJIU). "],["python-fundamentals.html", "Chapter 14 Python Fundamentals 14.1 Set up Environment 14.2 Conda Environment 14.3 Data Type 14.4 Data Structure 14.5 String 14.6 Control Structure 14.7 Function 14.8 List Comprehension 14.9 Python Scripts 14.10 Modules 14.11 Input/Output", " Chapter 14 Python Fundamentals This unit covers Python fundamentals. All the codes here are Python codes. 14.1 Set up Environment Install Anaconda Install Jupyter Notebook/Lab (See Jupyter Notebook installation documentation) Run the codes in notebooks 14.2 Conda Environment We can create a conda environment using: $ conda create --name XXX Please specify the conda environment name XXX on your own. Similarly, when you add the self-defined conda environment to the notebook kernel list: $ python -m ipykernel install --user --name=XXX You need to specify the conda environment name XXX. There are several important things here: You need to install the relevant modules AFTER you activate the conda environment in the terminal. You need to add the kernel name with python -m ipykernel install --user --name=XXX within the conda enviroment as well. In other words, you need to install the module ipykernel in the target conda environment as well. After a few trial-and-errors, I think the best environment setting is that you only add the kernel name (conda environment) to ipykernel within the conda environment. Do not add the conda environment again in your base python environment. What’s even better is to install jupyter in your conda environment (python-notes) and run your notebook from this python-notes as well. 14.3 Data Type String Numbers (Integers and Floats) Data Type Conversion Input a = &#39;cats&#39; b = &#39;dogs&#39; print(a + b) catsdogs a = 12 b = 13 print(a+b) 25 14.4 Data Structure List Tuple Dictionary vocab = [&#39;cat&#39;, &#39;dog&#39;, &#39;bird&#39;] word_pos = ((&#39;cat&#39;,&#39;n&#39;),(&#39;dog&#39;,&#39;n&#39;),(&#39;bark&#39;,&#39;v&#39;)) word_freq = {&#39;cat&#39;: 3, &#39;dog&#39;: 1, &#39;bird&#39;: 5} print(vocab) [&#39;cat&#39;, &#39;dog&#39;, &#39;bird&#39;] print(type(vocab)) &lt;class &#39;list&#39;&gt; print(type(word_pos)) &lt;class &#39;tuple&#39;&gt; print(type(word_freq)) &lt;class &#39;dict&#39;&gt; List and Tuple look similar but they differ in one important aspect: List is mutable while Tuple is Immutable. That is, when a List is created, particular elements of it can be reassigned. Along with this, the entire list can be reassigned. Elements and slices of elements can be deleted from the list. But these changes will not be possible for a Tuple. 14.5 String vocab1 = [&#39;cat&#39;, &#39;dog&#39;, &#39;bird&#39;] vocab2 = (&#39;cat&#39;, &#39;dog&#39;, &#39;bird&#39;) vocab1[0] = &#39;human&#39; print(vocab1) [&#39;human&#39;, &#39;dog&#39;, &#39;bird&#39;] vocab2[0] = &#39;human&#39; Error in py_call_impl(callable, dots$args, dots$keywords): TypeError: &#39;tuple&#39; object does not support item assignment w = &#39;wonderful&#39; type(w) &lt;class &#39;str&#39;&gt; w[:3] &#39;won&#39; In Python, a String functions as a List: &#39;o&#39; in w True w2 = &#39;book&#39; w + w2 &#39;wonderfulbook&#39; &#39; &#39;.join(w) &#39;w o n d e r f u l&#39; Useful functions for String: sent = &#39; This is a sentence example with leading/trailing spaces. &#39; sent.capitalize() &#39; this is a sentence example with leading/trailing spaces. &#39; sent.title() &#39; This Is A Sentence Example With Leading/Trailing Spaces. &#39; sent.upper() &#39; THIS IS A SENTENCE EXAMPLE WITH LEADING/TRAILING SPACES. &#39; sent.lower() &#39; this is a sentence example with leading/trailing spaces. &#39; sent.rstrip() &#39; This is a sentence example with leading/trailing spaces.&#39; sent.lstrip() &#39;This is a sentence example with leading/trailing spaces. &#39; sent.strip() &#39;This is a sentence example with leading/trailing spaces.&#39; sent.find(&#39;is&#39;) 5 sent.replace(&#39;is&#39;,&#39;was&#39;) &#39; Thwas was a sentence example with leading/trailing spaces. &#39; String formatting nwords = 50 textid = &#39;diary&#39; &#39;%s has %d words&#39; % (textid.upper(), nwords) &#39;DIARY has 50 words&#39; 14.6 Control Structure Iteration (for-loop) for w in vocab: print(&quot;_&quot; + w + &quot;_&quot;) _cat_ _dog_ _bird_ Condition (if-else) for w in vocab: if(w[0]==&quot;c&quot;): print(w) cat 14.7 Function def greet(name): print(&#39;Hello, &#39; + name + &#39;, how are you doing!&#39;) greet(name=&#39;Alvin&#39;) Hello, Alvin, how are you doing! greet(name=&#39;Charlie&#39;) Hello, Charlie, how are you doing! 14.8 List Comprehension [len(w) for w in vocab] [3, 3, 4] 14.9 Python Scripts Depending on the editor you use, you may have two types of Python script files: *.py: A simple python script file *.ipynb: A Jupyter Notebook file which needs to be run in Jupyter Lab/Notebook 14.10 Modules $ pip install PACKAGE_NAME Import packages/libraries import re import os 14.11 Input/Output with open(&#39;temp.txt&#39;, &#39;w&#39;) as f: f.write(&#39;hello world!\\n&#39;+&#39;This is a sentence.&#39;) 32 with open(&#39;temp.txt&#39;, &#39;r&#39;) as f: texts = [l for l in f.readlines()] print(texts) [&#39;hello world!\\n&#39;, &#39;This is a sentence.&#39;] rm temp.txt File and Directory Operation import os os.getcwdb() b&#39;/Users/Alvin/Dropbox/NTNU/Programming_Linguistics/Programming_Linguistics_bookdown&#39; os.unlink() os.rename() os.chdir() os.listdir() os.getwd() os.mkdir() os.rmdir os.path.exists() os.path.isfile() os.path.isdir() "],["organizing-files.html", "Chapter 15 Organizing Files 15.1 shutil", " Chapter 15 Organizing Files This unit shows how we can utilize Python to organize files on the hard drive, e.g., traversing the directory, copying, renaming, moving, or compressing files automatically. 15.1 shutil The shutil (shell utility) module helps us copy, move, rename, and delete files in Python. To copy file and directory: shutil.copy(): to copy a single file shutil.copytree(): to copy an entire folder and every folder and file contained in it To remove file and directory: os.unlink(): to delete the file os.rmdir(): to delete an empty folder shutil.rmtree(): to delete a non-empty folder and all files and folders it contains To move file and directory: shutil.move(): to move the file or folder at the path source to the path destination All the shutil file/directory operation functions will return a string of absolute path of the new files/directories locations. import shutil Ways to get the path root or the current working directory: from pathlib import Path print(Path.home()) /Users/Alvin import os print(os.getcwd()) /Users/Alvin/Dropbox/NTNU/Programming_Linguistics/Programming_Linguistics_bookdown t = shutil.copy(&#39;demo_data/corp-alice.txt&#39;, Path.home()) os.unlink(t) # clean up t = shutil.copytree(&#39;demo_data&#39;, Path.home()/&#39;demo_data&#39;) t PosixPath(&#39;/Users/Alvin/demo_data&#39;) os.rmdir(t) Error in py_call_impl(callable, dots$args, dots$keywords): OSError: [Errno 66] Directory not empty: &#39;/Users/Alvin/demo_data&#39; #shutil.rmtree(t) Be very careful when using these “removing” functions. It is often a good idea to run these data-removing functions with these calls commented out and with print() calls added to double check the file/directory names to be deleted. for f in Path(Path.home()/&#39;demo_data&#39;).glob(&#39;*.txt&#39;): print(f) # os.unlink(f) /Users/Alvin/demo_data/data-chinese-poem-big5.txt /Users/Alvin/demo_data/corp-alice.txt /Users/Alvin/demo_data/chinese_big5.txt /Users/Alvin/demo_data/data-chinese-poem-utf8.txt /Users/Alvin/demo_data/dict-ch-idiom.txt /Users/Alvin/demo_data/chinese_utf8.txt /Users/Alvin/demo_data/data-sentences.txt /Users/Alvin/demo_data/chinese_gb2312.txt ## clean up the earlier copied folder shutil.rmtree(Path(Path.home()/&#39;demo_data&#39;)) Because the data-removing functions in shutil irreversibly delete files and folders, they can be dangerous to use. Another third-party module, send2trash, can be much safer because it will send files and folders to the computer’s trash or recycle bin instead of permanently deleting them. For beginners, this can be very helpful for life-saving files/folders. Exercise 15.1 Combine the first page of each PDF in a directory into one new PDF. "],["object-orientation.html", "Chapter 16 Object Orientation 16.1 What is Object Orientation? 16.2 Class Defition 16.3 Types of Methods 16.4 Class Inheritance 16.5 Special Methods 16.6 Property Decorator 16.7 Checking Functions 16.8 Name Mangling 16.9 Reference", " Chapter 16 Object Orientation 16.1 What is Object Orientation? An effective program often utilizes an object-oriented approach in its design. Therefore, most coding languages evolve as an object-oriented language. In OO design, systems consist of collaborating sets of well-defined objects. One object sends a message to another object to achieve some goal. The message is implemented as a function call, often referred to as a method. Therefore, methods are associated with specific objects and depend on the nature of the object as well. ## Examples of String object&#39;s methods newstring = text.upper() newstring = text.lower() newstring = text.split() An object’s blueprint determines its structure. This blueprint is referred to as the class definition. When we create a new object from the object’s class definition, the object is an instance of the class and the process is called instantiation. In addition to methods, an object can also have attributes or properties that we can get and set. We can also determine whether to hide these attributes and make them available only through the methods (private attributes) or expose them to the outside world (public attributes). 16.2 Class Defition A Class definition is a template for a new object instance. While there are many pre-defined classes available in default Python modules, we can define our own class depending on the tasks at hand. In a class definition, usually we include: the mechanism and data required to create an new instance of the class (constructor method(s)), its attributes (both private and public attributes), the methods that can be used to set and get attributes or change the state ob the object (class methods). # Define a class class Employee(object): &quot;Employee Class&quot; # Constructor method def __init__(self, first, last, pay): self.first = first self.last = last self.email = first + &#39;.&#39; + last + &#39;@email.com&#39; self.pay = pay # instance method def fullname(self): return &#39;{} {}&#39;.format(self.first, self.last) emp_1 = Employee(&#39;Alvin&#39;, &#39;Chen&#39;, 50000) emp_2 = Employee(&#39;John&#39;, &#39;Doe&#39;, 60000) emp_1.fullname() &#39;Alvin Chen&#39; emp_2.fullname() &#39;John Doe&#39; 16.3 Types of Methods Class Method: a method bound to the class and with cls as the first default argument Static Method: a self-contained method bound to the class Instance Method: a method bound to the object instance of the class with self as the first default argument class Employee(object): num_of_emps = 0 raise_amt = 1.04 def __init__(self, first, last, pay): self.first = first self.last = last self.email = first + &#39;.&#39; + last + &#39;@email.com&#39; self.pay = pay Employee.num_of_emps += 1 def fullname(self): return &#39;{} {}&#39;.format(self.first, self.last) def apply_raise(self): self.pay = int(self.pay * self.raise_amt) @classmethod def set_raise_amt(cls, amount): cls.raise_amt = amount @classmethod def from_string(cls, emp_str): first, last, pay = emp_str.split(&#39;-&#39;) return cls(first, last, pay) @staticmethod def is_workday(day): if day.weekday() == 5 or day.weekday() == 6: return False return True emp_1 = Employee(&#39;Corey&#39;, &#39;Schafer&#39;, 50000) emp_2 = Employee(&#39;Test&#39;, &#39;Employee&#39;, 60000) Employee.set_raise_amt(1.05) print(Employee.raise_amt) 1.05 print(emp_1.raise_amt) 1.05 print(emp_2.raise_amt) 1.05 emp_str_1 = &#39;John-Doe-70000&#39; emp_str_2 = &#39;Steve-Smith-30000&#39; emp_str_3 = &#39;Jane-Doe-90000&#39; first, last, pay = emp_str_1.split(&#39;-&#39;) #new_emp_1 = Employee(first, last, pay) new_emp_1 = Employee.from_string(emp_str_1) print(new_emp_1.email) John.Doe@email.com print(new_emp_1.pay) 70000 import datetime my_date = datetime.date(2016, 7, 11) print(Employee.is_workday(my_date)) True 16.4 Class Inheritance With the class definition, we can create as many instances of the class as needed. Moreover, with the class definition, we can create suborindate or superordinate classess based on the original class. These sub-classess have taxonomic relationships with the original super class. Extend the original class constructor methods using super() class Employee: raise_amt = 1.04 def __init__(self, first, last, pay): self.first = first self.last = last self.email = first + &#39;.&#39; + last + &#39;@email.com&#39; self.pay = pay def fullname(self): return &#39;{} {}&#39;.format(self.first, self.last) def apply_raise(self): self.pay = int(self.pay * self.raise_amt) class Developer(Employee): raise_amt = 1.10 def __init__(self, first, last, pay, prog_lang): super().__init__(first, last, pay) self.prog_lang = prog_lang class Manager(Employee): def __init__(self, first, last, pay, employees=None): super().__init__(first, last, pay) if employees is None: self.employees = [] else: self.employees = employees def add_emp(self, emp): if emp not in self.employees: self.employees.append(emp) def remove_emp(self, emp): if emp in self.employees: self.employees.remove(emp) def print_emps(self): for emp in self.employees: print(&#39;--&gt;&#39;, emp.fullname()) dev_1 = Developer(&#39;Alvin&#39;, &#39;Chen&#39;, 50000, &#39;Python&#39;) dev_2 = Developer(&#39;John&#39;, &#39;Doe&#39;, 60000, &#39;R&#39;) mgr_1 = Manager(&#39;Anne&#39;, &#39;Mary&#39;, 90000, [dev_1]) print(mgr_1.email) Anne.Mary@email.com mgr_1.add_emp(dev_2) mgr_1.remove_emp(dev_2) mgr_1.print_emps() --&gt; Alvin Chen 16.5 Special Methods Dunder methods (double-underscore) To avoid overloading the expressions in coding class Employee: raise_amt = 1.04 def __init__(self, first, last, pay): self.first = first self.last = last self.email = first + &#39;.&#39; + last + &#39;@email.com&#39; self.pay = pay def fullname(self): return &#39;{} {}&#39;.format(self.first, self.last) def apply_raise(self): self.pay = int(self.pay * self.raise_amt) def __repr__(self): return &quot;Employee(&#39;{}&#39;, &#39;{}&#39;, {})&quot;.format(self.first, self.last, self.pay) def __str__(self): return &#39;{} - {}&#39;.format(self.fullname(), self.email) def __add__(self, other): return self.pay + other.pay def __len__(self): return len(self.fullname()) emp_1 = Employee(&#39;Corey&#39;, &#39;Schafer&#39;, 50000) emp_2 = Employee(&#39;Test&#39;, &#39;Employee&#39;, 60000) # print(emp_1 + emp_2) print(len(emp_1)) 13 16.6 Property Decorator @property: make a method function like attribute-accessing @NAME.setter: make a method function like class-attribute assigning @NAME.deleter: make a method function like class-attribute deleting class Employee: def __init__(self, first, last): self.first = first self.last = last @property def email(self): return &#39;{}.{}@email.com&#39;.format(self.first, self.last) @property def fullname(self): return &#39;{} {}&#39;.format(self.first, self.last) @fullname.setter def fullname(self, name): first, last = name.split(&#39; &#39;) self.first = first self.last = last @fullname.deleter def fullname(self): print(&#39;Delete Name!&#39;) self.first = None self.last = None emp_1 = Employee(&#39;John&#39;, &#39;Smith&#39;) emp_1.fullname = &quot;Corey Schafer&quot; print(emp_1.first) Corey print(emp_1.email) Corey.Schafer@email.com print(emp_1.fullname) Corey Schafer del emp_1.fullname Delete Name! 16.7 Checking Functions isinstance(): Check an instance’s type issubclass(): Check class inheritance 16.8 Name Mangling __NAME: Any identifier of this form within the class is textually replaced with _classname__NAME, where classname is the current class name, with leading underscore(s) stripped. This is for the purpose of creating private variables to the class. 16.9 Reference This notebook is based on Corey Schafer’s OOP Tutorial "],["regular-expression.html", "Chapter 17 Regular Expression 17.1 Comparison of R and Python 17.2 Structure of Regular Expression Usage 17.3 Special Falgs/Settings for Regular Expressions 17.4 Regular Expression in Python 17.5 Text Munging 17.6 References", " Chapter 17 Regular Expression 17.1 Comparison of R and Python R Python str_extract() re.search() str_extract_all() re.findall() str_match_all() re.finditer() str_replace_all() re.sub() str_split() re.split() ? re.subn() ? re.match() str_detect() ? str_subset() ? The above table shows the similarities and differences in terms of the regular expression functions in Python and R. They are more or less similar. These mappings can be helpful for R users to understand the re in Python. 17.2 Structure of Regular Expression Usage 17.2.1 re.search() Import the regex module with import re Create a Regex object by compiling a regular expression pattern (re.compile()). Remember to use a raw string. Use the pattern for search (re.search()) by passing the string you want to search into the Regex object’s search method. This returns a Match object. Call the Match object’s group() method to return a string of the actual matched text. import re text_to_search = &#39;&#39;&#39; abcdefghijklmnopqurtuvwxyz ABCDEFGHIJKLMNOPQRSTUVWXYZ 1234567890 Ha HaHa MetaCharacters (Need to be escaped): . ^ $ * + ? { } [ ] \\ | ( ) coreyms.com 321-555-4321 123.555.1234 123*555*1234 800-555-1234 900-555-1234 Mr. Schafer Mr Smith Ms Davis Mrs. Robinson Mr. T &#39;&#39;&#39; sentence = &#39;Start a sentence and then bring it to an end&#39; pattern = re.compile(r&#39;\\d{3}-\\d{3}-\\d{4}&#39;, re.I) 17.2.2 re.findall() While search() will return a Match object of the first matched text in the searched string, the findall() method will return the strings of every match in the searched string. (re.findall() will not return a Match object but a list of strings–*as long as there are no groups in the regular expression.) ## perform a search matches= pattern.findall(text_to_search) matches [&#39;321-555-4321&#39;, &#39;800-555-1234&#39;, &#39;900-555-1234&#39;] If there are groups in the regular expressions, then re.findall() will return a list of tuples. pattern2 = re.compile(r&#39;(\\d{3})-(\\d{3})-(\\d{4})&#39;, re.I) pattern2.findall(text_to_search) [(&#39;321&#39;, &#39;555&#39;, &#39;4321&#39;), (&#39;800&#39;, &#39;555&#39;, &#39;1234&#39;), (&#39;900&#39;, &#39;555&#39;, &#39;1234&#39;)] 17.2.3 re.finditer() ## find all matches matches = pattern.finditer(text_to_search) if matches: for m in matches: print(&quot;%02d-%02d: %s&quot; % (m.start(), m.end(), m.group())) 151-163: 321-555-4321 190-202: 800-555-1234 203-215: 900-555-1234 17.3 Special Falgs/Settings for Regular Expressions re.IGNORECASE: case-insensitive for pattern matching re.DOTALL: to allow the wildcard * to match linebreaks re.VERBOSE: to create complex regular expressions with multilines and comments (#) pattern3 = re.compile(r&#39;&#39;&#39; (\\d{3}) # area code - # delimiter (\\d{3}) # first 3 digits - # delimiter (\\d{4}) # last 4 digits &#39;&#39;&#39;, re.VERBOSE) pattern3.findall(text_to_search) [(&#39;321&#39;, &#39;555&#39;, &#39;4321&#39;), (&#39;800&#39;, &#39;555&#39;, &#39;1234&#39;), (&#39;900&#39;, &#39;555&#39;, &#39;1234&#39;)] Exercise 17.1 With the text_to_search, how to create a more complete regular expression to extract all the phone numbers, including those numbers that have other delimiters (e.g., *) [(&#39;321&#39;, &#39;555&#39;, &#39;4321&#39;), (&#39;123&#39;, &#39;555&#39;, &#39;1234&#39;), (&#39;123&#39;, &#39;555&#39;, &#39;1234&#39;), (&#39;800&#39;, &#39;555&#39;, &#39;1234&#39;), (&#39;900&#39;, &#39;555&#39;, &#39;1234&#39;)] 17.4 Regular Expression in Python 17.4.1 Raw String Notation Raw string notation (r'text') keeps regular expressions sane. Without it, every backslash ('') in a regular expression would have to be prefixed with another one to escape it. For example, the two following lines of code are functionally identical: 17.4.2 Find all matches re.findall(): matches all occurrences of a pattern, not just the first one as re.search() does. re.finditer(): If one wants more information about all matches of a pattern than the matched text, re.finditer() is useful as it provides match objects instead of strings. 17.4.3 group() vs. groups() group(): by default, returns the whole match of the pattern groups(): by default, returns all capturing groups m = re.match(&quot;a(.)(.)&quot;,&quot;abcedf&quot;) print(m.group(0)) # return the whole match abc print(m.group()) # return the whole match, same as above abc print(m.groups()) # return each capturing group match (&#39;b&#39;, &#39;c&#39;) print(m.group(1)) # return first capturing gorup match b 17.4.4 string format validation valid = re.compile(r&quot;^[a-z]+@[a-z]+\\.[a-z]{3}$&quot;) print(valid.match(&#39;alvin@ntnu.edu&#39;)) &lt;re.Match object; span=(0, 14), match=&#39;alvin@ntnu.edu&#39;&gt; print(valid.match(&#39;alvin123@ntnu.edu&#39;)) None print(valid.match(&#39;alvin@ntnu.homeschool&#39;)) None 17.4.5 re.match() vs. re.search() Python offers two different primitive operations based on regular expressions: re.match() checks for a match only at the beginning of the string re.search() checks for a match anywhere in the string (this is what Perl does by default). print(re.match(&quot;c&quot;, &quot;abcdef&quot;)) # No match None print(re.search(&quot;^c&quot;, &quot;abcdef&quot;)) # No match, same as above None print(re.search(&quot;c&quot;, &quot;abcdef&quot;)) # Match &lt;re.Match object; span=(2, 3), match=&#39;c&#39;&gt; re.match always matches at the beginning of the input string even if it is in the MULTILINE mode. re.search however, when in MULTILINE mode, is able to search at the beginning of every line if used in combination with ^. print(re.match(&#39;X&#39;, &#39;A\\nB\\nX&#39;, re.MULTILINE)) # No match None print(re.search(&#39;^X&#39;, &#39;A\\nB\\nX&#39;, re.MULTILINE)) # Match &lt;re.Match object; span=(4, 5), match=&#39;X&#39;&gt; print(re.search(&#39;^X&#39;, &#39;A\\nB\\nX&#39;)) # No match None 17.4.6 re.split() text = &quot;&quot;&quot;Ross McFluff: 834.345.1254 155 Elm Street Ronald Heathmore: 892.345.3428 436 Finley Avenue Frank Burger: 925.541.7625 662 South Dogwood Way Heather Albrecht: 548.326.4584 919 Park Place&quot;&quot;&quot; # split text into lines re.split(r&#39;\\n&#39;,text) [&#39;Ross McFluff: 834.345.1254 155 Elm Street&#39;, &#39;&#39;, &#39;Ronald Heathmore: 892.345.3428 436 Finley Avenue&#39;, &#39;Frank Burger: 925.541.7625 662 South Dogwood Way&#39;, &#39;&#39;, &#39;&#39;, &#39;Heather Albrecht: 548.326.4584 919 Park Place&#39;] re.split(r&#39;\\n+&#39;, text) [&#39;Ross McFluff: 834.345.1254 155 Elm Street&#39;, &#39;Ronald Heathmore: 892.345.3428 436 Finley Avenue&#39;, &#39;Frank Burger: 925.541.7625 662 South Dogwood Way&#39;, &#39;Heather Albrecht: 548.326.4584 919 Park Place&#39;] entries = re.split(r&#39;\\n+&#39;, text) [re.split(r&#39;\\s&#39;, entry) for entry in entries] [[&#39;Ross&#39;, &#39;McFluff:&#39;, &#39;834.345.1254&#39;, &#39;155&#39;, &#39;Elm&#39;, &#39;Street&#39;], [&#39;Ronald&#39;, &#39;Heathmore:&#39;, &#39;892.345.3428&#39;, &#39;436&#39;, &#39;Finley&#39;, &#39;Avenue&#39;], [&#39;Frank&#39;, &#39;Burger:&#39;, &#39;925.541.7625&#39;, &#39;662&#39;, &#39;South&#39;, &#39;Dogwood&#39;, &#39;Way&#39;], [&#39;Heather&#39;, &#39;Albrecht:&#39;, &#39;548.326.4584&#39;, &#39;919&#39;, &#39;Park&#39;, &#39;Place&#39;]] [re.split(r&#39;:?\\s&#39;, entry, maxsplit=3) for entry in entries] [[&#39;Ross&#39;, &#39;McFluff&#39;, &#39;834.345.1254&#39;, &#39;155 Elm Street&#39;], [&#39;Ronald&#39;, &#39;Heathmore&#39;, &#39;892.345.3428&#39;, &#39;436 Finley Avenue&#39;], [&#39;Frank&#39;, &#39;Burger&#39;, &#39;925.541.7625&#39;, &#39;662 South Dogwood Way&#39;], [&#39;Heather&#39;, &#39;Albrecht&#39;, &#39;548.326.4584&#39;, &#39;919 Park Place&#39;]] 17.5 Text Munging re.sub() text = &#39;&#39;&#39;Peter Piper picked a peck of pickled peppers A peck of pickled peppers Peter Piper picked If Peter Piper picked a peck of pickled peppers Where’s the peck of pickled peppers Peter Piper picked?&#39;&#39;&#39; print(re.sub(r&#39;[aeiou]&#39;,&#39;_&#39;, text)) P_t_r P_p_r p_ck_d _ p_ck _f p_ckl_d p_pp_rs A p_ck _f p_ckl_d p_pp_rs P_t_r P_p_r p_ck_d If P_t_r P_p_r p_ck_d _ p_ck _f p_ckl_d p_pp_rs Wh_r_’s th_ p_ck _f p_ckl_d p_pp_rs P_t_r P_p_r p_ck_d? print(re.sub(r&#39;([aeiou])&#39;,r&#39;[\\1]&#39;, text)) P[e]t[e]r P[i]p[e]r p[i]ck[e]d [a] p[e]ck [o]f p[i]ckl[e]d p[e]pp[e]rs A p[e]ck [o]f p[i]ckl[e]d p[e]pp[e]rs P[e]t[e]r P[i]p[e]r p[i]ck[e]d If P[e]t[e]r P[i]p[e]r p[i]ck[e]d [a] p[e]ck [o]f p[i]ckl[e]d p[e]pp[e]rs Wh[e]r[e]’s th[e] p[e]ck [o]f p[i]ckl[e]d p[e]pp[e]rs P[e]t[e]r P[i]p[e]r p[i]ck[e]d? American_dates = [&quot;7/31/1976&quot;, &quot;02.15.1970&quot;, &quot;11-31-1986&quot;, &quot;04/01.2020&quot;] print(American_dates) [&#39;7/31/1976&#39;, &#39;02.15.1970&#39;, &#39;11-31-1986&#39;, &#39;04/01.2020&#39;] print([re.sub(r&#39;(\\d+)(\\D)(\\d+)(\\D)(\\d+)&#39;, r&#39;\\3\\2\\1\\4\\5&#39;, date) for date in American_dates]) [&#39;31/7/1976&#39;, &#39;15.02.1970&#39;, &#39;31-11-1986&#39;, &#39;01/04.2020&#39;] In re.sub(repl, string), the repl argument can be a function. If repl is a function, it is called for every non-overlapping occurrence of pattern. The function takes a single match object argument, and returns the replacement string. s = &quot;This is a simple sentence.&quot; pat_vowels = re.compile(r&#39;[aeiou]&#39;) def replaceVowels(m): c = m.group(0) c2 = &quot;&quot; if c in &quot;ie&quot;: c2 = &quot;F&quot; else: c2 = &quot;B&quot; return c2 pat_vowels.sub(replaceVowels, s) &#39;ThFs Fs B sFmplF sFntFncF.&#39; Exercise 17.2 Create a small program to extract both emails and phone numbers from the texts on this faculty page: Department o English, NTNU. All Phone Numbers: [&#39;02-7749-1801&#39;, &#39;02-7749-1772&#39;, &#39;02-7749-1775&#39;, &#39;02-7749-1783&#39;, &#39;02-7749-1767&#39;, &#39;02-7749-1757&#39;, &#39;02-7749-1781&#39;, &#39;02-7749-1777&#39;, &#39;02-7749-1773&#39;, &#39;02-7749-1759&#39;, &#39;02-7749-1768&#39;, &#39;02-7749-1822&#39;, &#39;02-7749-1760&#39;, &#39;02-7749-1764&#39;, &#39;02-7749-1769&#39;, &#39;02-7749-1817&#39;, &#39;02-7749-1756&#39;, &#39;02-7749-1788&#39;, &#39;02-7749-1758&#39;, &#39;02-7749-1754&#39;, &#39;02-7749-1821&#39;, &#39;02-7749-1819&#39;, &#39;02-7749-1790&#39;, &#39;02-7749-1761&#39;, &#39;02-7749-1761&#39;, &#39;02-7749-1776&#39;, &#39;02-7749-1770&#39;, &#39;02-7749-1786&#39;, &#39;02-7749-1789&#39;, &#39;02-7749-1816&#39;, &#39;02-7749-1774&#39;, &#39;02-7749-1765&#39;, &#39;02-7749-1778&#39;, &#39;02-7749-1541&#39;, &#39;02-7749-1823&#39;, &#39;02-7749-1763&#39;, &#39;02-7749-1762&#39;, &#39;02-7749-1821&#39;, &#39;02-7749-1811&#39;, &#39;02-7749-1779&#39;, &#39;02-7749-1785&#39;, &#39;02-7749-1820&#39;, &#39;02-7749-1766&#39;, &#39;02-7749-1782&#39;, &#39;02-7749-1762&#39;, &#39;02-7749-1784&#39;, &#39;02-7749-1755&#39;, &#39;02-7749-1800&#39;, &#39;02-2363-4793&#39;] All Emails: [&#39;chunyin@gapps.ntnu.edu.tw&#39;, &#39;mhchang@ntnu.edu.tw&#39;, &#39;clchern@ntnu.edu.tw&#39;, &#39;t22035@ntnu.edu.tw&#39;, &#39;joanchang@ntnu.edu.tw&#39;, &#39;hjchen@ntnu.edu.tw&#39;, &#39;tcsu@ntnu.edu.tw&#39;, &#39;t22028@ntnu.edu.tw&#39;, &#39;lip@ntnu.edu.tw&#39;, &#39;ting@ntnu.edu.tw&#39;, &#39;hclee@ntnu.edu.tw&#39;, &#39;hslin@ntnu.edu.tw&#39;, &#39;chyhuang@ntnu.edu.tw&#39;, &#39;profgood@ntnu.edu.tw&#39;, &#39;cclin@ntnu.edu.tw&#39;, &#39;iriswu@ntnu.edu.tw&#39;, &#39;yeutingliu@gapps.ntnu.edu.tw&#39;, &#39;ioana.luca@ntnu.edu.tw&#39;, &#39;lindsey@ntnu.edu.tw&#39;, &#39;jprystash@ntnu.edu.tw&#39;, &#39;hsysu@ntnu.edu.tw&#39;, &#39;hannes.bergthaller@ntnu.edu.tw&#39;, &#39;peichinchang@ntnu.edu.tw&#39;, &#39;shiaohui@ntnu.edu.tw&#39;, &#39;lijeni@ntnu.edu.tw&#39;, &#39;ykhsu@ntnu.edu.tw&#39;, &#39;ycshao@ntnu.edu.tw&#39;, &#39;t22045@ntnu.edu.tw&#39;, &#39;jjwu@ntnu.edu.tw&#39;, &#39;mlhsieh@ntnu.edu.tw&#39;, &#39;jungsu@ntnu.edu.tw&#39;, &#39;t22001@ntnu.edu.tw&#39;, &#39;jjtseng@gapps.ntnu.edu.tw&#39;, &#39;aaron.c.deveson@ntnu.edu.tw&#39;, &#39;lihsin@ntnu.edu.tw&#39;, &#39;wanghc@gapps.ntnu.edu.tw&#39;, &#39;alvinchen@ntnu.edu.tw&#39;, &#39;gfsayang@ntnu.edu.tw&#39;, &#39;yuchentai@gapps.ntnu.edu.tw&#39;, &#39;hllin@ntnu.edu.tw&#39;, &#39;jiaqiwu8@ntnu.edu.tw&#39;, &#39;angelawu@ntnu.edu.tw&#39;, &#39;yichien@ntnu.edu.tw&#39;, &#39;fwkung@ntnu.edu.tw&#39;, &#39;t22040@ntnu.edu.tw&#39;, &#39;curran@ntnu.edu.tw&#39;, &#39;english@ntnu.edu.tw&#39;] 17.6 References Python regular expression cheatsheet Python official regular expression documentation Friedl, Jeffrey. Mastering Regular Expressions. 3rd ed., O’Reilly Media, 2009. A good graphic interface to try out regular expressions: pythex.org "],["pandas.html", "Chapter 18 Pandas 18.1 Libraries 18.2 Importing/Exporting Data 18.3 Inspecting Data Frame 18.4 Basic Functions 18.5 Subsetting Data Frame 18.6 Exploration 18.7 Join/Combine Data Frames 18.8 Statistics 18.9 Generic Functions 18.10 References", " Chapter 18 Pandas Methods to deal with tabular data These methods are to replicate what dplyr in R is capable of To handle tabular data like data frames, I would still recommend using R instead of Python for beginners. pandas can be intimidating for a lot of beginners. The statsmodels can download R datasets from https://vincentarelbundock.github.io/Rdatasets/datasets.html 18.1 Libraries import pandas as pd import numpy as np import statsmodels.api as sm import matplotlib 18.2 Importing/Exporting Data Importing: pd.read_csv(filename): From a CSV file pd.read_table(filename): From a delimited text file (like TSV) pd.read_excel(filename): From an Excel file pd.read_sql(query, connection_object): Read from a SQL table/database pd.read_json(json_string): Read from a JSON formatted string, URL or file. pd.read_html(url): Parses an html URL, string or file and extracts tables to a list of dataframes pd.read_clipboard(): Takes the contents of your clipboard and passes it to read_table() pd.DataFrame(dict): From a dict, keys for columns names, values for data as lists pd.DataFrame(list of tuples): From a list, which includes the records of each row Exporting: df.to_csv(filename) df.to_excel(filename) df.to_sql(table_name, connection_object) df.to_json(filename) DEMO_DATA_DIR = &#39;demo_data/titanic/&#39; iris = sm.datasets.get_rdataset(&#39;iris&#39;).data titanic = pd.read_csv(DEMO_DATA_DIR+&#39;train.csv&#39;) iris.head() Sepal.Length Sepal.Width Petal.Length Petal.Width Species 0 5.1 3.5 1.4 0.2 setosa 1 4.9 3.0 1.4 0.2 setosa 2 4.7 3.2 1.3 0.2 setosa 3 4.6 3.1 1.5 0.2 setosa 4 5.0 3.6 1.4 0.2 setosa titanic.head() PassengerId Survived Pclass ... Fare Cabin Embarked 0 1 0 3 ... 7.2500 NaN S 1 2 1 1 ... 71.2833 C85 C 2 3 1 3 ... 7.9250 NaN S 3 4 1 1 ... 53.1000 C123 S 4 5 0 3 ... 8.0500 NaN S [5 rows x 12 columns] x= [(1,2,3,4), (5,6,7,8), (9,10,11,12)] pd.DataFrame(x,columns=[&quot;A&quot;,&quot;B&quot;,&quot;C&quot;,&quot;D&quot;]) A B C D 0 1 2 3 4 1 5 6 7 8 2 9 10 11 12 x = {&quot;A&quot;:[1,2,3,4], &quot;B&quot;:[5,6,7,8], &quot;C&quot;:[9,10,11,12]} pd.DataFrame(x) A B C 0 1 5 9 1 2 6 10 2 3 7 11 3 4 8 12 When you have data of the columns, use dict; when you have the data of the rows, use list as the source data structures of a data frame. 18.3 Inspecting Data Frame df.head(n): First n rows of the DataFrame df.tail(n): Last n rows of the DataFrame df.shape: Number of rows and columns df.info(): Index, Datatype and Memory information df.describe(): Summary statistics for numerical columns s.value_counts(dropna=False): View unique values and counts df.apply(pd.Series.value_counts): Unique values and counts for all columns df.columns df.index df.dtypes df.set_index('column_name'): Set a column as the index iris.info() &lt;class &#39;pandas.core.frame.DataFrame&#39;&gt; RangeIndex: 150 entries, 0 to 149 Data columns (total 5 columns): # Column Non-Null Count Dtype --- ------ -------------- ----- 0 Sepal.Length 150 non-null float64 1 Sepal.Width 150 non-null float64 2 Petal.Length 150 non-null float64 3 Petal.Width 150 non-null float64 4 Species 150 non-null object dtypes: float64(4), object(1) memory usage: 6.0+ KB iris.describe() Sepal.Length Sepal.Width Petal.Length Petal.Width count 150.000000 150.000000 150.000000 150.000000 mean 5.843333 3.057333 3.758000 1.199333 std 0.828066 0.435866 1.765298 0.762238 min 4.300000 2.000000 1.000000 0.100000 25% 5.100000 2.800000 1.600000 0.300000 50% 5.800000 3.000000 4.350000 1.300000 75% 6.400000 3.300000 5.100000 1.800000 max 7.900000 4.400000 6.900000 2.500000 print(iris.shape) (150, 5) iris.head(3) Sepal.Length Sepal.Width Petal.Length Petal.Width Species 0 5.1 3.5 1.4 0.2 setosa 1 4.9 3.0 1.4 0.2 setosa 2 4.7 3.2 1.3 0.2 setosa iris.tail(3) Sepal.Length Sepal.Width Petal.Length Petal.Width Species 147 6.5 3.0 5.2 2.0 virginica 148 6.2 3.4 5.4 2.3 virginica 149 5.9 3.0 5.1 1.8 virginica iris[&#39;Species&#39;].value_counts() setosa 50 virginica 50 versicolor 50 Name: Species, dtype: int64 print(iris.columns) Index([&#39;Sepal.Length&#39;, &#39;Sepal.Width&#39;, &#39;Petal.Length&#39;, &#39;Petal.Width&#39;, &#39;Species&#39;], dtype=&#39;object&#39;) print(iris.index) RangeIndex(start=0, stop=150, step=1) print(iris.dtypes) Sepal.Length float64 Sepal.Width float64 Petal.Length float64 Petal.Width float64 Species object dtype: object 18.4 Basic Functions ## DataFrame attributes iris.shape (150, 5) iris.columns Index([&#39;Sepal.Length&#39;, &#39;Sepal.Width&#39;, &#39;Petal.Length&#39;, &#39;Petal.Width&#39;, &#39;Species&#39;], dtype=&#39;object&#39;) iris.index RangeIndex(start=0, stop=150, step=1) iris.info() &lt;class &#39;pandas.core.frame.DataFrame&#39;&gt; RangeIndex: 150 entries, 0 to 149 Data columns (total 5 columns): # Column Non-Null Count Dtype --- ------ -------------- ----- 0 Sepal.Length 150 non-null float64 1 Sepal.Width 150 non-null float64 2 Petal.Length 150 non-null float64 3 Petal.Width 150 non-null float64 4 Species 150 non-null object dtypes: float64(4), object(1) memory usage: 6.0+ KB iris.describe() Sepal.Length Sepal.Width Petal.Length Petal.Width count 150.000000 150.000000 150.000000 150.000000 mean 5.843333 3.057333 3.758000 1.199333 std 0.828066 0.435866 1.765298 0.762238 min 4.300000 2.000000 1.000000 0.100000 25% 5.100000 2.800000 1.600000 0.300000 50% 5.800000 3.000000 4.350000 1.300000 75% 6.400000 3.300000 5.100000 1.800000 max 7.900000 4.400000 6.900000 2.500000 iris.dtypes # check column data types Sepal.Length float64 Sepal.Width float64 Petal.Length float64 Petal.Width float64 Species object dtype: object 18.5 Subsetting Data Frame df[col]: Returns column with label col as Series df[[col1, col2]]: Returns columns as a new DataFrame s.iloc[0]: Selection by position s.loc['index_one']: Selection by index df.iloc[0,:]: First row df.iloc[0,0]: First element of first column iris.loc[:5, &#39;Species&#39;] # first six rows of &#39;Species&#39; column 0 setosa 1 setosa 2 setosa 3 setosa 4 setosa 5 setosa Name: Species, dtype: object iris.iloc[:5, 4] # same as above 0 setosa 1 setosa 2 setosa 3 setosa 4 setosa Name: Species, dtype: object 18.6 Exploration How to perform the key functions provided in R dplyr? dplyr Key Verbs filter() select() mutate() arrange() summarize() group_by() 18.6.1 NA Values Functions to take care of NA values: df.isnull() df.notnull() df.dropna(): Drop rows with null values df.dropna(axis=1): Drop columns with null values df.dropna(axis=1, thresh=n): Drop all columns have less than n non-values df.fillna(x): Replaces all null values with x s.fillna(s.mean()): Replace the null values of a Series with its mean score Quick check of the null values in each column titanic.isnull().sum() PassengerId 0 Survived 0 Pclass 0 Name 0 Sex 0 Age 177 SibSp 0 Parch 0 Ticket 0 Fare 0 Cabin 687 Embarked 2 dtype: int64 titanic.dropna(axis=1, thresh=600) PassengerId Survived Pclass ... Ticket Fare Embarked 0 1 0 3 ... A/5 21171 7.2500 S 1 2 1 1 ... PC 17599 71.2833 C 2 3 1 3 ... STON/O2. 3101282 7.9250 S 3 4 1 1 ... 113803 53.1000 S 4 5 0 3 ... 373450 8.0500 S .. ... ... ... ... ... ... ... 886 887 0 2 ... 211536 13.0000 S 887 888 1 1 ... 112053 30.0000 S 888 889 0 3 ... W./C. 6607 23.4500 S 889 890 1 1 ... 111369 30.0000 C 890 891 0 3 ... 370376 7.7500 Q [891 rows x 11 columns] titanic.notnull().sum() PassengerId 891 Survived 891 Pclass 891 Name 891 Sex 891 Age 714 SibSp 891 Parch 891 Ticket 891 Fare 891 Cabin 204 Embarked 889 dtype: int64 18.6.2 Converting Data Types s.astype(float): Convert a Series into a float type iris.dtypes Sepal.Length float64 Sepal.Width float64 Petal.Length float64 Petal.Width float64 Species object dtype: object iris[&#39;Species&#39;]=iris[&#39;Species&#39;].astype(&#39;category&#39;) iris.dtypes #iris.value_counts(iris[&#39;Species&#39;]).plot.bar() Sepal.Length float64 Sepal.Width float64 Petal.Length float64 Petal.Width float64 Species category dtype: object 18.6.3 Pandas-supported Data Types pandas-dtypes (source) 18.6.4 Transformation s.replace(X, Y) titanic.head() PassengerId Survived Pclass ... Fare Cabin Embarked 0 1 0 3 ... 7.2500 NaN S 1 2 1 1 ... 71.2833 C85 C 2 3 1 3 ... 7.9250 NaN S 3 4 1 1 ... 53.1000 C123 S 4 5 0 3 ... 8.0500 NaN S [5 rows x 12 columns] titanic.value_counts(titanic[&#39;Survived&#39;]).plot.bar() titanic.columns Index([&#39;PassengerId&#39;, &#39;Survived&#39;, &#39;Pclass&#39;, &#39;Name&#39;, &#39;Sex&#39;, &#39;Age&#39;, &#39;SibSp&#39;, &#39;Parch&#39;, &#39;Ticket&#39;, &#39;Fare&#39;, &#39;Cabin&#39;, &#39;Embarked&#39;], dtype=&#39;object&#39;) titanic.groupby([&#39;Sex&#39;,&#39;Pclass&#39;]).mean() PassengerId Survived Age SibSp Parch Fare Sex Pclass female 1 469.212766 0.968085 34.611765 0.553191 0.457447 106.125798 2 443.105263 0.921053 28.722973 0.486842 0.605263 21.970121 3 399.729167 0.500000 21.750000 0.895833 0.798611 16.118810 male 1 455.729508 0.368852 41.281386 0.311475 0.278689 67.226127 2 447.962963 0.157407 30.740707 0.342593 0.222222 19.741782 3 455.515850 0.135447 26.507589 0.498559 0.224784 12.661633 titanic[titanic[&#39;Age&#39;]&lt;18].groupby([&#39;Sex&#39;,&#39;Pclass&#39;]).mean() PassengerId Survived Age SibSp Parch Fare Sex Pclass female 1 525.375000 0.875000 14.125000 0.500000 0.875000 104.083337 2 369.250000 1.000000 8.333333 0.583333 1.083333 26.241667 3 374.942857 0.542857 8.428571 1.571429 1.057143 18.727977 male 1 526.500000 1.000000 8.230000 0.500000 2.000000 116.072900 2 527.818182 0.818182 4.757273 0.727273 1.000000 25.659473 3 437.953488 0.232558 9.963256 2.069767 1.000000 22.752523 18.6.5 filter() ## filter iris[iris[&#39;Sepal.Length&#39;]&gt;5] Sepal.Length Sepal.Width Petal.Length Petal.Width Species 0 5.1 3.5 1.4 0.2 setosa 5 5.4 3.9 1.7 0.4 setosa 10 5.4 3.7 1.5 0.2 setosa 14 5.8 4.0 1.2 0.2 setosa 15 5.7 4.4 1.5 0.4 setosa .. ... ... ... ... ... 145 6.7 3.0 5.2 2.3 virginica 146 6.3 2.5 5.0 1.9 virginica 147 6.5 3.0 5.2 2.0 virginica 148 6.2 3.4 5.4 2.3 virginica 149 5.9 3.0 5.1 1.8 virginica [118 rows x 5 columns] When there are more than one filtering condition, put the conditions in parentheses. iris[(iris[&#39;Sepal.Length&#39;]&gt;4) &amp; (iris[&#39;Sepal.Width&#39;]&gt;5)] Empty DataFrame Columns: [Sepal.Length, Sepal.Width, Petal.Length, Petal.Width, Species] Index: [] iris.query(&#39;`Sepal.Length`&gt;5&#39;) Sepal.Length Sepal.Width Petal.Length Petal.Width Species 0 5.1 3.5 1.4 0.2 setosa 5 5.4 3.9 1.7 0.4 setosa 10 5.4 3.7 1.5 0.2 setosa 14 5.8 4.0 1.2 0.2 setosa 15 5.7 4.4 1.5 0.4 setosa .. ... ... ... ... ... 145 6.7 3.0 5.2 2.3 virginica 146 6.3 2.5 5.0 1.9 virginica 147 6.5 3.0 5.2 2.0 virginica 148 6.2 3.4 5.4 2.3 virginica 149 5.9 3.0 5.1 1.8 virginica [118 rows x 5 columns] iris[(iris[&#39;Sepal.Length&#39;]&gt;5) &amp; (iris[&#39;Sepal.Width&#39;]&gt;4)] Sepal.Length Sepal.Width Petal.Length Petal.Width Species 15 5.7 4.4 1.5 0.4 setosa 32 5.2 4.1 1.5 0.1 setosa 33 5.5 4.2 1.4 0.2 setosa 18.6.6 arrange() iris.sort_values([&#39;Species&#39;,&#39;Sepal.Length&#39;], ascending=[False,True]) Sepal.Length Sepal.Width Petal.Length Petal.Width Species 106 4.9 2.5 4.5 1.7 virginica 121 5.6 2.8 4.9 2.0 virginica 113 5.7 2.5 5.0 2.0 virginica 101 5.8 2.7 5.1 1.9 virginica 114 5.8 2.8 5.1 2.4 virginica .. ... ... ... ... ... 33 5.5 4.2 1.4 0.2 setosa 36 5.5 3.5 1.3 0.2 setosa 15 5.7 4.4 1.5 0.4 setosa 18 5.7 3.8 1.7 0.3 setosa 14 5.8 4.0 1.2 0.2 setosa [150 rows x 5 columns] 18.6.7 select() ## select iris[[&#39;Sepal.Length&#39;, &#39;Species&#39;]] Sepal.Length Species 0 5.1 setosa 1 4.9 setosa 2 4.7 setosa 3 4.6 setosa 4 5.0 setosa .. ... ... 145 6.7 virginica 146 6.3 virginica 147 6.5 virginica 148 6.2 virginica 149 5.9 virginica [150 rows x 2 columns] ## deselect columns iris.drop([&#39;Sepal.Length&#39;], axis=1).head() Sepal.Width Petal.Length Petal.Width Species 0 3.5 1.4 0.2 setosa 1 3.0 1.4 0.2 setosa 2 3.2 1.3 0.2 setosa 3 3.1 1.5 0.2 setosa 4 3.6 1.4 0.2 setosa iris.filter([&#39;Species&#39;,&#39;Sepal.Length&#39;]) Species Sepal.Length 0 setosa 5.1 1 setosa 4.9 2 setosa 4.7 3 setosa 4.6 4 setosa 5.0 .. ... ... 145 virginica 6.7 146 virginica 6.3 147 virginica 6.5 148 virginica 6.2 149 virginica 5.9 [150 rows x 2 columns] iris[[&#39;Species&#39;,&#39;Sepal.Length&#39;]] Species Sepal.Length 0 setosa 5.1 1 setosa 4.9 2 setosa 4.7 3 setosa 4.6 4 setosa 5.0 .. ... ... 145 virginica 6.7 146 virginica 6.3 147 virginica 6.5 148 virginica 6.2 149 virginica 5.9 [150 rows x 2 columns] ## extract one particular column sepal_length = iris[&#39;Sepal.Length&#39;] type(sepal_length) &lt;class &#39;pandas.core.series.Series&#39;&gt; 18.6.8 mutate() ## mutate iris[&#39;Species_new&#39;] = iris[&#39;Species&#39;].apply(lambda x: len(x)) iris[&#39;Species_initial&#39;] = iris[&#39;Species&#39;].apply(lambda x: x[:2].upper()) iris Sepal.Length Sepal.Width ... Species_new Species_initial 0 5.1 3.5 ... 6 SE 1 4.9 3.0 ... 6 SE 2 4.7 3.2 ... 6 SE 3 4.6 3.1 ... 6 SE 4 5.0 3.6 ... 6 SE .. ... ... ... ... ... 145 6.7 3.0 ... 9 VI 146 6.3 2.5 ... 9 VI 147 6.5 3.0 ... 9 VI 148 6.2 3.4 ... 9 VI 149 5.9 3.0 ... 9 VI [150 rows x 7 columns] ## mutate alternative 2 iris.assign(Specias_initial2 = iris[&#39;Species&#39;].apply(lambda x: x.upper())) Sepal.Length Sepal.Width ... Species_initial Specias_initial2 0 5.1 3.5 ... SE SETOSA 1 4.9 3.0 ... SE SETOSA 2 4.7 3.2 ... SE SETOSA 3 4.6 3.1 ... SE SETOSA 4 5.0 3.6 ... SE SETOSA .. ... ... ... ... ... 145 6.7 3.0 ... VI VIRGINICA 146 6.3 2.5 ... VI VIRGINICA 147 6.5 3.0 ... VI VIRGINICA 148 6.2 3.4 ... VI VIRGINICA 149 5.9 3.0 ... VI VIRGINICA [150 rows x 8 columns] 18.6.9 apply(), mutate_if() df.apply(np.mean): Apply a function to all columns df.apply(np.max,axis=1): Apply a function to each row When apply() functions to the data frame, the axis=1 refers to row mutation and axis=0 refers to column mutation. This is very counter-intuitive for R users. iris.head(10) Sepal.Length Sepal.Width Petal.Length ... Species Species_new Species_initial 0 5.1 3.5 1.4 ... setosa 6 SE 1 4.9 3.0 1.4 ... setosa 6 SE 2 4.7 3.2 1.3 ... setosa 6 SE 3 4.6 3.1 1.5 ... setosa 6 SE 4 5.0 3.6 1.4 ... setosa 6 SE 5 5.4 3.9 1.7 ... setosa 6 SE 6 4.6 3.4 1.4 ... setosa 6 SE 7 5.0 3.4 1.5 ... setosa 6 SE 8 4.4 2.9 1.4 ... setosa 6 SE 9 4.9 3.1 1.5 ... setosa 6 SE [10 rows x 7 columns] iris[[&#39;Sepal.Width&#39;,&#39;Petal.Width&#39;]].apply(np.sum, axis=1).head(10) 0 3.7 1 3.2 2 3.4 3 3.3 4 3.8 5 4.3 6 3.7 7 3.6 8 3.1 9 3.2 dtype: float64 18.6.10 group_by() and summarize() iris.groupby(by=&#39;Species&#39;).mean() Sepal.Length Sepal.Width Petal.Length Petal.Width Species setosa 5.006 3.428 1.462 0.246 versicolor 5.936 2.770 4.260 1.326 virginica 6.588 2.974 5.552 2.026 iris.filter([&#39;Species&#39;,&#39;Sepal.Length&#39;]).groupby(&#39;Species&#39;).agg({&#39;Sepal.Length&#39;:[&#39;mean&#39;,&#39;count&#39;,&#39;std&#39;]}) Sepal.Length mean count std Species setosa 5.006 50 0.352490 versicolor 5.936 50 0.516171 virginica 6.588 50 0.635880 titanic.head() PassengerId Survived Pclass ... Fare Cabin Embarked 0 1 0 3 ... 7.2500 NaN S 1 2 1 1 ... 71.2833 C85 C 2 3 1 3 ... 7.9250 NaN S 3 4 1 1 ... 53.1000 C123 S 4 5 0 3 ... 8.0500 NaN S [5 rows x 12 columns] titanic.groupby([&#39;Pclass&#39;,&#39;Sex&#39;]).agg(np.sum) PassengerId Survived Age SibSp Parch Fare Pclass Sex 1 female 44106 91 2942.00 52 43 9975.8250 male 55599 45 4169.42 38 34 8201.5875 2 female 33676 70 2125.50 37 46 1669.7292 male 48380 17 3043.33 37 24 2132.1125 3 female 57561 72 2218.50 129 115 2321.1086 male 158064 47 6706.42 173 78 4393.5865 titanic.pivot_table(index=[&#39;Pclass&#39;,&#39;Sex&#39;], values=[&#39;Survived&#39;], aggfunc=np.sum) Survived Pclass Sex 1 female 91 male 45 2 female 70 male 17 3 female 72 male 47 18.6.11 rename() iris Sepal.Length Sepal.Width ... Species_new Species_initial 0 5.1 3.5 ... 6 SE 1 4.9 3.0 ... 6 SE 2 4.7 3.2 ... 6 SE 3 4.6 3.1 ... 6 SE 4 5.0 3.6 ... 6 SE .. ... ... ... ... ... 145 6.7 3.0 ... 9 VI 146 6.3 2.5 ... 9 VI 147 6.5 3.0 ... 9 VI 148 6.2 3.4 ... 9 VI 149 5.9 3.0 ... 9 VI [150 rows x 7 columns] iris.columns Index([&#39;Sepal.Length&#39;, &#39;Sepal.Width&#39;, &#39;Petal.Length&#39;, &#39;Petal.Width&#39;, &#39;Species&#39;, &#39;Species_new&#39;, &#39;Species_initial&#39;], dtype=&#39;object&#39;) Selective renaming column names iris = iris.rename(columns={&#39;Sepal.Length&#39;:&#39;SLen&#39;}) iris SLen Sepal.Width Petal.Length ... Species Species_new Species_initial 0 5.1 3.5 1.4 ... setosa 6 SE 1 4.9 3.0 1.4 ... setosa 6 SE 2 4.7 3.2 1.3 ... setosa 6 SE 3 4.6 3.1 1.5 ... setosa 6 SE 4 5.0 3.6 1.4 ... setosa 6 SE .. ... ... ... ... ... ... ... 145 6.7 3.0 5.2 ... virginica 9 VI 146 6.3 2.5 5.0 ... virginica 9 VI 147 6.5 3.0 5.2 ... virginica 9 VI 148 6.2 3.4 5.4 ... virginica 9 VI 149 5.9 3.0 5.1 ... virginica 9 VI [150 rows x 7 columns] Massive renaming column names iris.rename(columns=lambda x: &#39;XX&#39;+x) XXSLen XXSepal.Width ... XXSpecies_new XXSpecies_initial 0 5.1 3.5 ... 6 SE 1 4.9 3.0 ... 6 SE 2 4.7 3.2 ... 6 SE 3 4.6 3.1 ... 6 SE 4 5.0 3.6 ... 6 SE .. ... ... ... ... ... 145 6.7 3.0 ... 9 VI 146 6.3 2.5 ... 9 VI 147 6.5 3.0 ... 9 VI 148 6.2 3.4 ... 9 VI 149 5.9 3.0 ... 9 VI [150 rows x 7 columns] titanic.head(10) PassengerId Survived Pclass ... Fare Cabin Embarked 0 1 0 3 ... 7.2500 NaN S 1 2 1 1 ... 71.2833 C85 C 2 3 1 3 ... 7.9250 NaN S 3 4 1 1 ... 53.1000 C123 S 4 5 0 3 ... 8.0500 NaN S 5 6 0 3 ... 8.4583 NaN Q 6 7 0 1 ... 51.8625 E46 S 7 8 0 3 ... 21.0750 NaN S 8 9 1 3 ... 11.1333 NaN S 9 10 1 2 ... 30.0708 NaN C [10 rows x 12 columns] titanic.set_index(&#39;Name&#39;).rename(index=lambda x:x.replace(&#39; &#39;,&quot;_&quot;).upper()) PassengerId ... Embarked Name ... BRAUND,_MR._OWEN_HARRIS 1 ... S CUMINGS,_MRS._JOHN_BRADLEY_(FLORENCE_BRIGGS_THA... 2 ... C HEIKKINEN,_MISS._LAINA 3 ... S FUTRELLE,_MRS._JACQUES_HEATH_(LILY_MAY_PEEL) 4 ... S ALLEN,_MR._WILLIAM_HENRY 5 ... S ... ... ... ... MONTVILA,_REV._JUOZAS 887 ... S GRAHAM,_MISS._MARGARET_EDITH 888 ... S JOHNSTON,_MISS._CATHERINE_HELEN_&quot;CARRIE&quot; 889 ... S BEHR,_MR._KARL_HOWELL 890 ... C DOOLEY,_MR._PATRICK 891 ... Q [891 rows x 11 columns] 18.7 Join/Combine Data Frames df1.append(df2): Add the rows in df1 to the end of df2 (columns should be identical) (rbind() in R) pd.concat([df1, df2],axis=1): Add the columns in df1 to the end of df2 (rows should be identical) (cbind() in R) df1.join(df2,on=col1,how='inner'): SQL-style join the columns in df1 with the columns on df2 where the rows for col have identical values. ‘how’ can be one of ‘left’, ‘right’, ‘outer’, ‘inner’ 18.8 Statistics df.describe(): Summary statistics for numerical columns df.mean(): Returns the mean of all columns df.corr(): Returns the correlation between columns in a DataFrame df.count(): Returns the number of non-null values in each DataFrame column df.max(): Returns the highest value in each column df.min(): Returns the lowest value in each column df.median(): Returns the median of each column df.std(): Returns the standard deviation of each column titanic.count() PassengerId 891 Survived 891 Pclass 891 Name 891 Sex 891 Age 714 SibSp 891 Parch 891 Ticket 891 Fare 891 Cabin 204 Embarked 889 dtype: int64 titanic.median() PassengerId 446.0000 Survived 0.0000 Pclass 3.0000 Age 28.0000 SibSp 0.0000 Parch 0.0000 Fare 14.4542 dtype: float64 18.9 Generic Functions pandas.pivot_table() pandas.crosstab() pandas.cut() pandas.qcut() pandas.merge() pandas.get_dummies() 18.10 References Python for Data Analysis Python for Data Analysis GitHub How to get sample datasets in Python "],["nltk.html", "Chapter 19 NLTK 19.1 Installation 19.2 Corpora Data 19.3 WordNet 19.4 Discovering Word Collocations 19.5 Tokenization 19.6 Chinese Word Segmentation 19.7 Afterwords", " Chapter 19 NLTK The almighty nltk package! 19.1 Installation Install package in the terminal !pip install nltk Download nltk data in python import nltk nltk.download(&#39;all&#39;, halt_on_error=False) import nltk # nltk.download() The complete collection of the nltk.corpus is huge. You probably don’t need all of the corpora data. You can use nltk.download() to initialize a User Window for installation of specific datasets. 19.2 Corpora Data The package includes a lot of pre-loaded corpora datasets The default nltk_data directory is in /Users/YOUT_NAME/nltk_data/ Selective Examples Brown Corpus Reuters Corpus WordNet from nltk.corpus import gutenberg, brown, reuters # brown corpus ## Categories (topics?) print(&#39;Brown Corpus Total Categories: &#39;, len(brown.categories())) Brown Corpus Total Categories: 15 print(&#39;Categories List: &#39;, brown.categories()) Categories List: [&#39;adventure&#39;, &#39;belles_lettres&#39;, &#39;editorial&#39;, &#39;fiction&#39;, &#39;government&#39;, &#39;hobbies&#39;, &#39;humor&#39;, &#39;learned&#39;, &#39;lore&#39;, &#39;mystery&#39;, &#39;news&#39;, &#39;religion&#39;, &#39;reviews&#39;, &#39;romance&#39;, &#39;science_fiction&#39;] # Sentences print(brown.sents()[0]) ## first sentence [&#39;The&#39;, &#39;Fulton&#39;, &#39;County&#39;, &#39;Grand&#39;, &#39;Jury&#39;, &#39;said&#39;, &#39;Friday&#39;, &#39;an&#39;, &#39;investigation&#39;, &#39;of&#39;, &quot;Atlanta&#39;s&quot;, &#39;recent&#39;, &#39;primary&#39;, &#39;election&#39;, &#39;produced&#39;, &#39;``&#39;, &#39;no&#39;, &#39;evidence&#39;, &quot;&#39;&#39;&quot;, &#39;that&#39;, &#39;any&#39;, &#39;irregularities&#39;, &#39;took&#39;, &#39;place&#39;, &#39;.&#39;] print(brown.sents(categories=&#39;fiction&#39;)) ## first sentence for fiction texts [[&#39;Thirty-three&#39;], [&#39;Scotty&#39;, &#39;did&#39;, &#39;not&#39;, &#39;go&#39;, &#39;back&#39;, &#39;to&#39;, &#39;school&#39;, &#39;.&#39;], ...] ## Tagged Sentences print(brown.tagged_sents()[0]) [(&#39;The&#39;, &#39;AT&#39;), (&#39;Fulton&#39;, &#39;NP-TL&#39;), (&#39;County&#39;, &#39;NN-TL&#39;), (&#39;Grand&#39;, &#39;JJ-TL&#39;), (&#39;Jury&#39;, &#39;NN-TL&#39;), (&#39;said&#39;, &#39;VBD&#39;), (&#39;Friday&#39;, &#39;NR&#39;), (&#39;an&#39;, &#39;AT&#39;), (&#39;investigation&#39;, &#39;NN&#39;), (&#39;of&#39;, &#39;IN&#39;), (&quot;Atlanta&#39;s&quot;, &#39;NP$&#39;), (&#39;recent&#39;, &#39;JJ&#39;), (&#39;primary&#39;, &#39;NN&#39;), (&#39;election&#39;, &#39;NN&#39;), (&#39;produced&#39;, &#39;VBD&#39;), (&#39;``&#39;, &#39;``&#39;), (&#39;no&#39;, &#39;AT&#39;), (&#39;evidence&#39;, &#39;NN&#39;), (&quot;&#39;&#39;&quot;, &quot;&#39;&#39;&quot;), (&#39;that&#39;, &#39;CS&#39;), (&#39;any&#39;, &#39;DTI&#39;), (&#39;irregularities&#39;, &#39;NNS&#39;), (&#39;took&#39;, &#39;VBD&#39;), (&#39;place&#39;, &#39;NN&#39;), (&#39;.&#39;, &#39;.&#39;)] ## Sentence in natural forms sents = brown.sents(categories=&#39;fiction&#39;) [&#39; &#39;.join(sent) for sent in sents[1:5]] [&#39;Scotty did not go back to school .&#39;, &#39;His parents talked seriously and lengthily to their own doctor and to a specialist at the University Hospital -- Mr. McKinley was entitled to a discount for members of his family -- and it was decided it would be best for him to take the remainder of the term off , spend a lot of time in bed and , for the rest , do pretty much as he chose -- provided , of course , he chose to do nothing too exciting or too debilitating .&#39;, &#39;His teacher and his school principal were conferred with and everyone agreed that , if he kept up with a certain amount of work at home , there was little danger of his losing a term .&#39;, &#39;Scotty accepted the decision with indifference and did not enter the arguments .&#39;] ## Get tagged words tagged_words = brown.tagged_words(categories=&#39;fiction&#39;) #print(tagged_words[1]) ## a tuple ## Get all nouns nouns = [(word, tag) for word, tag in tagged_words if any (noun_tag in tag for noun_tag in [&#39;NP&#39;,&#39;NN&#39;])] ## Check first ten nouns nouns[:10] [(&#39;Scotty&#39;, &#39;NP&#39;), (&#39;school&#39;, &#39;NN&#39;), (&#39;parents&#39;, &#39;NNS&#39;), (&#39;doctor&#39;, &#39;NN&#39;), (&#39;specialist&#39;, &#39;NN&#39;), (&#39;University&#39;, &#39;NN-TL&#39;), (&#39;Hospital&#39;, &#39;NN-TL&#39;), (&#39;Mr.&#39;, &#39;NP&#39;), (&#39;McKinley&#39;, &#39;NP&#39;), (&#39;discount&#39;, &#39;NN&#39;)] ## Creating Freq list nouns_freq = nltk.FreqDist([w for w, t in nouns]) sorted(nouns_freq.items(),key=lambda x:x[1], reverse=True)[:20] [(&#39;man&#39;, 111), (&#39;time&#39;, 99), (&#39;men&#39;, 72), (&#39;room&#39;, 63), (&#39;way&#39;, 62), (&#39;eyes&#39;, 60), (&#39;face&#39;, 55), (&#39;house&#39;, 54), (&#39;head&#39;, 54), (&#39;night&#39;, 53), (&#39;day&#39;, 52), (&#39;hand&#39;, 50), (&#39;door&#39;, 47), (&#39;life&#39;, 44), (&#39;years&#39;, 44), (&#39;Mrs.&#39;, 41), (&#39;God&#39;, 41), (&#39;Kate&#39;, 40), (&#39;Mr.&#39;, 39), (&#39;people&#39;, 39)] sorted(nouns_freq.items(),key=lambda x:x[0], reverse=True)[:20] [(&#39;zoo&#39;, 2), (&#39;zlotys&#39;, 1), (&#39;zenith&#39;, 1), (&#39;youth&#39;, 5), (&#39;yelling&#39;, 1), (&#39;years&#39;, 44), (&#39;yearning&#39;, 1), (&quot;year&#39;s&quot;, 1), (&#39;year&#39;, 9), (&#39;yards&#39;, 4), (&#39;yard&#39;, 7), (&#39;yachts&#39;, 1), (&#39;writing&#39;, 2), (&#39;writers&#39;, 1), (&#39;writer&#39;, 4), (&#39;wrists&#39;, 1), (&#39;wrist&#39;, 2), (&#39;wrinkles&#39;, 1), (&#39;wrinkle&#39;, 1), (&#39;wretch&#39;, 1)] nouns_freq.most_common(10) [(&#39;man&#39;, 111), (&#39;time&#39;, 99), (&#39;men&#39;, 72), (&#39;room&#39;, 63), (&#39;way&#39;, 62), (&#39;eyes&#39;, 60), (&#39;face&#39;, 55), (&#39;house&#39;, 54), (&#39;head&#39;, 54), (&#39;night&#39;, 53)] ## Accsess data via fileid brown.fileids(categories=&#39;fiction&#39;)[0] &#39;ck01&#39; brown.sents(fileids=&#39;ck01&#39;) [[&#39;Thirty-three&#39;], [&#39;Scotty&#39;, &#39;did&#39;, &#39;not&#39;, &#39;go&#39;, &#39;back&#39;, &#39;to&#39;, &#39;school&#39;, &#39;.&#39;], ...] 19.3 WordNet 19.3.1 A Dictionary Resource from nltk.corpus import wordnet as wn word = &#39;walk&#39; # get synsets word_synsets = wn.synsets(word, pos=&#39;v&#39;) word_synsets [Synset(&#39;walk.v.01&#39;), Synset(&#39;walk.v.02&#39;), Synset(&#39;walk.v.03&#39;), Synset(&#39;walk.v.04&#39;), Synset(&#39;walk.v.05&#39;), Synset(&#39;walk.v.06&#39;), Synset(&#39;walk.v.07&#39;), Synset(&#39;walk.v.08&#39;), Synset(&#39;walk.v.09&#39;), Synset(&#39;walk.v.10&#39;)] Word sense is closely connected to its parts-of-speech. Therefore, in WordNet it is crucial to specify the POS tag of the word to obtain the correct synset of the word. There are four common part-of-speech tags in WordNet, as shown below: Part of Speech Tag Noun n Adjective a Adverb r Verb v Check the definition of a synset (i.e., a specific sense of the word): word_synsets[0].definition() &quot;use one&#39;s feet to advance; advance by steps&quot; Check the examples of a synset: word_synsets[0].examples() [&quot;Walk, don&#39;t run!&quot;, &#39;We walked instead of driving&#39;, &#39;She walks with a slight limp&#39;, &#39;The patient cannot walk yet&#39;, &#39;Walk over to the cabinet&#39;] ## Get details of each synset for s in word_synsets: if str(s.name()).startswith(&#39;walk.v&#39;): print( &#39;Syset ID: %s \\n&#39; &#39;POS Tag: %s \\n&#39; &#39;Definition: %s \\n&#39; &#39;Examples: %s \\n&#39; % (s.name(), s.pos(), s.definition(),s.examples()) ) Syset ID: walk.v.01 POS Tag: v Definition: use one&#39;s feet to advance; advance by steps Examples: [&quot;Walk, don&#39;t run!&quot;, &#39;We walked instead of driving&#39;, &#39;She walks with a slight limp&#39;, &#39;The patient cannot walk yet&#39;, &#39;Walk over to the cabinet&#39;] Syset ID: walk.v.02 POS Tag: v Definition: accompany or escort Examples: [&quot;I&#39;ll walk you to your car&quot;] Syset ID: walk.v.03 POS Tag: v Definition: obtain a base on balls Examples: [] Syset ID: walk.v.04 POS Tag: v Definition: traverse or cover by walking Examples: [&#39;Walk the tightrope&#39;, &#39;Paul walked the streets of Damascus&#39;, &#39;She walks 3 miles every day&#39;] Syset ID: walk.v.05 POS Tag: v Definition: give a base on balls to Examples: [] Syset ID: walk.v.06 POS Tag: v Definition: live or behave in a specified manner Examples: [&#39;walk in sadness&#39;] Syset ID: walk.v.07 POS Tag: v Definition: be or act in association with Examples: [&#39;We must walk with our dispossessed brothers and sisters&#39;, &#39;Walk with God&#39;] Syset ID: walk.v.08 POS Tag: v Definition: walk at a pace Examples: [&#39;The horses walked across the meadow&#39;] Syset ID: walk.v.09 POS Tag: v Definition: make walk Examples: [&#39;He walks the horse up the mountain&#39;, &#39;Walk the dog twice a day&#39;] Syset ID: walk.v.10 POS Tag: v Definition: take a walk; go for a walk; walk for pleasure Examples: [&#39;The lovers held hands while walking&#39;, &#39;We like to walk every Sunday&#39;] 19.3.2 Lexical Relations Extract words that maintain some lexical relations with the synset: word_synsets[0].hypernyms() # hypernym [Synset(&#39;travel.v.01&#39;)] word_synsets[0].hypernyms()[0].hyponyms() # similar words [Synset(&#39;accompany.v.02&#39;), Synset(&#39;advance.v.01&#39;), Synset(&#39;angle.v.01&#39;), Synset(&#39;ascend.v.01&#39;), Synset(&#39;automobile.v.01&#39;), Synset(&#39;back.v.02&#39;), Synset(&#39;bang.v.04&#39;), Synset(&#39;beetle.v.02&#39;), Synset(&#39;betake_oneself.v.01&#39;), Synset(&#39;billow.v.02&#39;), Synset(&#39;bounce.v.03&#39;), Synset(&#39;breeze.v.02&#39;), Synset(&#39;caravan.v.01&#39;), Synset(&#39;career.v.01&#39;), Synset(&#39;carry.v.36&#39;), Synset(&#39;circle.v.01&#39;), Synset(&#39;circle.v.02&#39;), Synset(&#39;circuit.v.01&#39;), Synset(&#39;circulate.v.07&#39;), Synset(&#39;come.v.01&#39;), Synset(&#39;come.v.11&#39;), Synset(&#39;crawl.v.01&#39;), Synset(&#39;cruise.v.02&#39;), Synset(&#39;derail.v.02&#39;), Synset(&#39;descend.v.01&#39;), Synset(&#39;do.v.13&#39;), Synset(&#39;drag.v.04&#39;), Synset(&#39;draw.v.12&#39;), Synset(&#39;drive.v.02&#39;), Synset(&#39;drive.v.14&#39;), Synset(&#39;ease.v.01&#39;), Synset(&#39;fall.v.01&#39;), Synset(&#39;fall.v.15&#39;), Synset(&#39;ferry.v.03&#39;), Synset(&#39;float.v.01&#39;), Synset(&#39;float.v.02&#39;), Synset(&#39;float.v.05&#39;), Synset(&#39;flock.v.01&#39;), Synset(&#39;fly.v.01&#39;), Synset(&#39;fly.v.06&#39;), Synset(&#39;follow.v.01&#39;), Synset(&#39;follow.v.04&#39;), Synset(&#39;forge.v.05&#39;), Synset(&#39;get_around.v.04&#39;), Synset(&#39;ghost.v.01&#39;), Synset(&#39;glide.v.01&#39;), Synset(&#39;go_around.v.02&#39;), Synset(&#39;hiss.v.02&#39;), Synset(&#39;hurtle.v.01&#39;), Synset(&#39;island_hop.v.01&#39;), Synset(&#39;lance.v.01&#39;), Synset(&#39;lurch.v.03&#39;), Synset(&#39;outflank.v.01&#39;), Synset(&#39;pace.v.02&#39;), Synset(&#39;pan.v.01&#39;), Synset(&#39;pass.v.01&#39;), Synset(&#39;pass_over.v.04&#39;), Synset(&#39;play.v.09&#39;), Synset(&#39;plow.v.03&#39;), Synset(&#39;prance.v.02&#39;), Synset(&#39;precede.v.04&#39;), Synset(&#39;precess.v.01&#39;), Synset(&#39;proceed.v.02&#39;), Synset(&#39;propagate.v.02&#39;), Synset(&#39;pursue.v.02&#39;), Synset(&#39;push.v.09&#39;), Synset(&#39;raft.v.02&#39;), Synset(&#39;repair.v.03&#39;), Synset(&#39;retreat.v.02&#39;), Synset(&#39;retrograde.v.02&#39;), Synset(&#39;return.v.01&#39;), Synset(&#39;ride.v.01&#39;), Synset(&#39;ride.v.04&#39;), Synset(&#39;ride.v.10&#39;), Synset(&#39;rise.v.01&#39;), Synset(&#39;roll.v.12&#39;), Synset(&#39;round.v.01&#39;), Synset(&#39;run.v.11&#39;), Synset(&#39;run.v.34&#39;), Synset(&#39;rush.v.01&#39;), Synset(&#39;scramble.v.01&#39;), Synset(&#39;seek.v.04&#39;), Synset(&#39;shuttle.v.01&#39;), Synset(&#39;sift.v.01&#39;), Synset(&#39;ski.v.01&#39;), Synset(&#39;slice_into.v.01&#39;), Synset(&#39;slither.v.01&#39;), Synset(&#39;snowshoe.v.01&#39;), Synset(&#39;speed.v.04&#39;), Synset(&#39;steamer.v.01&#39;), Synset(&#39;step.v.01&#39;), Synset(&#39;step.v.02&#39;), Synset(&#39;step.v.06&#39;), Synset(&#39;stray.v.02&#39;), Synset(&#39;swap.v.02&#39;), Synset(&#39;swash.v.01&#39;), Synset(&#39;swim.v.01&#39;), Synset(&#39;swim.v.05&#39;), Synset(&#39;swing.v.03&#39;), Synset(&#39;taxi.v.01&#39;), Synset(&#39;trail.v.03&#39;), Synset(&#39;tram.v.01&#39;), Synset(&#39;transfer.v.06&#39;), Synset(&#39;travel.v.04&#39;), Synset(&#39;travel.v.05&#39;), Synset(&#39;travel.v.06&#39;), Synset(&#39;travel_by.v.01&#39;), Synset(&#39;travel_purposefully.v.01&#39;), Synset(&#39;travel_rapidly.v.01&#39;), Synset(&#39;trundle.v.01&#39;), Synset(&#39;turn.v.06&#39;), Synset(&#39;walk.v.01&#39;), Synset(&#39;walk.v.10&#39;), Synset(&#39;weave.v.04&#39;), Synset(&#39;wend.v.01&#39;), Synset(&#39;wheel.v.03&#39;), Synset(&#39;whine.v.01&#39;), Synset(&#39;whish.v.02&#39;), Synset(&#39;whisk.v.02&#39;), Synset(&#39;whistle.v.02&#39;), Synset(&#39;withdraw.v.01&#39;), Synset(&#39;zigzag.v.01&#39;), Synset(&#39;zoom.v.02&#39;)] word_synsets[0].root_hypernyms() # root [Synset(&#39;travel.v.01&#39;)] word_synsets[0].hypernym_paths() # from root to this synset in WordNet [[Synset(&#39;travel.v.01&#39;), Synset(&#39;walk.v.01&#39;)]] Synonyms # Collect synonyms of all synsets synonyms = [] for syn in wn.synsets(&#39;book&#39;, pos=&#39;v&#39;): for lemma in syn.lemmas(): synonyms.append(lemma.name()) len(synonyms) 6 len(set(synonyms)) 3 print(set(synonyms)) {&#39;book&#39;, &#39;hold&#39;, &#39;reserve&#39;} Antonyms # First Synset Lemma String word_synsets[0].lemmas()[0].name() # Antonyms of the First Synset &#39;walk&#39; word_synsets[0].lemmas()[0].antonyms()[0] Lemma(&#39;ride.v.02.ride&#39;) While previous taxonomic relations (e.g., hypernymy and hyponymy) are in-between synsets, the synonymy and antonymy relations are in-between lemmas. We need to be very clear about the use of the three variants in WordNet: Word Form Lemma Synset 19.3.3 Semantic Similarity Computation Synsets are organized in a hypernym tree, which can be used for reasoning about the semantic similarity of two Synsets. The closer the two Synsets are in the tree, the more similar they are. # syn1 = wn.synsets(&#39;walk&#39;, pos=&#39;v&#39;)[0] syn1 = wn.synset(&#39;walk.v.01&#39;) syn2 = wn.synset(&#39;toddle.v.01&#39;) syn3 = wn.synset(&#39;think.v.01&#39;) syn1.wup_similarity(syn2) 0.8 syn1.wup_similarity(syn3) 0.2857142857142857 syn1.path_similarity(syn2) 0.5 syn1.path_similarity(syn3) 0.16666666666666666 ref = syn1.hypernyms()[0] syn1.shortest_path_distance(ref) 1 syn2.shortest_path_distance(ref) 2 syn1.shortest_path_distance(syn2) 1 print(ref.definition()) change location; move, travel, or proceed, also metaphorically print([l.name() for l in ref.lemmas()]) [&#39;travel&#39;, &#39;go&#39;, &#39;move&#39;, &#39;locomote&#39;] syn1.hypernym_paths() [[Synset(&#39;travel.v.01&#39;), Synset(&#39;walk.v.01&#39;)]] syn2.hypernym_paths() [[Synset(&#39;travel.v.01&#39;), Synset(&#39;walk.v.01&#39;), Synset(&#39;toddle.v.01&#39;)]] syn3.hypernym_paths() [[Synset(&#39;think.v.03&#39;), Synset(&#39;evaluate.v.02&#39;), Synset(&#39;think.v.01&#39;)]] The wup_similarity method is short for Wu-Pamler Similarity. It is a scoring method for how similar the word senses are based on where the Synsets occur relative to each other in the hypernym tree. For more information or other scoring methods, please check NLTK WordNet documentation. 19.4 Discovering Word Collocations from nltk.corpus import brown from nltk.collocations import BigramCollocationFinder from nltk.metrics import BigramAssocMeasures words = [w.lower() for w in brown.words()] bcf = BigramCollocationFinder.from_words(words) bcf.nbest(BigramAssocMeasures.likelihood_ratio, 4) [(&#39;;&#39;, &#39;;&#39;), (&#39;?&#39;, &#39;?&#39;), (&#39;of&#39;, &#39;the&#39;), (&#39;.&#39;, &#39;``&#39;)] # deal with stopwords from nltk.corpus import stopwords stopset = set(stopwords.words(&#39;english&#39;)) ## Fitler critera: ## remove words whose length &lt; 3 or which are on the stop word list filter_stops = lambda w: len(w) &lt; 3 or w in stopset bcf.apply_word_filter(filter_stops) bcf.nbest(BigramAssocMeasures.likelihood_ratio, 10) [(&#39;united&#39;, &#39;states&#39;), (&#39;new&#39;, &#39;york&#39;), (&#39;per&#39;, &#39;cent&#39;), (&#39;years&#39;, &#39;ago&#39;), (&#39;rhode&#39;, &#39;island&#39;), (&#39;los&#39;, &#39;angeles&#39;), (&#39;peace&#39;, &#39;corps&#39;), (&#39;san&#39;, &#39;francisco&#39;), (&#39;high&#39;, &#39;school&#39;), (&#39;fiscal&#39;, &#39;year&#39;)] ## apply freq-based filter bcf.apply_freq_filter(3) bcf.nbest(BigramAssocMeasures.likelihood_ratio, 10) [(&#39;united&#39;, &#39;states&#39;), (&#39;new&#39;, &#39;york&#39;), (&#39;per&#39;, &#39;cent&#39;), (&#39;years&#39;, &#39;ago&#39;), (&#39;rhode&#39;, &#39;island&#39;), (&#39;los&#39;, &#39;angeles&#39;), (&#39;peace&#39;, &#39;corps&#39;), (&#39;san&#39;, &#39;francisco&#39;), (&#39;high&#39;, &#39;school&#39;), (&#39;fiscal&#39;, &#39;year&#39;)] Exercise 19.1 Try to identify bigram collocations in the corpus, Alice in the Wonderland. The texts are available in nltk.corpus.gutenburg. Exercise 19.2 Following the same strategy of bigram collocation extraction, please try to extract trigrams from the brown corpus. Remove stop words and short words as we did in the lecture. Include only trigrams whose frequency &gt; 5. 19.5 Tokenization import nltk from nltk.tokenize import word_tokenize, sent_tokenize text = &quot;&quot;&quot;Three blind mice! See how they run! They all ran after the farmer&#39;s wife, Who cut off their tails with a carving knife. Did you ever see such a thing in your life As three blind mice? &quot;&quot;&quot; text_sent = sent_tokenize(text) text_word = word_tokenize(text) text_pos = nltk.pos_tag(text_word) With words, we can create a frequency list: import pprint as pp text_fd= nltk.FreqDist([w.lower() for w in text_word]) pp.pprint(text_fd.most_common(10)) [(&#39;three&#39;, 2), (&#39;blind&#39;, 2), (&#39;mice&#39;, 2), (&#39;!&#39;, 2), (&#39;see&#39;, 2), (&#39;they&#39;, 2), (&#39;a&#39;, 2), (&#39;how&#39;, 1), (&#39;run&#39;, 1), (&#39;all&#39;, 1)] Exercise 19.3 Provide the word frequency list of the top 30 nouns in Alice in the Wonderland. The raw texts of the novel is available in NTLK (see below). alice = nltk.corpus.gutenberg.raw(fileids=&#39;carroll-alice.txt&#39;) [(&#39;Alice&#39;, 392), (&#39;Queen&#39;, 71), (&#39;time&#39;, 65), (&#39;King&#39;, 60), (&#39;Turtle&#39;, 58), (&#39;Mock&#39;, 56), (&#39;Hatter&#39;, 55), (&#39;*&#39;, 54), (&#39;Gryphon&#39;, 54), (&#39;way&#39;, 53), (&#39;head&#39;, 50), (&#39;thing&#39;, 49), (&#39;voice&#39;, 47), (&#39;Rabbit&#39;, 44), (&#39;Duchess&#39;, 42), (&#39;tone&#39;, 40), (&#39;Dormouse&#39;, 40), (&#39;March&#39;, 34), (&#39;moment&#39;, 31), (&#39;Hare&#39;, 31), (&#39;nothing&#39;, 30), (&#39;things&#39;, 30), (&#39;door&#39;, 30), (&#39;Mouse&#39;, 29), (&#39;eyes&#39;, 28), (&#39;Caterpillar&#39;, 27), (&#39;day&#39;, 25), (&#39;course&#39;, 25), (&#39;Cat&#39;, 25), (&#39;round&#39;, 23)] 19.6 Chinese Word Segmentation import jieba text = &quot;&quot;&quot; 高速公路局說，目前在國道3號北向水上系統至中埔路段車多壅塞，已回堵約3公里。另外，國道1號北向仁德至永康路段路段，已回堵約有7公里。建議駕駛人提前避開壅塞路段改道行駛，行經車多路段請保持行車安全距離，小心行駛。 國道車多壅塞路段還有國1內湖-五堵北向路段、楊梅-新竹南向路段；國3三鶯-關西服務區南向路段、快官-霧峰南向路段、水上系統-中埔北向路段；國6霧峰系統-東草屯東向路段、國10燕巢-燕巢系統東向路段。 &quot;&quot;&quot; text_jb = jieba.lcut(text) Building prefix dict from the default dictionary ... Dumping model to file cache /var/folders/n7/ltpzwx813c599nfxfb94s_640000gn/T/jieba.cache Loading model cost 1.531 seconds. Prefix dict has been built successfully. print(&#39; | &#39;.join(text_jb)) | 高速公路 | 局說 | ， | 目前 | 在 | 國道 | 3 | 號 | 北向 | 水上 | 系統 | 至 | 中埔 | 路段 | 車多 | 壅塞 | ， | 已回 | 堵約 | 3 | 公里 | 。 | 另外 | ， | 國道 | 1 | 號 | 北向 | 仁德 | 至 | 永康 | 路段 | 路段 | ， | 已回 | 堵 | 約 | 有 | 7 | 公里 | 。 | 建議 | 駕駛人 | 提前 | 避開 | 壅塞 | 路段 | 改道 | 行駛 | ， | 行經車 | 多 | 路段 | 請 | 保持 | 行車 | 安全 | 距離 | ， | 小心 | 行駛 | 。 | | 國道 | 車多 | 壅塞 | 路段 | 還有國 | 1 | 內湖 | - | 五堵 | 北向 | 路段 | 、 | 楊梅 | - | 新竹 | 南向 | 路段 | ； | 國 | 3 | 三鶯 | - | 關 | 西服 | 務區 | 南向 | 路段 | 、 | 快官 | - | 霧峰 | 南向 | 路段 | 、 | 水上 | 系統 | - | 中埔 | 北向 | 路段 | ； | 國 | 6 | 霧峰 | 系統 | - | 東 | 草屯 | 東向 | 路段 | 、 | 國 | 10 | 燕巢 | - | 燕巢 | 系統 | 東向 | 路段 | 。 | 19.7 Afterwords There are many other aspects that we need to take into account when processing texts. Text segmentation is a non-trivial task in natural language processing. The base units that we work with will turn out to be connected to the specific research questions we aim to asnwer. If you would like to know more about computational text analytics, I would highly recommend you to move on to two more advanced courses: ENC2036 Corpus Linguistics ENC2045 Computational Linguistics "],["web-scraping.html", "Chapter 20 Web Scraping 20.1 webbrowswer module 20.2 requests Module 20.3 bs4 Module (Beautiful Soup) 20.4 Reference", " Chapter 20 Web Scraping Web scraping is the term for using a program to download and process content from the web. webbrowser: A default Python module to open a browser to specific page. requests: A module to download files and web pages from the Internet. bs4: A modile to parse HTML, i.e., the format that web pages are written in. selenium: A module to launch and control a web browser (e.g., filling in forms, simulating mouse clicks.) 20.1 webbrowswer module Create a python script with the following codes, named py-checkword.py #! python3 import webbrowser, sys, pyperclip if len(sys.argv) &gt; 1: # Get input from the command line target = &#39; &#39;.join(sys.argv[1:]) else: # Get input from the clipboard target = pyperclip.paste() webbrowser.open(&#39;https://www.dictionary.com/browse/&#39;+ target) Run the python script in the terminal python py-checkword.py beauty Exercise 20.1 How to modify the py-checkword.py so that the user can attach a list of words separated by spaces for checking? For example, the modified script will be able to open three web browsers for beauty, internet, and national. python py-checkword2.py beauty internet national 20.2 requests Module The requests modules allow us to easily download files from the web without having to worry about complicated issues such as network errors, connection problems, and data compression. import requests res = requests.get(&#39;https://www.gutenberg.org/files/2591/2591-0.txt&#39;) type(res) ## Check status code to see if the download is successful &lt;class &#39;requests.models.Response&#39;&gt; res.status_code == requests.codes.ok ## `requests.codes.ok` == 200 True len(res.text) 560045 print(res.text[:250]) ï»¿The Project Gutenberg eBook of Grimmsâ Fairy Tales, by Jacob Grimm and Wilhelm Grimm This eBook is for the use of anyone anywhere in the United States and most other parts of the world at no cost and with almost no restrictions whatsoever. Prepare potential errors during the file download import requests res = requests.get(&#39;https://www.gutenberg.org/file-that-does-not-exist.txt&#39;) ## Check status code to see if the download is successful res.status_code == requests.codes.ok ## `requests.codes.ok` == 200 False len(res.text) 6396 print(res.text[:250]) &lt;!DOCTYPE html&gt; &lt;html class=&quot;client-nojs&quot; lang=&quot;en&quot; dir=&quot;ltr&quot;&gt; &lt;head&gt; &lt;meta charset=&quot;UTF-8&quot;/&gt; &lt;title&gt;404 | Project Gutenberg&lt;/title&gt; &lt;link rel=&quot;stylesheet&quot; href=&quot;/gutenberg/style.css?v=1.1&quot;&gt; &lt;link rel=&quot;stylesheet&quot; href=&quot;/gutenberg/collapsible.css res.raise_for_status() Error in py_call_impl(callable, dots$args, dots$keywords): requests.exceptions.HTTPError: 404 Client Error: Not Found for url: https://www.gutenberg.org/file-that-does-not-exist.txt A better way to modify the codes is to make sure that the program stops as soon as some unexpected error happens. Always call raise_for_status() after calling requests.get() because we need to make sure the file has been successfully downloaded before the program continues. import requests res = requests.get(&#39;https://www.gutenberg.org/file-that-does-not-exist.txt&#39;) try: res.raise_for_status() except Exception as exc: print(&#39;There was a problem with the link: %s&#39; % (exc)) There was a problem with the link: 404 Client Error: Not Found for url: https://www.gutenberg.org/file-that-does-not-exist.txt Usually we may want to scrape the texts from the web and save them on the Hard Drive. import requests res = requests.get(&#39;https://www.gutenberg.org/files/2591/2591-0.txt&#39;) try: res.raise_for_status() except Exception as exc: print(&#39;There was a problem with the link: %s&#39; % (exc)) with open(&#39;grimms.txt&#39;, &#39;w&#39;) as f: f.write(res.text) 560045 20.3 bs4 Module (Beautiful Soup) Beautiful Soup is a module for extracting information from an HTML page. The package name is pip install -U beatifulsoup4 but in use, it is import bs4. Each Word is a dict: “headword”: head word string “pronunciation”: IPA “parts-of-speech”: A list of senses {“definition”: ’‘, “example”:’’} import requests, bs4 target=&#39;individual&#39; res = requests.get(&#39;https://www.dictionary.com/browse/&#39; + target) res.raise_for_status() soup = bs4.BeautifulSoup(res.text, &#39;lxml&#39;) entries = soup.select(&#39;.css-1avshm7&#39;) # entries ## Define the word structure (dict) cur_word = {} # for each entry for i, entry in enumerate(entries): ## Include only the main entry of the page if len(entry.select(&#39;h1&#39;)) &gt; 0: #print(&#39;Entry Number: &#39;, i) ## headword and pronunciations cur_headword = entry.select(&#39;h1&#39;)[0].getText() cur_spell = entry.select(&#39;.pron-spell-content&#39;)[0].getText() cur_ipa = entry.select(&#39;.pron-ipa-content&#39;)[0].getText().encode(&#39;utf-8&#39;).decode(&#39;utf-8&#39;) #print(&#39;Headword: &#39;, cur_headword) #print(&#39;Pronunciation: &#39;, cur_ipa) cur_word[&#39;headword&#39;] = cur_headword cur_word[&#39;pronunciation&#39;] = cur_ipa # for each POS type in the current entry for pos in entry.select(&#39;.css-pnw38j&#39;): cur_pos = pos.select(&#39;.luna-pos&#39;)[0].getText() #print(&#39;=&#39;*10) #print(&#39;POS: &#39;, cur_pos.upper()) cur_definitions = pos.select(&#39;div[value]&#39;) cur_sense_list =[] # for each definition in the current POS for sense in cur_definitions: #print(&#39;DEF: &#39; + sense.find(text=True, recursive=True)) ## check if there&#39;s any example ex = sense.find(attrs={&#39;class&#39;:&#39;luna-example&#39;}) if ex is not None: cur_ex = ex.getText() _ = ex.extract() else: cur_ex = &#39;&#39; cur_def = sense.getText() #print(&#39;-&#39;*10) #print(&#39;Definition: &#39; + cur_def) #print(&#39;Example: &#39;+ cur_ex) cur_sense = {&#39;definition&#39;: cur_def, &#39;example&#39;: cur_ex} cur_sense_list.append(cur_sense) cur_word[cur_pos] = cur_sense_list import json with open(target+&#39;.json&#39;, &#39;w&#39;, encoding=&#39;utf-8&#39;) as f: json.dump(cur_word, f, ensure_ascii=False) print(json.dumps(cur_word, sort_keys=False, indent=4, ensure_ascii=False)) import json with open(&#39;produce.json&#39;,&#39;r&#39;, encoding=&#39;utf-8&#39;) as f: cur_word = json.load(f) cur_word.keys() dict_keys([&#39;headword&#39;, &#39;pronunciation&#39;, &#39;verb (used with object),&#39;, &#39;verb (used without object),&#39;, &#39;noun&#39;]) print(json.dumps(cur_word, sort_keys=False, indent=4, ensure_ascii=False)) { &quot;headword&quot;: &quot;produce&quot;, &quot;pronunciation&quot;: &quot;/ verb prəˈdus, -ˈdyus; noun ˈprɒd us, -yus, ˈproʊ dus, -dyus /&quot;, &quot;verb (used with object),&quot;: [ { &quot;definition&quot;: &quot;to bring into existence; give rise to; cause: &quot;, &quot;example&quot;: &quot;to produce steam.&quot; }, { &quot;definition&quot;: &quot;to bring into existence by intellectual or creative ability: &quot;, &quot;example&quot;: &quot;to produce a great painting.&quot; }, { &quot;definition&quot;: &quot;to make or manufacture: &quot;, &quot;example&quot;: &quot;to produce automobiles for export.&quot; }, { &quot;definition&quot;: &quot;to bring forth; give birth to; bear: &quot;, &quot;example&quot;: &quot;to produce a litter of puppies.&quot; }, { &quot;definition&quot;: &quot;to provide, furnish, or supply; yield: &quot;, &quot;example&quot;: &quot;a mine producing silver.&quot; }, { &quot;definition&quot;: &quot;Finance. &quot;, &quot;example&quot;: &quot;&quot; }, { &quot;definition&quot;: &quot;to cause to accrue: &quot;, &quot;example&quot;: &quot;stocks producing unexpected dividends.&quot; }, { &quot;definition&quot;: &quot;to bring forward; present to view or notice; exhibit: &quot;, &quot;example&quot;: &quot;to produce one&#39;s credentials.&quot; }, { &quot;definition&quot;: &quot;to bring (a play, movie, opera, etc.) before the public.&quot;, &quot;example&quot;: &quot;&quot; }, { &quot;definition&quot;: &quot;to extend or prolong, as a line.&quot;, &quot;example&quot;: &quot;&quot; } ], &quot;verb (used without object),&quot;: [ { &quot;definition&quot;: &quot;to create, bring forth, or yield offspring, products, etc.: &quot;, &quot;example&quot;: &quot;Their mines are closed because they no longer produce.&quot; }, { &quot;definition&quot;: &quot;Economics. &quot;, &quot;example&quot;: &quot;&quot; }, { &quot;definition&quot;: &quot;to create economic value; bring crops, goods, etc., to a point at which they will command a price.&quot;, &quot;example&quot;: &quot;&quot; } ], &quot;noun&quot;: [ { &quot;definition&quot;: &quot;something that is produced; yield; product. &quot;, &quot;example&quot;: &quot;&quot; }, { &quot;definition&quot;: &quot;agricultural products collectively, especially vegetables and fruits.&quot;, &quot;example&quot;: &quot;&quot; }, { &quot;definition&quot;: &quot;offspring, especially of a female animal: &quot;, &quot;example&quot;: &quot;the produce of a mare.&quot; } ] } Exercise 20.2 Now how to extend this short script to allow the users to perform searches of multiple words all at once, scrape all definitions and examples from the website of Dictionary.com, and save them to the Hard Drive as json files in a specific directory? checkwords(targets=[&quot;individual&quot;, &quot;wonderful&quot;], outdir = &#39;dictionary_results/&#39;) import json outdir = &#39;dictionary_results/&#39; with open(outdir+&#39;individual.json&#39;,&#39;r&#39;) as f: cur_word = json.load(f) print(json.dumps(cur_word, sort_keys=False, indent=4, ensure_ascii=False)) { &quot;headword&quot;: &quot;individual&quot;, &quot;pronunciation&quot;: &quot;/ ˌɪn dəˈvɪdʒ u əl /&quot;, &quot;noun&quot;: [ { &quot;definition&quot;: &quot;a single human being, as distinguished from a group.&quot;, &quot;example&quot;: &quot;&quot; }, { &quot;definition&quot;: &quot;a person: &quot;, &quot;example&quot;: &quot;a strange individual.&quot; }, { &quot;definition&quot;: &quot;a distinct, indivisible entity; a single thing, being, instance, or item.&quot;, &quot;example&quot;: &quot;&quot; }, { &quot;definition&quot;: &quot;a group considered as a unit.&quot;, &quot;example&quot;: &quot;&quot; }, { &quot;definition&quot;: &quot;Biology. a single organism capable of independent existence. a member of a compound organism or colony.&quot;, &quot;example&quot;: &quot;&quot; }, { &quot;definition&quot;: &quot;Cards. a duplicate-bridge tournament in which each player plays the same number of hands in partnership with every other player, individual scores for each player being kept for each hand.&quot;, &quot;example&quot;: &quot;&quot; } ], &quot;adjective&quot;: [ { &quot;definition&quot;: &quot;single; particular; separate: &quot;, &quot;example&quot;: &quot;to number individual copies of a limited edition.&quot; }, { &quot;definition&quot;: &quot;intended for the use of one person only: &quot;, &quot;example&quot;: &quot;to serve individual portions of a pizza.&quot; }, { &quot;definition&quot;: &quot;of, relating to, or characteristic of a particular person or thing: &quot;, &quot;example&quot;: &quot;individual tastes.&quot; }, { &quot;definition&quot;: &quot;distinguished by special, singular, or markedly personal characteristics; exhibiting unique or unusual qualities: &quot;, &quot;example&quot;: &quot;a highly individual style of painting.&quot; }, { &quot;definition&quot;: &quot;existing as a distinct, indivisible entity, or considered as such; discrete: &quot;, &quot;example&quot;: &quot;individual parts of a tea set.&quot; }, { &quot;definition&quot;: &quot;of which each is different or of a different design from the others: &quot;, &quot;example&quot;: &quot;a set of individual coffee cups.&quot; } ] } 20.4 Reference Beautiful Soup Documentation "],["transcribing.html", "Chapter 21 Transcribing 21.1 Working with Audio Files 21.2 Working with Microphone Inputs 21.3 References", " Chapter 21 Transcribing In this unit, we look at an example of speech recognition using python. In language studies, we often need to transcribe the audio data into texts for further study. This unit will show you how we can utilize python to automate the speech-to-text transcribing. There are in general two sources of audio data: From a audio file (e.g., .wav) From the system microphone (e.g., speech created on the fly) 21.1 Working with Audio Files Recognizer: First we need to initilize a Recognizer object, which is mainly responsible for the speech-to-text recognition. AudioFile: Create an AudioFile object with a path to the audio file AudioData: Process the audio file and record the data from the AudioFile into an AudioData object. Choose the API for Speech-to-Text conversion: Use the Recognizer’s method, Recognizer.recognize_google(), to recognize speech in the AudioData. import speech_recognition as sr sr.__version__ &#39;3.8.1&#39; r = sr.Recognizer() #r.recognize_google() havard = sr.AudioFile(&#39;demo_data/audio/語音測試.wav&#39;) with havard as source: ## adjust for noise #r.adjust_for_ambient_noise(source) audio = r.record(source) type(havard) &lt;class &#39;speech_recognition.AudioFile&#39;&gt; type(audio) &lt;class &#39;speech_recognition.AudioData&#39;&gt; r.recognize_google(audio, language=&#39;zh&#39;) &#39;我現在在做基本的語音測試謝謝&#39; 21.2 Working with Microphone Inputs Recognizer: First we need to initilize a Recognizer object, which is mainly responsible for the speech-to-text recognition. Microphone: Create an Microphone object with a specific index to the system microphone AudioData: Record the speech data from the Microphone into an AudioData object. Choose the API for Speech-to-Text conversion: Use the Recognizer’s method, Recognizer.recognize_google(), to recognize speech in the AudioData. import speech_recognition as sr r = sr.Recognizer() mic = sr.Microphone() sr.Microphone.list_microphone_names() mic = sr.Microphone(device_index=0) with mic as source: audio = r.listen(source) type(audio) try: r.recognize_google(audio, language=&#39;zh&#39;) except sr.UnknownValueError: print(&#39;Unable to recognize the speech.&#39;) 21.3 References The Ultimate Guide to Speech Recognition with Python Harvard Sentences: These phrases were published by the IEEE in 1965 for use in speech intelligibility testing of telephone lines. They are still used in VoIP and cellular testing today. Available recordings of these sentences can be found on the Open Speech Repository website. "],["the-shell.html", "A The Shell A.1 Why do you need to know shell commands? A.2 Shebang Line A.3 Basic Shell Commands A.4 Text-Analytic Related Commands A.5 References", " A The Shell A.1 Why do you need to know shell commands? The command line has many great advantages that can make you a more efficient and productive data scientist. Janssens (2014) has nicely summarized the strengths of command lines in five points: The command line is agile The command line is augmenting The command line is scalable The command line is extensible The command line is ubiquitouos A.2 Shebang Line Like in R console, you can interact with the R console line by line or you can package all your R scripts in a file. For command line, you can also combine several shell commands into a script file. For a shell script file, you need a shebang line, which is the character sequence consisting of the characters number sign and exclamation mark (#!) at the beginning of a script. This line would indicate to the shell engine which interpreter (language environment) is needed to parse the script file. A shell script often takes a shebang line as below. #!/bin/sh #!/bin/bash A.3 Basic Shell Commands Linux Man Pages The most basic commands are listed below: pwd (print working directory). Shows directory or “folder” you are currently operating in. This is not necessarily the same as the R working directory you get from getwd(). ls (list files). Shows the files in the current working directory. This is equivalent to looking at the files in your Finder/Explorer/File Manager. Use ls -a to also list hidden files, such as .Rhistory and .git. cd (change directory). Allows you to navigate through your directories by changing the shell’s working directory. You can navigate like so: go to subdirectory foo of current working directory: cd foo go to parent of current working directory: cd .. go to your “home” directory: cd ~ or simply cd go to directory using absolute path, works regardless of your current working directory: cd /home/my_username/Desktop. Windows uses a slightly different syntax with the slashes between the folder names reversed, \\, e.g. cd C:\\Users\\MY_USERNAME\\Desktop. Pro tip 1: Dragging and dropping a file or folder into the terminal window will paste the absolute path into the window. Pro tip 2: Use the tab key to autocomplete unambiguous directory and file names. Hit tab twice to see all ambiguous options. Use arrow-up and arrow-down to repeat previous commands. Or search for previous commands with CTRL + r. which Show the full path of a shell commands which python: Check which version of python your system uses which r: Check which version of R your system uses cp Copy files and directories rm Remove files and directories mv Move files and directories mkdir Make directories A.4 Text-Analytic Related Commands gzip [-cd#] FILENAME. Zips/Unzips a file. The zipped file created by gzip is often with the extension *.gz. -c: write output on standard output -d: decompress -#: Regulate the speed of compression using the specified digit #, where -1 or –fast indicates the fastest compression method (less compression) and -9 or –best indicates the slowest compression method (best compression). The default compression level is -6. tar [-j|-z] [cv] [-f FILENAME] filename.... Archive many files into one single file -j: Use bzip2 compression -z: Use gzip compression -c: Create a new archive -v: Print all files processed verbosely tar [-j|-z] [xv] [-f FILENAME] [-C PATH. Restore the original files from the achive file -j: Use bzip2 compression -z: Use gzip compression -x: Extract files from archive -v: Print all files processed verbosely C: Extract files to a particular path So when you see a file with the extention of *.tar.gz, this indicates that this file is a zipped file, which compresses a list of multiple files into one tar archive. Usually people pass their collection of multiple text files (i.e., a corpus) in this way because it is often easier to share one file instead of tons of files at a time. A.5 References If you are interested in more functions and potentials of shell commands, I would highly recommend the book Data Science at the Command Line. References Janssens, J. (2014). Data science at the command line: Facing the future with time-tested tools. \" O’Reilly Media, Inc.\". "],["reproducible-report.html", "B Reproducible Report B.1 R Markdown B.2 Open Science B.3 Installing R Markdown B.4 R Markdown Components B.5 Tips B.6 References", " B Reproducible Report Creating reproducible reports is important in data analysis, or in general, open science. The idea behind the reproducible reports is that any readers should be able to implement the same analysis on the dataset and obtain the same results. A reproducible report usually includes: Your codes for data processing and analysis Your results of the data analysis Your descriptions, summaries and/or interpretation of the analysis A reproducible report can be presented in many different forms: HTML PDF MS-DOC Slide Formats Website B.1 R Markdown R markdown is a variant of the Markdown language, which is a markup language that provides a way of creating easy to read plain text file which can incorporate formatted text, images, headers and links to other documents. Another classic example of the markup language is the HTML (Hypertext Markup Language) B.2 Open Science Open science is a common goal in the academia. As a member of this scientific communicity, we hope that everyone can do as much as they can to make their data, methods, results and inferences transparent and available to everyone. There are several important tenets for open science (See Open science): Transparency in experimental methodology, observation, collection of data and analytical methods. Public availability and re-usability of scientific data Public accessibility and transparency of scientific communication Using web-based tools to facilitate scientific collaboration Scenario I After data collection, you load the data into R and write R code to explore and analyze the data and save the code in an R script. Then you save the analysis results and plots as external files and manually combine all of these and your written prose into an MS Word Document. Scenario II After data collection, you use R for data exploration and analysis as well. But this time you include all the R code used for exploration and analysis, as well as the analysis outputs (statistical reports and graphs) and your written text in one single R markdown document. This R markdown document can be used to automatically create the final document (e.g., PDF, DOC, HTML etc.). B.3 Installing R Markdown # Install from CRAN install.packages(&#39;rmarkdown&#39;, dep = TRUE) If you need to generate PDF output from R markdown, you will need to install LaTeX. If you don’t have LaTeX yet, it is recommended that you install TinyTeX. ## Optional (Only needed for PDF format) install.packages(&#39;tinytex&#39;) tinytex::install_tinytex() # install TinyTeX B.4 R Markdown Components Let’s check the R Markdown Reference Guide. YAML header: metadata and options for the entire document Formatted text: texts with markup formatting Code chunks: R code (or any other language code) Adding figures: R-generated graphs Adding tables: R-generated tables Inline R code: In-text R code B.5 Tips We can control the text length to make sure that the codes do not run off the page edge when rendering the R markdown to PDF. knitr::opts_chunk$set( message = FALSE, warning = FALSE, tidy.opts = list(width.cutoff = 60) ) We can suppress the startup messages and/or warnings. suppressPackageStartupMessages(library(ggplot2)) We can re-format the R code in the markdown in a tidy way. knitr::opts_chunk$set(message=FALSE, tidy.opts=list(width.cutoff=60), tidy=TRUE) B.6 References R Markdown: The Definitive Guide R Markdown Reference Guide R Markdown Cheatsheet "],["references-5.html", "References", " References Davies, T. M. (2016). The book of R: A first course in programming and statistics (1st ed.). No Starch Press, Inc. Gerrard, P. (2016). Lean python: Learn just enough python to build useful tools. Apress. Janssens, J. (2014). Data science at the command line: Facing the future with time-tested tools. \" O’Reilly Media, Inc.\". Sweigart, A. (2020). Automate the boring stuff with python: Practical programming for total beginners. 2nd edition. No Starch Press. Wickham, H., &amp; Grolemund, G. (2017). R for data science: Import, tidy, transform, visualize, and model data (1st ed.). O’Reilly Media, Inc. "],["404.html", "Page not found", " Page not found The page you requested cannot be found (perhaps it was moved or renamed). You may want to try searching to find the page's new location, or use the table of contents to find the page you are looking for. "]]
