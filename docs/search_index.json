[["nltk.html", "Chapter 16 NLTK 16.1 Installation 16.2 Corpora Data 16.3 WordNet 16.4 Discovering Word Collocations", " Chapter 16 NLTK The almighty nltk package! 16.1 Installation Install package in the terminal !pip install nltk Download nltk data in python import nltk nltk.download(&#39;all&#39;, halt_on_error=False) import nltk # nltk.download() The complete collection of the nltk.corpus is huge. You probably donâ€™t need all of the corpora data. You can use nltk.download() to initialize a User Window for installation of specific datasets. 16.2 Corpora Data The package includes a lot of pre-loaded corpora datasets The default nltk_data directory is in /Users/YOUT_NAME/nltk_data/ Selective Examples Brown Corpus Reuters Corpus WordNet from nltk.corpus import gutenberg, brown, reuters # brown corpus ## Categories (topics?) print(&#39;Brown Corpus Total Categories: &#39;, len(brown.categories())) Brown Corpus Total Categories: 15 print(&#39;Categories List: &#39;, brown.categories()) Categories List: [&#39;adventure&#39;, &#39;belles_lettres&#39;, &#39;editorial&#39;, &#39;fiction&#39;, &#39;government&#39;, &#39;hobbies&#39;, &#39;humor&#39;, &#39;learned&#39;, &#39;lore&#39;, &#39;mystery&#39;, &#39;news&#39;, &#39;religion&#39;, &#39;reviews&#39;, &#39;romance&#39;, &#39;science_fiction&#39;] # Sentences print(brown.sents()[0]) ## first sentence [&#39;The&#39;, &#39;Fulton&#39;, &#39;County&#39;, &#39;Grand&#39;, &#39;Jury&#39;, &#39;said&#39;, &#39;Friday&#39;, &#39;an&#39;, &#39;investigation&#39;, &#39;of&#39;, &quot;Atlanta&#39;s&quot;, &#39;recent&#39;, &#39;primary&#39;, &#39;election&#39;, &#39;produced&#39;, &#39;``&#39;, &#39;no&#39;, &#39;evidence&#39;, &quot;&#39;&#39;&quot;, &#39;that&#39;, &#39;any&#39;, &#39;irregularities&#39;, &#39;took&#39;, &#39;place&#39;, &#39;.&#39;] print(brown.sents(categories=&#39;fiction&#39;)) ## first sentence for fiction texts [[&#39;Thirty-three&#39;], [&#39;Scotty&#39;, &#39;did&#39;, &#39;not&#39;, &#39;go&#39;, &#39;back&#39;, &#39;to&#39;, &#39;school&#39;, &#39;.&#39;], ...] ## Tagged Sentences print(brown.tagged_sents()[0]) [(&#39;The&#39;, &#39;AT&#39;), (&#39;Fulton&#39;, &#39;NP-TL&#39;), (&#39;County&#39;, &#39;NN-TL&#39;), (&#39;Grand&#39;, &#39;JJ-TL&#39;), (&#39;Jury&#39;, &#39;NN-TL&#39;), (&#39;said&#39;, &#39;VBD&#39;), (&#39;Friday&#39;, &#39;NR&#39;), (&#39;an&#39;, &#39;AT&#39;), (&#39;investigation&#39;, &#39;NN&#39;), (&#39;of&#39;, &#39;IN&#39;), (&quot;Atlanta&#39;s&quot;, &#39;NP$&#39;), (&#39;recent&#39;, &#39;JJ&#39;), (&#39;primary&#39;, &#39;NN&#39;), (&#39;election&#39;, &#39;NN&#39;), (&#39;produced&#39;, &#39;VBD&#39;), (&#39;``&#39;, &#39;``&#39;), (&#39;no&#39;, &#39;AT&#39;), (&#39;evidence&#39;, &#39;NN&#39;), (&quot;&#39;&#39;&quot;, &quot;&#39;&#39;&quot;), (&#39;that&#39;, &#39;CS&#39;), (&#39;any&#39;, &#39;DTI&#39;), (&#39;irregularities&#39;, &#39;NNS&#39;), (&#39;took&#39;, &#39;VBD&#39;), (&#39;place&#39;, &#39;NN&#39;), (&#39;.&#39;, &#39;.&#39;)] ## Sentence in natural forms sents = brown.sents(categories=&#39;fiction&#39;) [&#39; &#39;.join(sent) for sent in sents[1:5]] [&#39;Scotty did not go back to school .&#39;, &#39;His parents talked seriously and lengthily to their own doctor and to a specialist at the University Hospital -- Mr. McKinley was entitled to a discount for members of his family -- and it was decided it would be best for him to take the remainder of the term off , spend a lot of time in bed and , for the rest , do pretty much as he chose -- provided , of course , he chose to do nothing too exciting or too debilitating .&#39;, &#39;His teacher and his school principal were conferred with and everyone agreed that , if he kept up with a certain amount of work at home , there was little danger of his losing a term .&#39;, &#39;Scotty accepted the decision with indifference and did not enter the arguments .&#39;] ## Get tagged words tagged_words = brown.tagged_words(categories=&#39;fiction&#39;) #print(tagged_words[1]) ## a tuple ## Get all nouns nouns = [(word, tag) for word, tag in tagged_words if any (noun_tag in tag for noun_tag in [&#39;NP&#39;,&#39;NN&#39;])] ## Check first ten nouns nouns[:10] [(&#39;Scotty&#39;, &#39;NP&#39;), (&#39;school&#39;, &#39;NN&#39;), (&#39;parents&#39;, &#39;NNS&#39;), (&#39;doctor&#39;, &#39;NN&#39;), (&#39;specialist&#39;, &#39;NN&#39;), (&#39;University&#39;, &#39;NN-TL&#39;), (&#39;Hospital&#39;, &#39;NN-TL&#39;), (&#39;Mr.&#39;, &#39;NP&#39;), (&#39;McKinley&#39;, &#39;NP&#39;), (&#39;discount&#39;, &#39;NN&#39;)] ## Creating Freq list nouns_freq = nltk.FreqDist([w for w, t in nouns]) sorted(nouns_freq.items(),key=lambda x:x[1], reverse=True)[:20] [(&#39;man&#39;, 111), (&#39;time&#39;, 99), (&#39;men&#39;, 72), (&#39;room&#39;, 63), (&#39;way&#39;, 62), (&#39;eyes&#39;, 60), (&#39;face&#39;, 55), (&#39;house&#39;, 54), (&#39;head&#39;, 54), (&#39;night&#39;, 53), (&#39;day&#39;, 52), (&#39;hand&#39;, 50), (&#39;door&#39;, 47), (&#39;life&#39;, 44), (&#39;years&#39;, 44), (&#39;Mrs.&#39;, 41), (&#39;God&#39;, 41), (&#39;Kate&#39;, 40), (&#39;Mr.&#39;, 39), (&#39;people&#39;, 39)] sorted(nouns_freq.items(),key=lambda x:x[0], reverse=True)[:20] [(&#39;zoo&#39;, 2), (&#39;zlotys&#39;, 1), (&#39;zenith&#39;, 1), (&#39;youth&#39;, 5), (&#39;yelling&#39;, 1), (&#39;years&#39;, 44), (&#39;yearning&#39;, 1), (&quot;year&#39;s&quot;, 1), (&#39;year&#39;, 9), (&#39;yards&#39;, 4), (&#39;yard&#39;, 7), (&#39;yachts&#39;, 1), (&#39;writing&#39;, 2), (&#39;writers&#39;, 1), (&#39;writer&#39;, 4), (&#39;wrists&#39;, 1), (&#39;wrist&#39;, 2), (&#39;wrinkles&#39;, 1), (&#39;wrinkle&#39;, 1), (&#39;wretch&#39;, 1)] nouns_freq.most_common(10) [(&#39;man&#39;, 111), (&#39;time&#39;, 99), (&#39;men&#39;, 72), (&#39;room&#39;, 63), (&#39;way&#39;, 62), (&#39;eyes&#39;, 60), (&#39;face&#39;, 55), (&#39;house&#39;, 54), (&#39;head&#39;, 54), (&#39;night&#39;, 53)] ## Accsess data via fileid brown.fileids(categories=&#39;fiction&#39;)[0] &#39;ck01&#39; brown.sents(fileids=&#39;ck01&#39;) [[&#39;Thirty-three&#39;], [&#39;Scotty&#39;, &#39;did&#39;, &#39;not&#39;, &#39;go&#39;, &#39;back&#39;, &#39;to&#39;, &#39;school&#39;, &#39;.&#39;], ...] 16.3 WordNet 16.3.1 A Dictionary Resource from nltk.corpus import wordnet as wn word = &#39;walk&#39; # get synsets word_synsets = wn.synsets(word, pos=&#39;v&#39;) word_synsets [Synset(&#39;walk.v.01&#39;), Synset(&#39;walk.v.02&#39;), Synset(&#39;walk.v.03&#39;), Synset(&#39;walk.v.04&#39;), Synset(&#39;walk.v.05&#39;), Synset(&#39;walk.v.06&#39;), Synset(&#39;walk.v.07&#39;), Synset(&#39;walk.v.08&#39;), Synset(&#39;walk.v.09&#39;), Synset(&#39;walk.v.10&#39;)] Word sense is closely connected to its parts-of-speech. Therefore, in WordNet it is crucial to specify the POS tag of the word to obtain the correct synset of the word. There are four common part-of-speech tags in WordNet, as shown below: Part of Speech Tag Noun n Adjective a Adverb r Verb v Check the definition of a synset (i.e., a specific sense of the word): word_synsets[0].definition() &quot;use one&#39;s feet to advance; advance by steps&quot; Check the examples of a synset: word_synsets[0].examples() [&quot;Walk, don&#39;t run!&quot;, &#39;We walked instead of driving&#39;, &#39;She walks with a slight limp&#39;, &#39;The patient cannot walk yet&#39;, &#39;Walk over to the cabinet&#39;] ## Get details of each synset for s in word_synsets: if str(s.name()).startswith(&#39;walk.v&#39;): print( &#39;Syset ID: %s \\n&#39; &#39;POS Tag: %s \\n&#39; &#39;Definition: %s \\n&#39; &#39;Examples: %s \\n&#39; % (s.name(), s.pos(), s.definition(),s.examples()) ) Syset ID: walk.v.01 POS Tag: v Definition: use one&#39;s feet to advance; advance by steps Examples: [&quot;Walk, don&#39;t run!&quot;, &#39;We walked instead of driving&#39;, &#39;She walks with a slight limp&#39;, &#39;The patient cannot walk yet&#39;, &#39;Walk over to the cabinet&#39;] Syset ID: walk.v.02 POS Tag: v Definition: accompany or escort Examples: [&quot;I&#39;ll walk you to your car&quot;] Syset ID: walk.v.03 POS Tag: v Definition: obtain a base on balls Examples: [] Syset ID: walk.v.04 POS Tag: v Definition: traverse or cover by walking Examples: [&#39;Walk the tightrope&#39;, &#39;Paul walked the streets of Damascus&#39;, &#39;She walks 3 miles every day&#39;] Syset ID: walk.v.05 POS Tag: v Definition: give a base on balls to Examples: [] Syset ID: walk.v.06 POS Tag: v Definition: live or behave in a specified manner Examples: [&#39;walk in sadness&#39;] Syset ID: walk.v.07 POS Tag: v Definition: be or act in association with Examples: [&#39;We must walk with our dispossessed brothers and sisters&#39;, &#39;Walk with God&#39;] Syset ID: walk.v.08 POS Tag: v Definition: walk at a pace Examples: [&#39;The horses walked across the meadow&#39;] Syset ID: walk.v.09 POS Tag: v Definition: make walk Examples: [&#39;He walks the horse up the mountain&#39;, &#39;Walk the dog twice a day&#39;] Syset ID: walk.v.10 POS Tag: v Definition: take a walk; go for a walk; walk for pleasure Examples: [&#39;The lovers held hands while walking&#39;, &#39;We like to walk every Sunday&#39;] 16.3.2 Lexical Relations Extract words that maintain some lexical relations with the synset: word_synsets[0].hypernyms() # hypernym [Synset(&#39;travel.v.01&#39;)] word_synsets[0].hypernyms()[0].hyponyms() # similar words [Synset(&#39;accompany.v.02&#39;), Synset(&#39;advance.v.01&#39;), Synset(&#39;angle.v.01&#39;), Synset(&#39;ascend.v.01&#39;), Synset(&#39;automobile.v.01&#39;), Synset(&#39;back.v.02&#39;), Synset(&#39;bang.v.04&#39;), Synset(&#39;beetle.v.02&#39;), Synset(&#39;betake_oneself.v.01&#39;), Synset(&#39;billow.v.02&#39;), Synset(&#39;bounce.v.03&#39;), Synset(&#39;breeze.v.02&#39;), Synset(&#39;caravan.v.01&#39;), Synset(&#39;career.v.01&#39;), Synset(&#39;carry.v.36&#39;), Synset(&#39;circle.v.01&#39;), Synset(&#39;circle.v.02&#39;), Synset(&#39;circuit.v.01&#39;), Synset(&#39;circulate.v.07&#39;), Synset(&#39;come.v.01&#39;), Synset(&#39;come.v.11&#39;), Synset(&#39;crawl.v.01&#39;), Synset(&#39;cruise.v.02&#39;), Synset(&#39;derail.v.02&#39;), Synset(&#39;descend.v.01&#39;), Synset(&#39;do.v.13&#39;), Synset(&#39;drag.v.04&#39;), Synset(&#39;draw.v.12&#39;), Synset(&#39;drive.v.02&#39;), Synset(&#39;drive.v.14&#39;), Synset(&#39;ease.v.01&#39;), Synset(&#39;fall.v.01&#39;), Synset(&#39;fall.v.15&#39;), Synset(&#39;ferry.v.03&#39;), Synset(&#39;float.v.01&#39;), Synset(&#39;float.v.02&#39;), Synset(&#39;float.v.05&#39;), Synset(&#39;flock.v.01&#39;), Synset(&#39;fly.v.01&#39;), Synset(&#39;fly.v.06&#39;), Synset(&#39;follow.v.01&#39;), Synset(&#39;follow.v.04&#39;), Synset(&#39;forge.v.05&#39;), Synset(&#39;get_around.v.04&#39;), Synset(&#39;ghost.v.01&#39;), Synset(&#39;glide.v.01&#39;), Synset(&#39;go_around.v.02&#39;), Synset(&#39;hiss.v.02&#39;), Synset(&#39;hurtle.v.01&#39;), Synset(&#39;island_hop.v.01&#39;), Synset(&#39;lance.v.01&#39;), Synset(&#39;lurch.v.03&#39;), Synset(&#39;outflank.v.01&#39;), Synset(&#39;pace.v.02&#39;), Synset(&#39;pan.v.01&#39;), Synset(&#39;pass.v.01&#39;), Synset(&#39;pass_over.v.04&#39;), Synset(&#39;play.v.09&#39;), Synset(&#39;plow.v.03&#39;), Synset(&#39;prance.v.02&#39;), Synset(&#39;precede.v.04&#39;), Synset(&#39;precess.v.01&#39;), Synset(&#39;proceed.v.02&#39;), Synset(&#39;propagate.v.02&#39;), Synset(&#39;pursue.v.02&#39;), Synset(&#39;push.v.09&#39;), Synset(&#39;raft.v.02&#39;), Synset(&#39;repair.v.03&#39;), Synset(&#39;retreat.v.02&#39;), Synset(&#39;retrograde.v.02&#39;), Synset(&#39;return.v.01&#39;), Synset(&#39;ride.v.01&#39;), Synset(&#39;ride.v.04&#39;), Synset(&#39;ride.v.10&#39;), Synset(&#39;rise.v.01&#39;), Synset(&#39;roll.v.12&#39;), Synset(&#39;round.v.01&#39;), Synset(&#39;run.v.11&#39;), Synset(&#39;run.v.34&#39;), Synset(&#39;rush.v.01&#39;), Synset(&#39;scramble.v.01&#39;), Synset(&#39;seek.v.04&#39;), Synset(&#39;shuttle.v.01&#39;), Synset(&#39;sift.v.01&#39;), Synset(&#39;ski.v.01&#39;), Synset(&#39;slice_into.v.01&#39;), Synset(&#39;slither.v.01&#39;), Synset(&#39;snowshoe.v.01&#39;), Synset(&#39;speed.v.04&#39;), Synset(&#39;steamer.v.01&#39;), Synset(&#39;step.v.01&#39;), Synset(&#39;step.v.02&#39;), Synset(&#39;step.v.06&#39;), Synset(&#39;stray.v.02&#39;), Synset(&#39;swap.v.02&#39;), Synset(&#39;swash.v.01&#39;), Synset(&#39;swim.v.01&#39;), Synset(&#39;swim.v.05&#39;), Synset(&#39;swing.v.03&#39;), Synset(&#39;taxi.v.01&#39;), Synset(&#39;trail.v.03&#39;), Synset(&#39;tram.v.01&#39;), Synset(&#39;transfer.v.06&#39;), Synset(&#39;travel.v.04&#39;), Synset(&#39;travel.v.05&#39;), Synset(&#39;travel.v.06&#39;), Synset(&#39;travel_by.v.01&#39;), Synset(&#39;travel_purposefully.v.01&#39;), Synset(&#39;travel_rapidly.v.01&#39;), Synset(&#39;trundle.v.01&#39;), Synset(&#39;turn.v.06&#39;), Synset(&#39;walk.v.01&#39;), Synset(&#39;walk.v.10&#39;), Synset(&#39;weave.v.04&#39;), Synset(&#39;wend.v.01&#39;), Synset(&#39;wheel.v.03&#39;), Synset(&#39;whine.v.01&#39;), Synset(&#39;whish.v.02&#39;), Synset(&#39;whisk.v.02&#39;), Synset(&#39;whistle.v.02&#39;), Synset(&#39;withdraw.v.01&#39;), Synset(&#39;zigzag.v.01&#39;), Synset(&#39;zoom.v.02&#39;)] word_synsets[0].root_hypernyms() # root [Synset(&#39;travel.v.01&#39;)] word_synsets[0].hypernym_paths() # from root to this synset in WordNet [[Synset(&#39;travel.v.01&#39;), Synset(&#39;walk.v.01&#39;)]] Synonyms # Collect synonyms of all synsets synonyms = [] for syn in wn.synsets(&#39;book&#39;, pos=&#39;v&#39;): for lemma in syn.lemmas(): synonyms.append(lemma.name()) len(synonyms) 6 len(set(synonyms)) 3 print(set(synonyms)) {&#39;reserve&#39;, &#39;hold&#39;, &#39;book&#39;} Antonyms # First Synset Lemma String word_synsets[0].lemmas()[0].name() # Antonnyms of the First Synset &#39;walk&#39; word_synsets[0].lemmas()[0].antonyms()[0] Lemma(&#39;ride.v.02.ride&#39;) While previous taxonomic relations (e.g., hypernymy and hyponymy) are in-between synsets, the synonymy and antonymy relations are in-between lemmas. We need to be very clear about the use of the three variants in WordNet: Word Form Lemma Synset 16.3.3 Semantic Similarity Computation Synsets are organized in a hypernym tree, which can be used for reasoning about the semantic similarity of two Synsets. The closer the two Synsets are in the tree, the more similar they are. # syn1 = wn.synsets(&#39;walk&#39;, pos=&#39;v&#39;)[0] syn1 = wn.synset(&#39;walk.v.01&#39;) syn2 = wn.synset(&#39;toddle.v.01&#39;) syn3 = wn.synset(&#39;think.v.01&#39;) syn1.wup_similarity(syn2) 0.8 syn1.wup_similarity(syn3) 0.2857142857142857 syn1.path_similarity(syn2) 0.5 syn1.path_similarity(syn3) 0.16666666666666666 ref = syn1.hypernyms()[0] syn1.shortest_path_distance(ref) 1 syn2.shortest_path_distance(ref) 2 syn1.shortest_path_distance(syn2) 1 print(ref.definition()) change location; move, travel, or proceed, also metaphorically print([l.name() for l in ref.lemmas()]) [&#39;travel&#39;, &#39;go&#39;, &#39;move&#39;, &#39;locomote&#39;] syn1.hypernym_paths() [[Synset(&#39;travel.v.01&#39;), Synset(&#39;walk.v.01&#39;)]] syn2.hypernym_paths() [[Synset(&#39;travel.v.01&#39;), Synset(&#39;walk.v.01&#39;), Synset(&#39;toddle.v.01&#39;)]] syn3.hypernym_paths() [[Synset(&#39;think.v.03&#39;), Synset(&#39;evaluate.v.02&#39;), Synset(&#39;think.v.01&#39;)]] The wup_similarity method is short for Wu-Pamler Similarity. It is a scoring method for how similar the word senses are based on where the Synsets occur relative to each other in the hypernym tree. For more information or other scoring methods, please check NLTK WordNet documentation. 16.4 Discovering Word Collocations from nltk.corpus import brown from nltk.collocations import BigramCollocationFinder from nltk.metrics import BigramAssocMeasures words = [w.lower() for w in brown.words()] bcf = BigramCollocationFinder.from_words(words) bcf.nbest(BigramAssocMeasures.likelihood_ratio, 4) [(&#39;;&#39;, &#39;;&#39;), (&#39;?&#39;, &#39;?&#39;), (&#39;of&#39;, &#39;the&#39;), (&#39;.&#39;, &#39;``&#39;)] # deal with stopwords from nltk.corpus import stopwords stopset = set(stopwords.words(&#39;english&#39;)) ## Fitler critera: ## remove words whose length &lt; 3 or which are on the stop word list filter_stops = lambda w: len(w) &lt; 3 or w in stopset bcf.apply_word_filter(filter_stops) bcf.nbest(BigramAssocMeasures.likelihood_ratio, 10) [(&#39;united&#39;, &#39;states&#39;), (&#39;new&#39;, &#39;york&#39;), (&#39;per&#39;, &#39;cent&#39;), (&#39;years&#39;, &#39;ago&#39;), (&#39;rhode&#39;, &#39;island&#39;), (&#39;los&#39;, &#39;angeles&#39;), (&#39;peace&#39;, &#39;corps&#39;), (&#39;san&#39;, &#39;francisco&#39;), (&#39;high&#39;, &#39;school&#39;), (&#39;fiscal&#39;, &#39;year&#39;)] ## apply freq-based filter bcf.apply_freq_filter(3) bcf.nbest(BigramAssocMeasures.likelihood_ratio, 10) [(&#39;united&#39;, &#39;states&#39;), (&#39;new&#39;, &#39;york&#39;), (&#39;per&#39;, &#39;cent&#39;), (&#39;years&#39;, &#39;ago&#39;), (&#39;rhode&#39;, &#39;island&#39;), (&#39;los&#39;, &#39;angeles&#39;), (&#39;peace&#39;, &#39;corps&#39;), (&#39;san&#39;, &#39;francisco&#39;), (&#39;high&#39;, &#39;school&#39;), (&#39;fiscal&#39;, &#39;year&#39;)] Exercise 16.1 Try to identify bigram collocations in the corpus, Alice in the Wonderland. The texts are available in nltk.corpus.gutenburg. Exercise 16.2 Following the same strategy of bigram collocation extraction, please try to extract trigrams from the brown corpus. Remove stop words and short words as we did in the lecture. Include only trigrams whose frequency &gt; 5. "]]
