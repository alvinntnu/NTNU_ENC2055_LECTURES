[["web-scraping.html", "Chapter 17 Web Scraping 17.1 webbrowswer module 17.2 requests Module 17.3 bs4 Module (Beautiful Soup) 17.4 Reference", " Chapter 17 Web Scraping Web scraping is the term for using a program to download and process content from the web. webbrowser: A default Python module to open a browser to specific page. requests: A module to download files and web pages from the Internet. bs4: A modile to parse HTML, i.e., the format that web pages are written in. selenium: A module to launch and control a web browser (e.g., filling in forms, simulating mouse clicks.) 17.1 webbrowswer module Create a python script with the following codes, named py-checkword.py #! python3 import webbrowser, sys, pyperclip if len(sys.argv) &gt; 1: # Get input from the command line target = &#39; &#39;.join(sys.argv[1:]) else: # Get input from the clipboard target = pyperclip.paste() webbrowser.open(&#39;https://www.dictionary.com/browse/&#39;+ target) Run the python script in the terminal python py-checkword.py beauty Exercise 17.1 How to modify the py-checkword.py so that the user can attach a list of words separated by spaces for checking? For example, the modified script will be able to open three web browsers for beauty, internet, and national. python py-checkword2.py beauty internet national 17.2 requests Module The requests modules allow us to easily download files from the web without having to worry about complicated issues such as network errors, connection problems, and data compression. import requests res = requests.get(&#39;https://www.gutenberg.org/files/2591/2591-0.txt&#39;) type(res) ## Check status code to see if the download is successful &lt;class &#39;requests.models.Response&#39;&gt; res.status_code == requests.codes.ok ## `requests.codes.ok` == 200 True len(res.text) 559879 print(res.text[:250]) ï»¿The Project Gutenberg eBook of Grimmsâ Fairy Tales, by The Brothers Grimm This eBook is for the use of anyone anywhere in the United States and most other parts of the world at no cost and with almost no restrictions whatsoever. You may cop Prepare potential errors during the file download import requests res = requests.get(&#39;https://www.gutenberg.org/file-that-does-not-exist.txt&#39;) ## Check status code to see if the download is successful res.status_code == requests.codes.ok ## `requests.codes.ok` == 200 False len(res.text) 6396 print(res.text[:250]) &lt;!DOCTYPE html&gt; &lt;html class=&quot;client-nojs&quot; lang=&quot;en&quot; dir=&quot;ltr&quot;&gt; &lt;head&gt; &lt;meta charset=&quot;UTF-8&quot;/&gt; &lt;title&gt;404 | Project Gutenberg&lt;/title&gt; &lt;link rel=&quot;stylesheet&quot; href=&quot;/gutenberg/style.css?v=1.1&quot;&gt; &lt;link rel=&quot;stylesheet&quot; href=&quot;/gutenberg/collapsible.css res.raise_for_status() Error in py_call_impl(callable, dots$args, dots$keywords): HTTPError: 404 Client Error: Not Found for url: https://www.gutenberg.org/file-that-does-not-exist.txt Detailed traceback: File &quot;&lt;string&gt;&quot;, line 1, in &lt;module&gt; File &quot;/Users/Alvin/opt/anaconda3/envs/python-notes/lib/python3.7/site-packages/requests/models.py&quot;, line 943, in raise_for_status raise HTTPError(http_error_msg, response=self) A better way to modify the codes is to make sure that the program stops as soon as some unexpected error happens. Always call raise_for_status() after calling requests.get() because we need to make sure the file has been successfully downloaded before the program continues. import requests res = requests.get(&#39;https://www.gutenberg.org/file-that-does-not-exist.txt&#39;) try: res.raise_for_status() except Exception as exc: print(&#39;There was a problem with the link: %s&#39; % (exc)) There was a problem with the link: 404 Client Error: Not Found for url: https://www.gutenberg.org/file-that-does-not-exist.txt Usually we may want to scrape the texts from the web and save them on the Hard Drive. import requests res = requests.get(&#39;https://www.gutenberg.org/files/2591/2591-0.txt&#39;) try: res.raise_for_status() except Exception as exc: print(&#39;There was a problem with the link: %s&#39; % (exc)) with open(&#39;grimms.txt&#39;, &#39;w&#39;) as f: f.write(res.text) 559879 17.3 bs4 Module (Beautiful Soup) Beautiful Soup is a module for extracting information from an HTML page. The package name is pip install -U beatifulsoup4 but in use, it is import bs4. Each Word is a dict: “headword”: head word string “pronunciation”: IPA “parts-of-speech”: A list of senses {“definition”: ’‘, “example”:’’} import requests, bs4 target=&#39;produce&#39; res = requests.get(&#39;https://www.dictionary.com/browse/&#39; + target) res.raise_for_status() soup = bs4.BeautifulSoup(res.text, &#39;lxml&#39;) entries = soup.select(&#39;.css-1avshm7&#39;) # entries ## Define the word structure (dict) cur_word = {} # for each entry for i, entry in enumerate(entries): ## Include only the main entry of the page if len(entry.select(&#39;h1&#39;)) &gt; 0: #print(&#39;Entry Number: &#39;, i) ## headword and pronunciations cur_headword = entry.select(&#39;h1&#39;)[0].getText() cur_spell = entry.select(&#39;.pron-spell-content&#39;)[0].getText() cur_ipa = entry.select(&#39;.pron-ipa-content&#39;)[0].getText().encode(&#39;utf-8&#39;).decode(&#39;utf-8&#39;) #print(&#39;Headword: &#39;, cur_headword) #print(&#39;Pronunciation: &#39;, cur_ipa) cur_word[&#39;headword&#39;] = cur_headword cur_word[&#39;pronunciation&#39;] = cur_ipa # for each POS type in the current entry for pos in entry.select(&#39;.css-pnw38j&#39;): cur_pos = pos.select(&#39;.luna-pos&#39;)[0].getText() #print(&#39;=&#39;*10) #print(&#39;POS: &#39;, cur_pos.upper()) cur_definitions = pos.select(&#39;div[value] &gt; span.one-click-content&#39;) cur_sense_list =[] # for each definition in the current POS for sense in cur_definitions: #print(&#39;DEF: &#39; + sense.find(text=True, recursive=True)) ## check if there&#39;s any example ex = sense.find(attrs={&#39;class&#39;:&#39;luna-example&#39;}) if ex is not None: cur_ex = ex.getText() _ = ex.extract() else: cur_ex = &#39;&#39; cur_def = sense.getText() #print(&#39;-&#39;*10) #print(&#39;Definition: &#39; + cur_def) #print(&#39;Example: &#39;+ cur_ex) cur_sense = {&#39;definition&#39;: cur_def, &#39;example&#39;: cur_ex} cur_sense_list.append(cur_sense) cur_word[cur_pos] = cur_sense_list import json with open(target+&#39;.json&#39;, &#39;w&#39;, encoding=&#39;utf-8&#39;) as f: json.dump(cur_word, f, ensure_ascii=False) import json with open(&#39;produce.json&#39;,&#39;r&#39;, encoding=&#39;utf-8&#39;) as f: cur_word = json.load(f) cur_word.keys() dict_keys([&#39;headword&#39;, &#39;pronunciation&#39;, &#39;verb (used with object),&#39;, &#39;verb (used without object),&#39;, &#39;noun&#39;]) print(json.dumps(cur_word, sort_keys=False, indent=4, ensure_ascii=False)) { &quot;headword&quot;: &quot;produce&quot;, &quot;pronunciation&quot;: &quot;/ verb prəˈdus, -ˈdyus; noun ˈprɒd us, -yus, ˈproʊ dus, -dyus /&quot;, &quot;verb (used with object),&quot;: [ { &quot;definition&quot;: &quot;to bring into existence; give rise to; cause: &quot;, &quot;example&quot;: &quot;to produce steam.&quot; }, { &quot;definition&quot;: &quot;to bring into existence by intellectual or creative ability: &quot;, &quot;example&quot;: &quot;to produce a great painting.&quot; }, { &quot;definition&quot;: &quot;to make or manufacture: &quot;, &quot;example&quot;: &quot;to produce automobiles for export.&quot; }, { &quot;definition&quot;: &quot;to bring forth; give birth to; bear: &quot;, &quot;example&quot;: &quot;to produce a litter of puppies.&quot; }, { &quot;definition&quot;: &quot;to provide, furnish, or supply; yield: &quot;, &quot;example&quot;: &quot;a mine producing silver.&quot; }, { &quot;definition&quot;: &quot;Finance. &quot;, &quot;example&quot;: &quot;&quot; }, { &quot;definition&quot;: &quot;to cause to accrue: &quot;, &quot;example&quot;: &quot;stocks producing unexpected dividends.&quot; }, { &quot;definition&quot;: &quot;to bring forward; present to view or notice; exhibit: &quot;, &quot;example&quot;: &quot;to produce one&#39;s credentials.&quot; }, { &quot;definition&quot;: &quot;to bring (a play, movie, opera, etc.) before the public.&quot;, &quot;example&quot;: &quot;&quot; }, { &quot;definition&quot;: &quot;to extend or prolong, as a line.&quot;, &quot;example&quot;: &quot;&quot; } ], &quot;verb (used without object),&quot;: [ { &quot;definition&quot;: &quot;to create, bring forth, or yield offspring, products, etc.: &quot;, &quot;example&quot;: &quot;Their mines are closed because they no longer produce.&quot; }, { &quot;definition&quot;: &quot;Economics. &quot;, &quot;example&quot;: &quot;&quot; }, { &quot;definition&quot;: &quot;to create economic value; bring crops, goods, etc., to a point at which they will command a price.&quot;, &quot;example&quot;: &quot;&quot; } ], &quot;noun&quot;: [ { &quot;definition&quot;: &quot;something that is produced; yield; product. &quot;, &quot;example&quot;: &quot;&quot; }, { &quot;definition&quot;: &quot;agricultural products collectively, especially vegetables and fruits.&quot;, &quot;example&quot;: &quot;&quot; }, { &quot;definition&quot;: &quot;offspring, especially of a female animal: &quot;, &quot;example&quot;: &quot;the produce of a mare.&quot; } ] } Exercise 17.2 Now how to extend this short script to allow the users to perform searches of multiple words all at once, scrape all definitions and examples from the website of Dictionary.com, and save them to the Hard Drive as json files in a specific directory? checkwords(targets=[&quot;individual&quot;, &quot;wonderful&quot;], outdir = &#39;dictionary_results/&#39;) import json outdir = &#39;dictionary_results/&#39; with open(outdir+&#39;wonderful.json&#39;,&#39;r&#39;) as f: cur_word = json.load(f) print(json.dumps(cur_word, sort_keys=False, indent=4, ensure_ascii=False)) { &quot;headword&quot;: &quot;wonderful&quot;, &quot;pronunciation&quot;: &quot;/ ˈwʌn dər fəl /&quot;, &quot;adjective&quot;: [ { &quot;definition&quot;: &quot;excellent; great; marvelous: &quot;, &quot;example&quot;: &quot;We all had a wonderful weekend.&quot; }, { &quot;definition&quot;: &quot;of a sort that causes or arouses wonder; amazing; astonishing: &quot;, &quot;example&quot;: &quot;The storm was wonderful to behold.&quot; } ] } 17.4 Reference Beautiful Soup Documentation "]]
